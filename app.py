import streamlit as st
import parselmouth
from parselmouth.praat import call
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import platform
import datetime
import io

# --- êµ¬ê¸€ ì‹œíŠ¸ & ì´ë©”ì¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
from google.oauth2 import service_account
import gspread
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email.mime.text import MIMEText
from email import encoders

from sklearn.metrics import confusion_matrix, roc_curve

import sqlite3
import hashlib
import json
from pathlib import Path

from scipy.signal import find_peaks

from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis
from sklearn.model_selection import LeaveOneOut
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# -------------------------------
# Step1 screening ë©”ì‹œì§€(í™•ë¥  êµ¬ê°„ë³„)
# -------------------------------
def step1_screening_band(p_pd: float, pd_cut: float = 0.50):
    """
    Step1(ì •ìƒ vs PD) ìŠ¤í¬ë¦¬ë‹ í™•ë¥ (p_pd)ì— ë”°ë¼ ì•ˆë‚´ ë¬¸êµ¬/í†¤ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.
    Return: (kind, headline, band_code)
      - kind: 'success'|'warning'|'error' (Streamlit ë°°ë„ˆ ìƒ‰ìƒ)
      - headline: ì‚¬ìš©ì ì•ˆë‚´ ë¬¸êµ¬(ìŠ¤í¬ë¦¬ë‹/ì¶”ì • í‘œí˜„)
      - band_code: í›„ì† í•´ì„(ì„¹ì…˜ ì œëª©/ê²½ê³„ ì•ˆë‚´)ì— ì‚¬ìš©í•  ë‚´ë¶€ ì½”ë“œ
    """
    try:
        p_pd = float(p_pd)
    except Exception:
        p_pd = 0.0

    # í™•ë¥  êµ¬ê°„(ì„œë¹„ìŠ¤/ì„ìƒìš© ì¶”ì²œ)
    if p_pd <= 0.10:
        return ("success", "ì •ìƒ ë²”ìœ„ë¡œ íŒë‹¨ë©ë‹ˆë‹¤(ì •ìƒ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŒ).", "normal_very_high")
    if p_pd < 0.30:
        return ("success", "ì •ìƒ ë²”ìœ„ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.", "normal_high")
    if p_pd < 0.45:
        return ("warning", "ê²½ê³„ êµ¬ê°„ì…ë‹ˆë‹¤(ì •ìƒ/íŒŒí‚¨ìŠ¨ ê°€ëŠ¥ì„±ì´ í˜¼ì¬).", "border_mixed")
    if p_pd < 0.55:
        return ("warning", f"ì»·ì˜¤í”„({pd_cut:.2f}) ê·¼ì²˜ì˜ ê²½ê³„ êµ¬ê°„ì…ë‹ˆë‹¤(ì¶”ê°€ í‰ê°€/ì¬ì¸¡ì • ê¶Œì¥).", "border_cutoff")
    if p_pd < 0.70:
        return ("warning", "íŒŒí‚¨ìŠ¨ë³‘ ê´€ë ¨ ìŒì„± íŠ¹ì§•ì´ ê´€ì°°ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.", "pd_possible")
    if p_pd < 0.90:
        return ("error", "íŒŒí‚¨ìŠ¨ë³‘ ê´€ë ¨ ìŒì„± íŠ¹ì§•ì´ ëšœë ·í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.", "pd_high")
    return ("error", "íŒŒí‚¨ìŠ¨ë³‘ ê´€ë ¨ ìŒì„± íŠ¹ì§•ì´ ë§¤ìš° ê°•í•˜ê²Œ ê´€ì°°ë©ë‹ˆë‹¤.", "pd_very_high")



@st.cache_data
def get_step1_training_stats(_file_mtime=None):
    """
    Step1(ì •ìƒ vs PD) í•´ì„ ë³´ê°•ìš© í†µê³„(í•™ìŠµë°ì´í„° ê¸°ì¤€).
    - ì¤‘ì•™ê°’(robust) ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ê°’ì´ ì–´ëŠ ì§‘ë‹¨ì— ë” ê°€ê¹Œìš´ì§€ ì„¤ëª…í•˜ê¸° ìœ„í•´ ì‚¬ìš©
    - ì„œë¹„ìŠ¤ ì•ˆì •ì„±: ëª¨ë¸/íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ì—ì„œ ê³„ìˆ˜ ì¶”ì¶œì´ ì‹¤íŒ¨í•´ë„ ì„¤ëª…ì´ 'ê³µë€'ì´ ë˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ì•ˆì „ì¥ì¹˜
    """
    training_path = get_training_file()
    if training_path is None:
        return None

    try:
        df = pd.read_csv(training_path) if training_path.lower().endswith(".csv") else pd.read_excel(training_path)
    except Exception:
        return None

    label_col = "ì§„ë‹¨ê²°ê³¼ (Label)"
    if label_col not in df.columns:
        return None

    labels = df[label_col].astype(str).str.lower()
    is_pd = labels.str.startswith("pd_")
    is_normal = labels.eq("normal")

    feats = ["F0", "Range", "ê°•ë„(dB)", "SPS"]
    stats = {}
    for f in feats:
        if f not in df.columns:
            continue
        pd_vals = pd.to_numeric(df.loc[is_pd, f], errors="coerce").dropna()
        n_vals = pd.to_numeric(df.loc[is_normal, f], errors="coerce").dropna()
        if len(pd_vals) < 2 or len(n_vals) < 2:
            continue
        stats[f] = {
            "pd_med": float(pd_vals.median()),
            "n_med": float(n_vals.median()),
            "pd_mean": float(pd_vals.mean()),
            "n_mean": float(n_vals.mean()),
        }
    return stats if stats else None


def explain_step1_by_training(stats, x_dict, topk=3):
    """
    í•™ìŠµë°ì´í„°(ì¤‘ì•™ê°’) ê¸°ì¤€ìœ¼ë¡œ ì…ë ¥ê°’ì´ PD/ì •ìƒ ì¤‘ ì–´ë””ì— ë” ê°€ê¹Œìš´ì§€ ì„¤ëª… ë¬¸ì¥ ìƒì„±.

    Return:
        reasons_normal: ì •ìƒ ì¤‘ì•™ê°’ ìª½ìœ¼ë¡œ ë” ê°€ê¹Œìš´(ë˜ëŠ” ì •ìƒ ìª½ì„ ì§€ì§€í•˜ëŠ”) ê·¼ê±° TOP-K
        reasons_pd_strict: PD ì¤‘ì•™ê°’ ìª½ìœ¼ë¡œ 'ëª…í™•íˆ' ë” ê°€ê¹Œìš´ ê·¼ê±° TOP-K
        reasons_pd_closest: (ê²½ê³„/ì• ë§¤ êµ¬ê°„ ëŒ€ë¹„) PD ì¤‘ì•™ê°’ì— ìƒëŒ€ì ìœ¼ë¡œ 'ê°€ê¹Œìš´' í•­ëª© TOP-K
            - ì •ìƒ ì¤‘ì•™ê°’ì´ ë” ê°€ê¹ë”ë¼ë„, PD ì¤‘ì•™ê°’ê³¼ì˜ ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í•­ëª©ì„ ë°˜í™˜
            - ì„ìƒìš©: PD í™•ë¥ ì´ cut-off ê·¼ì²˜ì¼ ë•Œ "ì–´ë–¤ ì§€í‘œê°€ PD í•™ìŠµêµ°ê³¼ ìœ ì‚¬í–ˆëŠ”ì§€"ë¥¼ ê³µë€ ì—†ì´ ë³´ì—¬ì£¼ê¸° ìœ„í•¨
    """
    if not stats:
        return [], [], []

    reasons_pd_strict, reasons_n, reasons_pd_closest = [], [], []
    scored = []  # (abs_strength, strength, closeness_pd, f, x, pd_med, n_med)

    for f, s in stats.items():
        if f not in x_dict:
            continue
        try:
            x = float(x_dict[f])
        except Exception:
            continue
        if np.isnan(x):
            continue

        pd_med = s.get("pd_med")
        n_med = s.get("n_med")
        if pd_med is None or n_med is None:
            continue

        d_pd = abs(x - pd_med)
        d_n = abs(x - n_med)
        denom = abs(n_med - pd_med) + 1e-6

        # +ë©´ PDìª½, -ë©´ ì •ìƒìª½ (ì¤‘ì•™ê°’ ê¸°ì¤€ ìƒëŒ€ì  ê°€ê¹Œì›€)
        strength = float((d_n - d_pd) / denom)
        abs_strength = abs(strength)

        # PD ì¤‘ì•™ê°’ê³¼ì˜ ìƒëŒ€ì  ê·¼ì ‘ë„(0~1 ê·¼ì‚¬): 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ PD ì¤‘ì•™ê°’ì— ê°€ê¹Œì›€
        closeness_pd = float(max(0.0, 1.0 - (d_pd / denom)))

        scored.append((abs_strength, strength, closeness_pd, f, x, pd_med, n_med))

    if not scored:
        return [], [], []

    scored.sort(reverse=True, key=lambda t: (t[0], t[2]))

    def _fmt(f, x, pd_med, n_med):
        if f == "ê°•ë„(dB)":
            name, fmt = "í‰ê·  ìŒì„± ê°•ë„", f"{x:.1f}dB"
            pd_fmt, n_fmt = f"{pd_med:.1f}dB", f"{n_med:.1f}dB"
        elif f == "Range":
            name, fmt = "ìŒë„ ë²”ìœ„", f"{x:.1f}Hz"
            pd_fmt, n_fmt = f"{pd_med:.1f}Hz", f"{n_med:.1f}Hz"
        elif f == "F0":
            name, fmt = "í‰ê·  ìŒë„(F0)", f"{x:.1f}Hz"
            pd_fmt, n_fmt = f"{pd_med:.1f}Hz", f"{n_med:.1f}Hz"
        elif f == "SPS":
            name, fmt = "ë§ì†ë„(SPS)", f"{x:.2f}"
            pd_fmt, n_fmt = f"{pd_med:.2f}", f"{n_med:.2f}"
        else:
            name, fmt = f, f"{x:.3f}"
            pd_fmt, n_fmt = f"{pd_med:.3f}", f"{n_med:.3f}"
        return name, fmt, pd_fmt, n_fmt

    # 1) 'ëª…í™•íˆ' ë” ê°€ê¹Œìš´ ê·¼ê±°(ë°©í–¥ í¬í•¨)
    for _, strength, closeness_pd, f, x, pd_med, n_med in scored:
        name, fmt, pd_fmt, n_fmt = _fmt(f, x, pd_med, n_med)

        if strength > 0 and len(reasons_pd_strict) < topk:
            reasons_pd_strict.append(f"{name}ê°€ {fmt}ë¡œ **ì •ìƒ ì¤‘ì•™ê°’({n_fmt})ë³´ë‹¤ PD ì¤‘ì•™ê°’({pd_fmt})ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤**.")
        elif strength < 0 and len(reasons_n) < topk:
            reasons_n.append(f"{name}ê°€ {fmt}ë¡œ **PD ì¤‘ì•™ê°’({pd_fmt})ë³´ë‹¤ ì •ìƒ ì¤‘ì•™ê°’({n_fmt})ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤**.")

        if len(reasons_pd_strict) >= topk and len(reasons_n) >= topk:
            break

    # 2) ê²½ê³„ìš©: PD ì¤‘ì•™ê°’ 'ê·¼ì ‘ë„' ìƒìœ„ í•­ëª©(ë°©í–¥ ë¬´ê´€)
    scored_by_pd = sorted(scored, reverse=True, key=lambda t: t[2])
    for _, strength, closeness_pd, f, x, pd_med, n_med in scored_by_pd:
        if len(reasons_pd_closest) >= topk:
            break
        name, fmt, pd_fmt, n_fmt = _fmt(f, x, pd_med, n_med)
        reasons_pd_closest.append(
            f"{name}ê°€ {fmt}ì´ë©°, **PD ì¤‘ì•™ê°’({pd_fmt})ê³¼ì˜ ê±°ë¦¬ê°€ ë¹„êµì  ê°€ê¹ìŠµë‹ˆë‹¤**(ì •ìƒ ì¤‘ì•™ê°’ {n_fmt})."
        )

    return reasons_n[:topk], reasons_pd_strict[:topk], reasons_pd_closest[:topk]


# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="íŒŒí‚¨ìŠ¨ë³‘ í™˜ì í•˜ìœ„ìœ í˜• ë¶„ë¥˜ í”„ë¡œê·¸ë¨", layout="wide")


# ==========================================
# [ì„¤ëª…(ì´ìœ ) ìë™ ìƒì„±: ìƒìœ„ ê¸°ì—¬ ë³€ìˆ˜ TOP-K]
# - ê·œì¹™ ê¸°ë°˜ ì„¤ëª…ì´ ë¹„ì–´ìˆì„ ë•Œ, ëª¨ë¸ì˜ ì„ í˜• ê¸°ì—¬ë„(í‘œì¤€í™”ëœ ê°’ Ã— ê³„ìˆ˜)ë¥¼ ì´ìš©í•´
#   'ì™œ ê·¸ë ‡ê²Œ ë‚˜ì™”ëŠ”ì§€'ë¥¼ ìµœì†Œ 3ê°œ í•­ëª©ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
# - ì„œë¹„ìŠ¤ ì•ˆì •ì„± ëª©ì : ê³¼ë„í•œ ë‹¨ì • ëŒ€ì‹  'ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ' í‘œí˜„í•©ë‹ˆë‹¤.
# ==========================================

FEAT_LABELS_STEP1 = {
    "F0": "í‰ê·  ìŒë„(F0)",
    "Range": "ìŒë„ ë²”ìœ„(range)",
    "Intensity": "í‰ê·  ìŒì„± ê°•ë„(dB)",
    "SPS": "ë§ì†ë„(SPS)",
    "Sex": "ì„±ë³„"
}

FEAT_LABELS_STEP2 = {
    "Intensity": "í‰ê·  ìŒì„± ê°•ë„(dB)",
    "SPS": "ë§ì†ë„(SPS)",
    "P_Loudness": "ê°•ë„(ì²­ì§€ê°)",
    "P_Rate": "ë§ì†ë„(ì²­ì§€ê°)",
    "P_Artic": "ì¡°ìŒì •í™•ë„(ì²­ì§€ê°)"
}

def _get_pipeline_parts(pipeline):
    """Return (imputer, scaler, estimator) if present, else (None, None, pipeline)."""
    imputer = None
    scaler = None
    est = pipeline
    try:
        # sklearn Pipeline
        if hasattr(pipeline, "named_steps"):
            steps = pipeline.named_steps
            # common estimator step names we might use
            for key in ("clf", "logit", "lr", "lda", "qda", "model"):
                if key in steps:
                    est = steps[key]
                    break
            else:
                # fallback: last step
                est = list(steps.values())[-1]
            imputer = steps.get("imputer")
            scaler = steps.get("scaler")
    except Exception:
        pass
    return imputer, scaler, est

def top_contrib_linear_binary(pipeline, x_row, feat_names, pos_label="Parkinson", topk=3):
    """Return (pos_reasons, neg_reasons) from linear contributions for binary classifier.
    x_row: 1D array-like of raw features in feat_names order.
    """
    imputer, scaler, est = _get_pipeline_parts(pipeline)
    X = np.asarray(x_row, dtype=float).reshape(1, -1)
    if imputer is not None:
        X = imputer.transform(X)
    if scaler is not None:
        Xs = scaler.transform(X)
    else:
        Xs = X

    # determine which row of coef corresponds to pos_label
    classes = list(getattr(est, "classes_", []))
    coef = getattr(est, "coef_", None)
    if coef is None or len(coef) == 0:
        return [], []

    if len(classes) == 2 and coef.shape[0] == 1:
        # sklearn binary logistic: coef_ is (1, n_features) for classes_[1]
        pos_is_class1 = (len(classes) > 1 and classes[1] == pos_label)
        w = coef[0]
        contrib = Xs[0] * (w if pos_is_class1 else -w)
    else:
        # multi-output-like: fall back
        w = coef[0]
        contrib = Xs[0] * w

    # top contributors toward pos (positive contrib) and toward neg (negative contrib)
    idx_sorted = np.argsort(np.abs(contrib))[::-1]
    pos, neg = [], []
    for i in idx_sorted:
        name = feat_names[i]
        label = FEAT_LABELS_STEP1.get(name, FEAT_LABELS_STEP2.get(name, name))
        val = float(np.asarray(x_row, dtype=float)[i]) if np.isfinite(np.asarray(x_row, dtype=float)[i]) else None
        if contrib[i] >= 0 and len(pos) < topk:
            pos.append(f"{label}ì´(ê°€) ëª¨ë¸ì—ì„œ PD í™•ë¥ ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤" + (f" (ì…ë ¥: {val:.2f})" if val is not None else ""))
        elif contrib[i] < 0 and len(neg) < topk:
            neg.append(f"{label}ì´(ê°€) ëª¨ë¸ì—ì„œ ì •ìƒ í™•ë¥ ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤" + (f" (ì…ë ¥: {val:.2f})" if val is not None else ""))
        if len(pos) >= topk and len(neg) >= topk:
            break
    return pos, neg

def top_contrib_linear_multiclass(pipeline, x_row, feat_names, pred_class, topk=3):
    """Return reasons for predicted class for linear multiclass estimator (LDA)."""
    imputer, scaler, est = _get_pipeline_parts(pipeline)
    X = np.asarray(x_row, dtype=float).reshape(1, -1)
    if imputer is not None:
        X = imputer.transform(X)
    if scaler is not None:
        Xs = scaler.transform(X)
    else:
        Xs = X

    classes = list(getattr(est, "classes_", []))
    coef = getattr(est, "coef_", None)
    if coef is None or len(classes) == 0:
        return []

    try:
        cidx = classes.index(pred_class)
    except ValueError:
        cidx = int(np.argmax(getattr(est, "predict_proba", lambda z: np.zeros((1,len(classes))))(Xs)[0])) if len(classes) else 0

    w = coef[cidx] if coef.ndim == 2 else coef
    contrib = Xs[0] * w
    idx_sorted = np.argsort(np.abs(contrib))[::-1][:topk]
    reasons = []
    for i in idx_sorted:
        name = feat_names[i]
        label = FEAT_LABELS_STEP2.get(name, FEAT_LABELS_STEP1.get(name, name))
        val = float(np.asarray(x_row, dtype=float)[i]) if np.isfinite(np.asarray(x_row, dtype=float)[i]) else None
        reasons.append(f"{label}ì´(ê°€) ì´ ì§‘ë‹¨ íŒì •ì— í¬ê²Œ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤" + (f" (ì…ë ¥: {val:.2f})" if val is not None else ""))
    return reasons

# ==========================================
# [ì„¤ì •] êµ¬ê¸€ ì‹œíŠ¸ ì •ë³´ (Secrets)
# ==========================================
HAS_GCP_SECRETS = True
try:
    SHEET_NAME = st.secrets["gcp_info"]["sheet_name"]
except:
    st.warning("âš ï¸ Secrets ì„¤ì •ì´ ì—†ì–´ êµ¬ê¸€ì‹œíŠ¸/ì´ë©”ì¼ ì „ì†¡ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. (SQLite ì €ì¥ì€ ì‚¬ìš© ê°€ëŠ¥)")
    SHEET_NAME = None
    HAS_GCP_SECRETS = False

# ==========================================
# [ì „ì—­ ì„¤ì •] í°íŠ¸ ë° ë³€ìˆ˜
# ==========================================
FEATS_STEP1 = ['F0', 'Range', 'Intensity', 'SPS', 'Sex']  # Step1 íŒì •ì—ëŠ” VHIë¥¼ í¬í•¨í•˜ì§€ ì•Šê³ (ì°¸ê³  ì§€í‘œë¡œë§Œ ì‚¬ìš©)
# Step2ëŠ” PD í•˜ìœ„ì§‘ë‹¨ í‘œë³¸ì´ ì‘ì•„(íŠ¹íˆ ë§ì†ë„ ì§‘ë‹¨) ê³ ì°¨ì› íŠ¹ì„±ì— ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.
# ì„ìƒì ìœ¼ë¡œ êµ¬ë¶„ë ¥ì´ í° í•µì‹¬ ë³€ìˆ˜(ê°•ë„/ë§ì†ë„/ì¡°ìŒ)ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
FEATS_STEP2 = ['Intensity', 'SPS', 'P_Loudness', 'P_Rate', 'P_Artic']

# Step2 í•˜ìœ„ì§‘ë‹¨: Top1â€“Top2 ì°¨ì´ê°€ ì‘ìœ¼ë©´(í˜¼í•© íŒ¨í„´) í˜¼í•©í˜•ìœ¼ë¡œ í‘œì‹œ (ì„ìƒìš©)
MIX_MARGIN_P = 0.10  # 10%p
def sex_to_num(x):
    """ì„±ë³„ì„ ìˆ«ì featureë¡œ ë³€í™˜: ë‚¨/M=1.0, ì—¬/F=0.0, ê·¸ ì™¸/ê²°ì¸¡=0.5"""
    if x is None:
        return 0.5


# ==========================================
# [training_data ìœ„ì¹˜ íƒìƒ‰]
# - Streamlit Cloud/LinuxëŠ” ëŒ€ì†Œë¬¸ì êµ¬ë¶„ + ì‹¤í–‰ ê²½ë¡œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´
#   app.py(ì´ íŒŒì¼) ê¸°ì¤€ìœ¼ë¡œ training_data.*ë¥¼ ì°¾ë„ë¡ í•©ë‹ˆë‹¤.
# ==========================================
MODEL_LOAD_ERROR = ""

def get_training_file():
    base = Path(__file__).resolve().parent
    # ìš°ì„ ìˆœìœ„: xlsx > csv (ê°™ì€ í´ë”)
    candidates = [
        base / "training_data.xlsx",
        base / "training_data.csv",
        base / "Training_data.xlsx",
        base / "Training_data.csv",
        base / "TRAINING_DATA.xlsx",
        base / "TRAINING_DATA.csv",
    ]
    for p in candidates:
        if p.exists():
            return p

    # í˜¹ì‹œ í•˜ìœ„ í´ë”ì— ìˆì„ ê²½ìš°(ë§ˆì§€ë§‰ ì•ˆì „ì¥ì¹˜)
    for p in base.rglob("training_data.csv"):
        return p
    for p in base.rglob("training_data.xlsx"):
        return p
    return None

    s = str(x).strip().lower()
    if s in ["ë‚¨", "ë‚¨ì„±", "ë‚¨ì", "m", "male", "man", "1"]:
        return 1.0
    if s in ["ì—¬", "ì—¬ì„±", "ì—¬ì", "f", "female", "woman", "0", "2"]:
        return 0.0
    return 0.5


@st.cache_resource

def _youden_cutoff(y_true, scores):
    """Youden's J(ë¯¼ê°ë„+íŠ¹ì´ë„-1)ë¥¼ ìµœëŒ€í™”í•˜ëŠ” threshold ë°˜í™˜"""
    fpr, tpr, thr = roc_curve(y_true, scores)
    j = tpr - fpr
    bi = int(np.argmax(j))
    # sklearn roc_curveì˜ thrì—ëŠ” infê°€ ë“¤ì–´ê°ˆ ìˆ˜ ìˆì–´ ë°©ì–´
    cut = float(thr[bi]) if np.isfinite(thr[bi]) else 0.5
    sens = float(tpr[bi])
    spec = float(1.0 - fpr[bi])
    return cut, sens, spec


@st.cache_data
def compute_cutoffs_from_training(_file_mtime=None):
    """
    training_data.csv/xlsxë¡œë¶€í„° Step1/Step2 í™•ë¥  cut-offë¥¼ ìë™ ì‚°ì¶œ
    - ëˆ„ìˆ˜ ë°©ì§€: Leave-One-Out(LOO) OOF í™•ë¥ ë¡œ cut-off ì‚°ì •
    - Step1: ì´í•­ ë¡œì§€ìŠ¤í‹±(PD í™•ë¥ ) + Youden cut-off
    - Step2: (PD ë‚´ë¶€) ì •ê·œí™” QDA(reg_param) í™•ë¥  + í´ë˜ìŠ¤ë³„(OVR) Youden cut-off
    """
    training_path = get_training_file()
    if training_path is None:
        global MODEL_LOAD_ERROR
        MODEL_LOAD_ERROR = "training_data.csv/xlsx íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. app.pyì™€ ê°™ì€ í´ë”(ë ˆí¬ ë£¨íŠ¸)ì— training_data.csvë¥¼ ë‘ê³  ì»¤ë°‹í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        return None

    target_file = training_path

    loaders = [
        (lambda f: pd.read_excel(f), "excel"),
        (lambda f: pd.read_csv(f, encoding='utf-8'), "utf-8"),
        (lambda f: pd.read_csv(f, encoding='cp949'), "cp949"),
        (lambda f: pd.read_csv(f, encoding='euc-kr'), "euc-kr")
    ]
    df_raw = None
    for loader, _ in loaders:
        try:
            df_raw = loader(target_file)
            if df_raw is not None and not df_raw.empty:
                break
        except Exception:
            continue
    if df_raw is None or df_raw.empty:
        return None

    # --- ë¡œìš° íŒŒì‹± ---
    data_list = []
    for _, row in df_raw.iterrows():
        label = str(row.get('ì§„ë‹¨ê²°ê³¼ (Label)', 'Normal')).strip()
        l = label.lower()
        if 'normal' in l:
            diagnosis, subgroup = "Normal", "Normal"
        elif 'pd_intensity' in l:
            diagnosis, subgroup = "Parkinson", "ê°•ë„ ì§‘ë‹¨"
        elif 'pd_rate' in l:
            diagnosis, subgroup = "Parkinson", "ë§ì†ë„ ì§‘ë‹¨"
        elif 'pd_articulation' in l:
            diagnosis, subgroup = "Parkinson", "ì¡°ìŒ ì§‘ë‹¨"
        else:
            continue

        raw_total = pd.to_numeric(row.get('VHIì´ì ', 0), errors="coerce")
        raw_p = pd.to_numeric(row.get('VHI_ì‹ ì²´', 0), errors="coerce")
        raw_f = pd.to_numeric(row.get('VHI_ê¸°ëŠ¥', 0), errors="coerce")
        raw_e = pd.to_numeric(row.get('VHI_ì •ì„œ', 0), errors="coerce")
        raw_total = float(0 if pd.isna(raw_total) else raw_total)
        raw_p = float(0 if pd.isna(raw_p) else raw_p)
        raw_f = float(0 if pd.isna(raw_f) else raw_f)
        raw_e = float(0 if pd.isna(raw_e) else raw_e)

        # VHIëŠ” UIì—ì„œ VHI-10(0~40) ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ë˜ë¯€ë¡œ,
        # training_dataì˜ VHI-30(ì´ì  0~120, í•˜ìœ„ì²™ë„ 0~40)ì„ VHI-10 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # UIì—ì„œ ê³„ì‚°í•˜ëŠ” ë¶„í•´(ê¸°ëŠ¥ 0~20 / ì‹ ì²´ 0~12 / ì •ì„œ 0~8)ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¥ë‹ˆë‹¤.
        if raw_total <= 40 and raw_f <= 20 and raw_p <= 12 and raw_e <= 8:
            vhi_total, vhi_p, vhi_f, vhi_e = raw_total, raw_p, raw_f, raw_e
        else:
            vhi_f = (raw_f / 40.0) * 20.0
            vhi_p = (raw_p / 40.0) * 12.0
            vhi_e = (raw_e / 40.0) * 8.0
            vhi_total = vhi_f + vhi_p + vhi_e

        sex_num = sex_to_num(row.get('ì„±ë³„', None))

        data_list.append([
            row.get('F0', 0), row.get('Range', 0), row.get('ê°•ë„(dB)', 0), row.get('SPS', 0),
            vhi_total, vhi_p, vhi_f, vhi_e, sex_num,
            row.get('ìŒë„(ì²­ì§€ê°)', 0), row.get('ìŒë„ë²”ìœ„(ì²­ì§€ê°)', 0), row.get('ê°•ë„(ì²­ì§€ê°)', 0),
            row.get('ë§ì†ë„(ì²­ì§€ê°)', 0), row.get('ì¡°ìŒì •í™•ë„(ì²­ì§€ê°)', 0),
            diagnosis, subgroup
        ])

    df = pd.DataFrame(data_list, columns=FEATS_STEP2 + ['Diagnosis', 'Subgroup'])

    # ìˆ«ì ë³€í™˜/ê²°ì¸¡ ì²˜ë¦¬
    for col in FEATS_STEP2:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    # ìŒí–¥/ì²­ì§€ê°ì€ í‰ê· ìœ¼ë¡œ, VHIëŠ” 0ìœ¼ë¡œ(ì…ë ¥ ëˆ„ë½ ëŒ€ë¹„)
    for col in ['F0', 'Range', 'Intensity', 'SPS',
                'P_Pitch', 'P_Range', 'P_Loudness', 'P_Rate', 'P_Artic', 'Sex']:
        if col in df.columns:
            df[col] = df[col].fillna(df[col].mean())
    for col in ['VHI_Total', 'VHI_P', 'VHI_F', 'VHI_E']:
        if col in df.columns:
            df[col] = df[col].fillna(0.0)

    # ---------- Step1: Normal vs PD cut-off (LOO OOF) ----------
    X1 = df[FEATS_STEP1].copy().to_numpy()
    y1 = df["Diagnosis"].astype(str).values

    loo = LeaveOneOut()
    oof_pd = np.zeros(len(df), dtype=float)

    pipe1 = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(
            solver="lbfgs",
            max_iter=5000,
            class_weight="balanced",
            random_state=42
        ))
    ])

    for tr, te in loo.split(X1, y1):
        pipe1.fit(X1.iloc[tr], df['Diagnosis'].iloc[tr].astype(str).values)
        proba = pipe1.predict_proba(X1.iloc[te])[0]
        cls = pipe1.named_steps['clf'].classes_
        pd_idx = int(np.where(cls == 'Parkinson')[0][0]) if 'Parkinson' in cls else -1
        oof_pd[te[0]] = float(proba[pd_idx]) if pd_idx >= 0 else float(proba[-1])

    y1_bin = (y1 == 'Parkinson').astype(int)
    step1_cutoff, step1_sens, step1_spec = _youden_cutoff(y1_bin, oof_pd)

    # ---------- Step2: PD ë‚´ë¶€ 3ì§‘ë‹¨ cut-off (í´ë˜ìŠ¤ë³„ OVR, LOO OOF) ----------
    df_pd = df[df["Diagnosis"] == "Parkinson"].copy()
    cutoff_by_class = {}
    step2_report = None

    if len(df_pd) >= 3:
        X2 = df_pd[FEATS_STEP2].copy().to_numpy()
        y2 = df_pd["Subgroup"].astype(str).values
        classes = np.unique(y2)
        class_to_idx = {c: i for i, c in enumerate(classes)}

        oof2 = np.zeros((len(df_pd), len(classes)), dtype=float)

        pipe2 = Pipeline([
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler()),
            ("clf", LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'))
        ])

        for tr, te in loo.split(X2, y2):
            # í˜¹ì‹œë¼ë„ íŠ¹ì • foldì—ì„œ í•œ í´ë˜ìŠ¤ê°€ ì‚¬ë¼ì§ˆ ê²½ìš°ë¥¼ ëŒ€ë¹„(í˜„ ë°ì´í„°ì—ì„œëŠ” ê±°ì˜ ì—†ìŒ)
            y_tr = y2[tr]
            if len(np.unique(y_tr)) < 2:
                continue
            pipe2.fit(X2.iloc[tr], y_tr)
            proba = pipe2.predict_proba(X2.iloc[te])[0]
            fold_classes = pipe2.named_steps["clf"].classes_
            for j, c in enumerate(fold_classes):
                oof2[te[0], class_to_idx[c]] = float(proba[j])

        # í´ë˜ìŠ¤ë³„ OVR Youden cut-off
        for c in classes:
            y_bin = (y2 == c).astype(int)
            p = oof2[:, class_to_idx[c]]
            if np.all(y_bin == 0) or np.all(y_bin == 1):
                cutoff_by_class[c] = 0.5
                continue
            cut, _, _ = _youden_cutoff(y_bin, p)
            cutoff_by_class[c] = float(cut)

        # ì°¸ê³ ìš©: LOO ê¸°ì¤€ í˜¼ë™í–‰ë ¬(ë‹¨ìˆœ argmax)
        y_pred = [classes[int(np.argmax(oof2[i]))] for i in range(len(df_pd))]
        step2_cm = confusion_matrix(y2, y_pred, labels=list(classes))
        step2_report = {"classes": list(classes), "confusion_matrix": step2_cm.tolist()}

    # Step1 í˜¼ë™í–‰ë ¬(í™•ë¥  cut-off ì ìš©)
    y_pred1 = (oof_pd >= step1_cutoff).astype(int)
    step1_cm = confusion_matrix(y1, y_pred1, labels=[0, 1])  # 0=Normal,1=PD

    return {
        "step1_cutoff": float(step1_cutoff),
        "step1_sensitivity": float(step1_sens),
        "step1_specificity": float(step1_spec),
        "step1_confusion_matrix": step1_cm.tolist(),
        "step2_cutoff_by_class": cutoff_by_class,
        "step2_report": step2_report
    }


# ==========================================
# [SQLite ì €ì¥] Secretsê°€ ì—†ì–´ë„ ì €ì¥ ê°€ëŠ¥í•œ ë¡œì»¬ DB
# ==========================================
DB_PATH = os.environ.get("PD_TOOL_DB_PATH", "pd_tool.db")

@st.cache_resource
def _db_conn():
    conn = sqlite3.connect(Path(DB_PATH).as_posix(), check_same_thread=False, timeout=30)
    try:
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.execute("PRAGMA synchronous=NORMAL;")
    except Exception:
        pass
    conn.execute("""
        CREATE TABLE IF NOT EXISTS analyses (
            analysis_id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TEXT NOT NULL,
            subject_name TEXT,
            subject_age INTEGER,
            subject_gender TEXT,
            wav_filename TEXT,
            wav_sha256 TEXT,
            f0 REAL, pitch_range REAL, intensity_db REAL, sps REAL,
            vhi_total REAL, vhi_p REAL, vhi_f REAL, vhi_e REAL,
            p_pitch REAL, p_prange REAL, p_loud REAL, p_rate REAL, p_artic REAL,
            step1_p_pd REAL, step1_p_normal REAL, step1_cutoff REAL,
            final_decision TEXT, normal_prob REAL
        );
    """)
    conn.commit()
    return conn

def _sha256_file(path: str) -> str:
    try:
        h = hashlib.sha256()
        with open(path, "rb") as f:
            for chunk in iter(lambda: f.read(1024 * 1024), b""):
                h.update(chunk)
        return h.hexdigest()
    except Exception:
        return ""

def save_to_sqlite(wav_path: str, patient_info: dict, analysis: dict, diagnosis: dict, step1_meta: dict):
    conn = _db_conn()
    now = datetime.datetime.now().isoformat(timespec="seconds")
    wav_filename = os.path.basename(wav_path) if wav_path else None
    wav_sha = _sha256_file(wav_path) if wav_path else ""
    conn.execute(
        """INSERT INTO analyses(
            created_at, subject_name, subject_age, subject_gender,
            wav_filename, wav_sha256,
            f0, pitch_range, intensity_db, sps,
            vhi_total, vhi_p, vhi_f, vhi_e,
            p_pitch, p_prange, p_loud, p_rate, p_artic,
            step1_p_pd, step1_p_normal, step1_cutoff,
            final_decision, normal_prob
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);""",
        (
            now,
            str(patient_info.get("name","")).strip() or None,
            int(patient_info.get("age")) if str(patient_info.get("age","")).strip() != "" else None,
            str(patient_info.get("gender","")).strip() or None,
            wav_filename, wav_sha,
            float(analysis.get("f0",0.0)), float(analysis.get("range",0.0)), float(analysis.get("db",0.0)), float(analysis.get("sps",0.0)),
            float(analysis.get("vhi_total",0.0)), float(analysis.get("vhi_p",0.0)), float(analysis.get("vhi_f",0.0)), float(analysis.get("vhi_e",0.0)),
            float(analysis.get("p_pitch",0.0)), float(analysis.get("p_prange",0.0)), float(analysis.get("p_loud",0.0)), float(analysis.get("p_rate",0.0)), float(analysis.get("p_artic",0.0)),
            float(step1_meta.get("p_pd",0.0)), float(step1_meta.get("p_normal",0.0)), float(step1_meta.get("cutoff",0.5)),
            str(diagnosis.get("final","")), float(diagnosis.get("normal_prob",0.0))
        )
    )
    conn.commit()

def setup_korean_font():
    system_name = platform.system()
    if system_name == 'Windows':
        try:
            plt.rc('font', family='Malgun Gothic')
        except: pass
    elif system_name == 'Darwin': 
        plt.rc('font', family='AppleGothic')
    else: 
        plt.rc('font', family='NanumGothic')
    plt.rcParams['axes.unicode_minus'] = False

setup_korean_font()

# ==========================================
# 0. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
# ==========================================

@st.cache_resource
def train_models():
    """training_dataë¡œ Step1/Step2 ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."""
    global MODEL_LOAD_ERROR

    training_path = get_training_file()
    if training_path is None:
        MODEL_LOAD_ERROR = "training_data.csv/xlsx íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return None, None

    try:
        if str(training_path).lower().endswith(".xlsx"):
            raw = pd.read_excel(training_path)
        else:
            raw = pd.read_csv(training_path, encoding="utf-8-sig")
    except Exception as e:
        MODEL_LOAD_ERROR = f"training_data ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}: {e}"
        return None, None

    if 'ì§„ë‹¨ê²°ê³¼ (Label)' not in raw.columns:
        MODEL_LOAD_ERROR = "training_dataì— 'ì§„ë‹¨ê²°ê³¼ (Label)' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
        return None, None

    def _label_to_diag_and_sub(lab: str):
        s = str(lab).strip().lower()
        if 'normal' in s:
            return "Normal", "Normal"
        if 'pd_intensity' in s:
            return "Parkinson", "ê°•ë„ ì§‘ë‹¨"
        if 'pd_rate' in s:
            return "Parkinson", "ë§ì†ë„ ì§‘ë‹¨"
        if 'pd_articulation' in s or 'pd_artic' in s:
            return "Parkinson", "ì¡°ìŒ ì§‘ë‹¨"
        return None, None

    # ---------- Step1 ----------
    X1_rows, y1 = [], []
    for _, row in raw.iterrows():
        diag, _sub = _label_to_diag_and_sub(row.get('ì§„ë‹¨ê²°ê³¼ (Label)', ''))
        if diag is None:
            continue

        raw_total = pd.to_numeric(row.get('VHIì´ì ', np.nan), errors="coerce")
        raw_p = pd.to_numeric(row.get('VHI_ì‹ ì²´', np.nan), errors="coerce")
        raw_f = pd.to_numeric(row.get('VHI_ê¸°ëŠ¥', np.nan), errors="coerce")
        raw_e = pd.to_numeric(row.get('VHI_ì •ì„œ', np.nan), errors="coerce")

        if (pd.notna(raw_total) and raw_total <= 40) and (pd.notna(raw_f) and raw_f <= 20) and (pd.notna(raw_p) and raw_p <= 12) and (pd.notna(raw_e) and raw_e <= 8):
            vhi_total, vhi_p, vhi_f, vhi_e = float(raw_total), float(raw_p), float(raw_f), float(raw_e)
        else:
            vhi_f = (0 if pd.isna(raw_f) else float(raw_f)) / 40.0 * 20.0
            vhi_p = (0 if pd.isna(raw_p) else float(raw_p)) / 40.0 * 12.0
            vhi_e = (0 if pd.isna(raw_e) else float(raw_e)) / 40.0 * 8.0
            vhi_total = vhi_f + vhi_p + vhi_e

        sex_num = sex_to_num(row.get('ì„±ë³„', None))

        X1_rows.append([
            row.get('F0', np.nan),
            row.get('Range', np.nan),
            row.get('ê°•ë„(dB)', np.nan),
            row.get('SPS', np.nan),
            sex_num
        ])
        y1.append(diag)

    X1 = np.array(X1_rows, dtype=float)
    y1 = np.array(y1, dtype=str)

    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.preprocessing import StandardScaler
    from sklearn.linear_model import LogisticRegression

    model_step1 = Pipeline([
        ("imp", SimpleImputer(strategy="median")),
        ("sc", StandardScaler()),
        ("clf", LogisticRegression(max_iter=4000, class_weight="balanced"))
    ])
    model_step1.fit(X1, y1)

    # ---------- Step2 (PD only) ----------
    X2_rows, y2 = [], []
    for _, row in raw.iterrows():
        diag, sub = _label_to_diag_and_sub(row.get('ì§„ë‹¨ê²°ê³¼ (Label)', ''))
        if diag != "Parkinson" or sub == "Normal":
            continue

        X2_rows.append([
            row.get('ê°•ë„(dB)', np.nan),              # Intensity
            row.get('SPS', np.nan),                   # SPS
            row.get('ê°•ë„(ì²­ì§€ê°)', np.nan),          # P_Loudness
            row.get('ë§ì†ë„(ì²­ì§€ê°)', np.nan),        # P_Rate
            row.get('ì¡°ìŒì •í™•ë„(ì²­ì§€ê°)', np.nan)     # P_Artic
        ])
        y2.append(sub)

    X2 = np.array(X2_rows, dtype=float)
    y2 = np.array(y2, dtype=object)

    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

    model_step2 = Pipeline([
        ("imp", SimpleImputer(strategy="median")),
        ("sc", StandardScaler()),
        ("clf", LinearDiscriminantAnalysis(solver="eigen", shrinkage="auto"))
    ])
    model_step2.fit(X2, y2)

    return model_step1, model_step2


try:
    model_step1, model_step2 = train_models()
except Exception as e:
    MODEL_LOAD_ERROR = f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜ˆì™¸: {type(e).__name__}: {e}"
    model_step1, model_step2 = None, None

# training_data ê¸°ë°˜ cut-off(í™•ë¥  ì„ê³„ê°’) ìë™ ì‚°ì¶œ
try:
    _tp = get_training_file()
    _mt = float(_tp.stat().st_mtime) if _tp is not None else None
    CUTS = compute_cutoffs_from_training(_mt)
except Exception:
    CUTS = None

# ==========================================
# [ì´ë©”ì¼ ì „ì†¡ í•¨ìˆ˜] íŒŒì¼ëª…: ì´ë¦„.wav
# ==========================================
def send_email_and_log_sheet(wav_path, patient_info, analysis, diagnosis):
    # Secretsê°€ ì—†ìœ¼ë©´(ë˜ëŠ” ì‹œíŠ¸ëª…ì´ ì—†ìœ¼ë©´) í´ë¼ìš°ë“œ ì „ì†¡ ëŒ€ì‹  SQLiteì— ì €ì¥
    if not globals().get("HAS_GCP_SECRETS", True) or (SHEET_NAME is None):
        try:
            step1_meta = st.session_state.get("save_ready_data", {}).get("step1_meta", st.session_state.get("step1_meta", {}))
        except Exception:
            step1_meta = {}
        try:
            save_to_sqlite(wav_path, patient_info, analysis, diagnosis, step1_meta)
            return True, "Secrets ë¯¸ì„¤ì •: êµ¬ê¸€ì‹œíŠ¸/ì´ë©”ì¼ ëŒ€ì‹  SQLiteì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return False, f"Secrets ë¯¸ì„¤ì • + SQLite ì €ì¥ ì‹¤íŒ¨: {e}"

    try:
        creds = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        )
        gc = gspread.authorize(creds)
        sh = gc.open(SHEET_NAME)
        worksheet = sh.sheet1
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = patient_info['name'].replace(" ", "")
        
        # êµ¬ê¸€ ì‹œíŠ¸ìš© íŒŒì¼ëª… (ìƒì„¸ ì •ë³´ í¬í•¨)
        log_filename = f"{safe_name}_{patient_info['age']}_{patient_info['gender']}_{timestamp}.wav"

        if not worksheet.row_values(1):
            worksheet.append_row([
                "Timestamp", "Filename", "Name", "Age", "Gender",
                "F0", "Range", "Intensity_dB", "SPS", 
                "VHI_Total", "VHI_P", "VHI_F", "VHI_E",
                "P_Artic", "P_Pitch", "P_Loud", "P_Rate", "P_PRange",
                "Final_Diagnosis", "Normal_Prob"
            ])
            
        row_data = [
            timestamp, log_filename,
            patient_info['name'], patient_info['age'], patient_info['gender'],
            analysis['f0'], analysis['range'], analysis['db'], analysis['sps'],
            analysis['vhi_total'], analysis['vhi_p'], analysis['vhi_f'], analysis['vhi_e'],
            analysis['p_artic'], analysis['p_pitch'], analysis['p_loud'], analysis['p_rate'], analysis['p_prange'],
            diagnosis['final'], diagnosis['normal_prob']
        ]
        worksheet.append_row(row_data)

        sender = st.secrets["email"]["sender"]
        password = st.secrets["email"]["password"]
        receiver = st.secrets["email"]["receiver"]

        msg = MIMEMultipart()
        msg['From'] = sender
        msg['To'] = receiver
        
        # [ìˆ˜ì •] ì´ë©”ì¼ ì²¨ë¶€ íŒŒì¼ëª…: ì´ë¦„.wav
        email_attach_name = f"{safe_name}.wav"
        msg['Subject'] = f"[PD Data] {email_attach_name}"

        body = f"""
        í™˜ì: {patient_info['name']} ({patient_info['age']}/{patient_info['gender']})
        ì§„ë‹¨: {diagnosis['final']} ({diagnosis['normal_prob']:.1f}%)
        
        * ìŒì„± íŒŒì¼ì´ ì²¨ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ({email_attach_name})
        * ìƒì„¸ ìˆ˜ì¹˜ëŠ” êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
        """
        msg.attach(MIMEText(body, 'plain'))

        with open(wav_path, "rb") as f:
            part = MIMEBase("audio", "wav")
            part.set_payload(f.read())
        
        encoders.encode_base64(part)
        # ì²¨ë¶€ íŒŒì¼ëª… ì„¤ì •
        part.add_header("Content-Disposition", f"attachment; filename={email_attach_name}")
        msg.attach(part)

        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender, password)
        server.sendmail(sender, receiver, msg.as_string())
        server.quit()

        # (ì„ íƒ) í´ë¼ìš°ë“œ ì „ì†¡ ì„±ê³µ ì‹œì—ë„ SQLiteì— ë¡œê·¸ ì €ì¥
        try:
            step1_meta = st.session_state.get("save_ready_data", {}).get("step1_meta", st.session_state.get("step1_meta", {}))
            save_to_sqlite(wav_path, patient_info, analysis, diagnosis, step1_meta)
            return True, "ë©”ì¼/ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ + SQLite ë¡œê·¸ ì €ì¥ ì™„ë£Œ"
        except Exception:
            return True, "ë©”ì¼ ì „ì†¡ ë° ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ"

    except Exception as e:
        return False, str(e)

# ==========================================
# [SMR ì¸¡ì • í•¨ìˆ˜]
# ==========================================
def auto_detect_smr_events(sound_path, top_n=20):
    try:
        sound = parselmouth.Sound(sound_path)
        intensity = sound.to_intensity(time_step=0.005)
        times = intensity.xs()
        values = intensity.values[0, :]
        inv_vals = -values
        peaks, properties = find_peaks(inv_vals, prominence=5, distance=40)
        candidates = []
        for p_idx in peaks:
            time_point = times[p_idx]
            v_int = values[p_idx]
            start_search = max(0, p_idx - 20)
            end_search = min(len(values), p_idx + 20)
            local_max = np.max(values[start_search:end_search])
            depth = local_max - v_int
            candidates.append({"time": time_point, "depth": depth})
        candidates.sort(key=lambda x: x['time'])
        return candidates, len(candidates)
    except:
        return [], 0

# ==========================================
# [ë¶„ì„ ë¡œì§] Median Ratio í•„í„°ë¡œ í™•ì‹¤í•œ ì˜¥íƒ€ë¸Œ ì œê±°
# ==========================================
def plot_pitch_contour_plotly(sound_path, f0_min, f0_max):
    try:
        sound = parselmouth.Sound(sound_path)
        pitch = call(sound, "To Pitch", 0.0, f0_min, f0_max)
        pitch_array = pitch.selected_array['frequency']
        pitch_values = np.array(pitch_array, dtype=np.float64)
        duration = sound.get_total_duration()
        n_points = len(pitch_values)
        time_array = np.linspace(0, duration, n_points)
        
        valid_indices = pitch_values != 0
        valid_times = time_array[valid_indices]
        valid_pitch = pitch_values[valid_indices]

        if len(valid_pitch) > 0:
            median_f0 = np.median(valid_pitch)
            lower_bound = median_f0 * 0.6
            upper_bound = median_f0 * 1.6
            
            clean_mask = (valid_pitch >= lower_bound) & (valid_pitch <= upper_bound)
            clean_p = valid_pitch[clean_mask]
            clean_t = valid_times[clean_mask]
            
            if len(clean_p) > 0:
                mean_f0 = np.mean(clean_p)
                rng = np.max(clean_p) - np.min(clean_p)
            else:
                mean_f0, rng = 0, 0
                clean_p, clean_t = [], []
        else:
            clean_p, clean_t = [], []
            mean_f0, rng = 0, 0

        fig = go.Figure()
        if len(clean_p) > 0:
            fig.add_trace(go.Scatter(x=clean_t, y=clean_p, mode='markers', marker=dict(size=4, color='red'), name='Pitch'))
            y_min = max(0, np.min(clean_p) - 20)
            y_max = np.max(clean_p) + 20
            fig.update_layout(title="ìŒë„ ì»¨íˆ¬ì–´ (ì´ìƒì¹˜ ì œê±°ë¨)", xaxis_title="Time(s)", yaxis_title="Hz", height=300, yaxis=dict(range=[y_min, y_max]))
        else:
            fig.update_layout(title="ìŒë„ ì»¨íˆ¬ì–´ (ê°ì§€ëœ ìŒì„± ì—†ìŒ)", height=300)

        return fig, mean_f0, rng, duration
    except: return None, 0, 0, 0

def run_analysis_logic(file_path):
    try:
        fig, f0, rng, dur = plot_pitch_contour_plotly(file_path, 70, 500)
        sound = parselmouth.Sound(file_path)
        intensity = sound.to_intensity()
        mean_db = call(intensity, "Get mean", 0, 0, "energy")
        sps = st.session_state.user_syllables / dur if dur > 0 else 0
        smr_events, smr_count = auto_detect_smr_events(file_path)
        
        st.session_state.update({
            'f0_mean': f0, 'pitch_range': rng, 'mean_db': mean_db, 
            'sps': sps, 'duration': dur, 'fig_plotly': fig, 
            'smr_events': smr_events, 'smr_count': smr_count,
            'is_analyzed': True, 'is_saved': False
        })
        return True
    except Exception as e:
        st.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}"); return False

def generate_interpretation(prob_normal, db, sps, range_val, artic, vhi, vhi_e):
    positives, negatives = [], []
    if vhi < 15: positives.append(f"í™˜ì ë³¸ì¸ì˜ ì£¼ê´€ì  ë¶ˆí¸í•¨(VHI {vhi}ì )ì´ ë‚®ì•„, ì¼ìƒ ëŒ€í™”ì— ì‹¬ë¦¬ì /ê¸°ëŠ¥ì  ë¶€ë‹´ì´ ì ì€ ìƒíƒœì…ë‹ˆë‹¤.")
    if range_val >= 100: positives.append(f"ìŒë„ ë²”ìœ„ê°€ {range_val:.1f}Hzë¡œ ë„“ê²Œ ë‚˜íƒ€ë‚˜, ëª©ì†Œë¦¬ì— ìƒë™ê°ì´ ìˆê³  ì–µì–‘ì˜ ë³€í™”ê°€ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.")
    if artic >= 75: positives.append(f"ì²­ì§€ê°ì  ì¡°ìŒ ì •í™•ë„ê°€ {artic}ì ìœ¼ë¡œ ì–‘í˜¸í•˜ì—¬, ìƒëŒ€ë°©ì´ ë§ì„ ì•Œì•„ë“£ê¸°ì— ëª…ë£Œí•œ ìƒíƒœì…ë‹ˆë‹¤.")
    if sps < 4.5: positives.append(f"ë§ì†ë„ê°€ {sps:.2f} SPSë¡œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤. íŒŒí‚¨ìŠ¨ë³‘ì—ì„œ í”íˆ ë‚˜íƒ€ë‚˜ëŠ” ê¸‰ê²©í•œ ê°€ì† í˜„ìƒ(Festination) ì—†ì´ ì•ˆì •ì ì¸ ì†ë„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    if db >= 60: positives.append(f"í‰ê·  ìŒì„± ê°•ë„ê°€ {db:.1f} dBë¡œ, ì¼ë°˜ì ì¸ ëŒ€í™” ìˆ˜ì¤€(60dB ì´ìƒ)ì˜ ì„±ëŸ‰ì„ íŠ¼íŠ¼í•˜ê²Œ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

    if db < 60: negatives.append(f"í‰ê·  ìŒì„± ê°•ë„ê°€ {db:.1f} dBë¡œ ë‚®ê²Œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤(â€» ë§ˆì´í¬/ê±°ë¦¬/í™˜ê²½ì— ë”°ë¼ ì ˆëŒ€ê°’ì€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©°, ë³¸ ë„êµ¬ì˜ ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ ë‚®ì€ í¸ì…ë‹ˆë‹¤). ì´ëŠ” íŒŒí‚¨ìŠ¨ë³‘ì—ì„œ í”í•œ ê°•ë„ ê°ì†Œ(Hypophonia) íŒ¨í„´ê³¼ ìœ ì‚¬í•˜ì—¬ ë°œì„± í›ˆë ¨ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    if sps >= 4.5: negatives.append(f"ë§ì†ë„ê°€ {sps:.2f} SPSë¡œ ì§€ë‚˜ì¹˜ê²Œ ë¹ ë¦…ë‹ˆë‹¤. ì´ëŠ” ë°œí™” ì œì–´ê°€ ì–´ë ¤ì›Œ ë§ì´ ë¹ ë¥´ì§€ëŠ” ê°€ì† ì§•í›„(Short rushes of speech)ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
    if artic < 70: negatives.append(f"ì²­ì§€ê°ì  ì¡°ìŒ ì •í™•ë„ê°€ {artic}ì ìœ¼ë¡œ ë‹¤ì†Œ ë‚®ìŠµë‹ˆë‹¤. ë°œìŒì´ ë¶ˆë¶„ëª…í•´ì§€ëŠ” ì¡°ìŒ ì¥ì• (Dysarthria) ì§•í›„ê°€ ê´€ì°°ë©ë‹ˆë‹¤.")
    if vhi >= 20: negatives.append(f"VHI ì´ì ì´ {vhi}ì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤. í™˜ì ìŠ¤ìŠ¤ë¡œ ìŒì„± ë¬¸ì œë¡œ ì¸í•œ ìƒí™œì˜ ë¶ˆí¸í•¨ê³¼ ì‹¬ë¦¬ì  ìœ„ì¶•ì„ í¬ê²Œ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.")
    if vhi_e >= 5: negatives.append("íŠ¹íˆ VHI ì •ì„œ(E) ì ìˆ˜ê°€ ë†’ì•„, ë§í•˜ê¸°ì— ëŒ€í•œ ë¶ˆì•ˆê°ì´ë‚˜ ìì‹ ê° ì €í•˜ê°€ ê°ì§€ë©ë‹ˆë‹¤.")
    return positives, negatives

# --- UI Title ---
st.title("íŒŒí‚¨ìŠ¨ë³‘ í™˜ì í•˜ìœ„ìœ í˜• ë¶„ë¥˜ í”„ë¡œê·¸ë¨")
st.markdown("ì´ í”„ë¡œê·¸ë¨ì€ ì²­ì§€ê°ì  í‰ê°€, ìŒí–¥í•™ì  ë¶„ì„, ìê°€ë³´ê³ (VHI-10) ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ íŒŒí‚¨ìŠ¨ë³‘ í™˜ìì˜ ìŒì„± íŠ¹ì„±ì„ 3ê°€ì§€ í•˜ìœ„ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

# 1. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ‘¤ ëŒ€ìƒì ì •ë³´ (í•„ìˆ˜)")
    subject_name = st.text_input("ì´ë¦„ (ì‹¤ëª…/ID)", "ì°¸ì—¬ì")
    subject_age = st.number_input("ë‚˜ì´", 1, 120, 60)
    subject_gender = st.selectbox("ì„±ë³„", ["M", "F"])

# 2. ë°ì´í„° ìˆ˜ì§‘
st.header("1. ìŒì„± ë°ì´í„° ìˆ˜ì§‘")
if 'user_syllables' not in st.session_state: st.session_state.user_syllables = 80
if 'source_type' not in st.session_state: st.session_state.source_type = None

col_rec, col_up = st.columns(2)
TEMP_FILENAME = "temp_for_analysis.wav"

with col_rec:
    st.markdown("#### ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ")
    font_size = st.slider("ğŸ” ê¸€ì í¬ê¸°", 15, 50, 28, key="fs_read")
    
    # ë¬¸ë‹¨ ì„ íƒ
    read_opt = st.radio("ğŸ“– ë‚­ë… ë¬¸ë‹¨ ì„ íƒ", ["1. ì‚°ì±… (ì¼ë°˜ìš© - 69ìŒì ˆ)", "2. ë°”ë‹·ê°€ì˜ ì¶”ì–µ (SMR/ì •ë°€ìš© - 80ìŒì ˆ)"])
    
    def styled_text(text, size): 
        return f"""<div style="font-size: {size}px; line-height: 1.8; border: 1px solid #ddd; padding: 15px; background-color: #f9f9f9; color: #333;">{text}</div>"""

    if "ë°”ë‹·ê°€" in read_opt:
        read_text = "ë°”ë‹·ê°€ì— íŒŒë„ê°€ ì¹©ë‹ˆë‹¤. ë¬´ì§€ê°œ ì•„ë˜ ë°”ë‘‘ì´ê°€ ëœë‹ˆë‹¤. ë³´íŠ¸ê°€ ì§€ë‚˜ê°€ê³  ë²„í„°êµ¬ì´ë¥¼ ë¨¹ìŠµë‹ˆë‹¤. í¬í† ì¹´ë“œë¥¼ ë¶€íƒí•´ì„œ ë‹ë³´ê¸°ë¡œ ë´…ë‹ˆë‹¤. ì‹œì¥ì—ì„œ ë¹ˆëŒ€ë–¡ì„ ì‚¬ ë¨¹ì—ˆìŠµë‹ˆë‹¤."
        default_syl = 80
    else:
        read_text = "ë†’ì€ ì‚°ì— ì˜¬ë¼ê°€ ë§‘ì€ ê³µê¸°ë¥¼ ë§ˆì‹œë©° ì†Œë¦¬ë¥¼ ì§€ë¥´ë©´ ê°€ìŠ´ì´ í™œì§ ì—´ë¦¬ëŠ” ë“¯í•˜ë‹¤. ë°”ë‹·ê°€ì— ë‚˜ê°€ ì¡°ê°œë¥¼ ì£¼ìœ¼ë©° ë„“ê²Œ í¼ì³ìˆëŠ” ë°”ë‹¤ë¥¼ ë°”ë¼ë³´ë©´ ë‚´ ë§ˆìŒ ì—­ì‹œ ë„“ì–´ì§€ëŠ” ê²ƒ ê°™ë‹¤."
        default_syl = 69
        
    st.markdown(styled_text(read_text, font_size), unsafe_allow_html=True)
    
    # ìŒì ˆ ìˆ˜ ìë™ ë³€ê²½
    syllables_rec = st.number_input("ì „ì²´ ìŒì ˆ ìˆ˜", 1, 500, default_syl, key=f"syl_rec_{read_opt}")
    st.session_state.user_syllables = syllables_rec
    
    audio_buf = st.audio_input("ë‚­ë… ë…¹ìŒ")
    if st.button("ğŸ™ï¸ ë…¹ìŒëœ ìŒì„± ë¶„ì„"):
        if audio_buf:
            with open(TEMP_FILENAME, "wb") as f: f.write(audio_buf.read())
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            run_analysis_logic(st.session_state.current_wav_path)
        else: st.warning("ë…¹ìŒë¶€í„° í•´ì£¼ì„¸ìš”.")

with col_up:
    st.markdown("#### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    up_file = st.file_uploader("WAV íŒŒì¼ ì„ íƒ", type=["wav"])
    if up_file: st.audio(up_file, format='audio/wav')
    if st.button("ğŸ“‚ ì—…ë¡œë“œ íŒŒì¼ ë¶„ì„"):
        if up_file:
            with open(TEMP_FILENAME, "wb") as f: f.write(up_file.read())
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            run_analysis_logic(st.session_state.current_wav_path)
        else: st.warning("íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# 3. ê²°ê³¼ ë° ì €ì¥
if st.session_state.get('is_analyzed'):
    st.markdown("---")
    st.subheader("2. ë¶„ì„ ê²°ê³¼ ë° ë³´ì •")
    
    c1, c2 = st.columns([2, 1])
    
    with c1: 
        st.plotly_chart(st.session_state['fig_plotly'], use_container_width=True)
    
    with c2:
        # ê°•ë„(dB) ë³´ì •: ê¸°ë³¸ê°’ -5 dB(ê¶Œì¥). í•„ìš” ì‹œ ì„ìƒê°€ê°€ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ ìŠ¬ë¼ì´ë”ëŠ” ìœ ì§€í•©ë‹ˆë‹¤.
        INTENSITY_CORR_DB_DEFAULT = -5.0
        lock_db = st.checkbox("ê°•ë„ ë³´ì • ê³ ì •(-5 dB) ì‚¬ìš©(ê¶Œì¥)", value=True, key="lock_db_corr",
                             help="ì„œë¹„ìŠ¤ ê¸°ë³¸ê°’ì€ -5 dB ê³ ì •ì…ë‹ˆë‹¤. ì„ìƒì ìœ¼ë¡œ í•„ìš”í•  ë•Œë§Œ í•´ì œí•˜ì—¬ ì¡°ì •í•˜ì„¸ìš”.")
        db_adj = st.slider("ê°•ë„(dB) ë³´ì •", -50.0, 50.0, INTENSITY_CORR_DB_DEFAULT, 0.5, disabled=lock_db,
                           help="ë§ˆì´í¬/í™˜ê²½ì— ë”°ë¼ dBê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ì€ -5 dB ê³ ì •(ê¶Œì¥)ì´ë©°, í•´ì œ ì‹œ ìˆ˜ë™ ì¡°ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        if lock_db:
            db_adj = INTENSITY_CORR_DB_DEFAULT
        final_db = st.session_state['mean_db'] + db_adj
        
        range_adj = st.slider("ìŒë„ë²”ìœ„(Hz) ë³´ì •", 0.0, 300.0, float(st.session_state['pitch_range']))
        s_time, e_time = st.slider("ë§ì†ë„ êµ¬ê°„(ì´ˆ)", 0.0, st.session_state['duration'], (0.0, st.session_state['duration']), 0.01)
        sel_dur = max(0.1, e_time - s_time)
        final_sps = st.session_state.user_syllables / sel_dur
        
        st.write("#### ğŸ“Š ìŒí–¥í•™ì  ë¶„ì„ ê²°ê³¼")
        result_df = pd.DataFrame({
            "í•­ëª©": ["í‰ê·  ê°•ë„(dB)", "í‰ê·  ìŒë„(Hz)", "ìŒë„ ë²”ìœ„(Hz)", "ë§ì†ë„(SPS)"],
            "ìˆ˜ì¹˜": [f"{final_db:.2f}", f"{st.session_state['f0_mean']:.2f}", f"{range_adj:.2f}", f"{final_sps:.2f}"]
        })
        st.dataframe(result_df, hide_index=True)

    st.markdown("---")
    if st.session_state.get('smr_events'):
        st.markdown("##### ğŸ” SMR ìë™ ë¶„ì„ (ë‹¨ì–´ ë§¤ì¹­)")
        events = st.session_state['smr_events']
        smr_df_data = {}
        words = ["ë°”ë‹·ê°€", "íŒŒë„ê°€", "ë¬´ì§€ê°œ", "ë°”ë‘‘ì´", "ë³´íŠ¸ê°€", "ë²„í„°êµ¬ì´", "í¬í† ì¹´ë“œ", "ë¶€íƒí•´", "ë‹ë³´ê¸°", "ë¹ˆëŒ€ë–¡"]
        
        for i, word in enumerate(words):
            if i < len(events):
                ev = events[i]
                status = "ğŸŸ¢ ì–‘í˜¸" if ev['depth'] >= 20 else ("ğŸŸ¡ ì£¼ì˜" if ev['depth'] >= 15 else "ğŸ”´ ë¶ˆëŸ‰")
                val = f"{ev['depth']:.1f}dB\n{status}"
            else:
                val = "ë¯¸ê°ì§€"
            smr_df_data[word] = [val]
        
        st.dataframe(pd.DataFrame(smr_df_data), use_container_width=True)

    st.markdown("---")
    st.subheader("3. ì²­ì§€ê° ë° VHI-10 ì…ë ¥")
    cc1, cc2 = st.columns([1, 1.2])
    with cc1:
        st.markdown("#### ğŸ”Š ì²­ì§€ê° í‰ê°€")
        p_artic = st.slider("ì¡°ìŒ ì •í™•ë„", 0, 100, 50)
        p_pitch = st.slider("ìŒë„", 0, 100, 50)
        p_prange = st.slider("ìŒë„ ë²”ìœ„", 0, 100, 50)
        p_loud = st.slider("ê°•ë„", 0, 100, 50)
        p_rate = st.slider("ë§ì†ë„", 0, 100, 50)
    with cc2:
        st.markdown("#### ğŸ“ VHI-10")
        vhi_opts = [0, 1, 2, 3, 4]
        
        with st.expander("VHI-10 ë¬¸í•­ ì…ë ¥ (í´ë¦­í•´ì„œ í¼ì¹˜ê¸°)", expanded=True):
            q1 = st.select_slider("1. ì‚¬ëŒë“¤ì´ ë‚´ ëª©ì†Œë¦¬ë¥¼ ë“£ëŠ”ë° ì–´ë ¤ì›€ì„ ëŠë‚€ë‹¤.", options=vhi_opts)
            q2 = st.select_slider("2. ì‚¬ëŒë“¤ì´ ë‚´ ë§ì„ ì˜ ëª» ì•Œì•„ë“¤ì–´ ë°˜ë³µí•´ì•¼ í•œë‹¤.", options=vhi_opts)
            q3 = st.select_slider("3. ë‚¯ì„  ì‚¬ëŒë“¤ê³¼ ì „í™”ë¡œ ëŒ€í™”í•˜ëŠ” ê²ƒì´ ì–´ë µë‹¤.", options=vhi_opts)
            q4 = st.select_slider("4. ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ì¸í•´ ê¸´ì¥ëœë‹¤.", options=vhi_opts)
            q5 = st.select_slider("5. ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ì¸í•´ ì‚¬ëŒë“¤ì„ í”¼í•˜ê²Œ ëœë‹¤.", options=vhi_opts)
            q6 = st.select_slider("6. ë‚´ ëª©ì†Œë¦¬ ë•Œë¬¸ì— ì§œì¦ì´ ë‚œë‹¤.", options=vhi_opts)
            q7 = st.select_slider("7. ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ìˆ˜ì…ì— ì§€ì¥ì´ ìˆë‹¤.", options=vhi_opts)
            q8 = st.select_slider("8. ë‚´ ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ëŒ€í™”ê°€ ì œí•œëœë‹¤.", options=vhi_opts)
            q9 = st.select_slider("9. ë‚´ ëª©ì†Œë¦¬ ë•Œë¬¸ì— ì†Œì™¸ê°ì„ ëŠë‚€ë‹¤.", options=vhi_opts)
            q10 = st.select_slider("10. ëª©ì†Œë¦¬ë¥¼ ë‚´ëŠ” ê²ƒì´ í˜ë“¤ë‹¤.", options=vhi_opts)

        vhi_f = q1 + q2 + q5 + q7 + q8
        vhi_p = q3 + q4 + q6
        vhi_e = q9 + q10
        vhi_total = vhi_f + vhi_p + vhi_e
        
        st.markdown("##### ğŸ“Š ì˜ì—­ë³„ ì ìˆ˜")
        col_v1, col_v2, col_v3, col_v4 = st.columns(4)
        col_v1.metric("ì´ì ", f"{vhi_total}ì ")
        col_v2.metric("ê¸°ëŠ¥(F)", f"{vhi_f}ì ")
        col_v3.metric("ì‹ ì²´(P)", f"{vhi_p}ì ")
        col_v4.metric("ì •ì„œ(E)", f"{vhi_e}ì ")

    st.markdown("---")
    st.subheader("4. ìµœì¢… ì§„ë‹¨ ë° í´ë¼ìš°ë“œ ì „ì†¡")
    
    if st.button("ğŸš€ ì§„ë‹¨ ê²°ê³¼ í™•ì¸", key="btn_diag"):
        if model_step1:
            # ì„±ë³„ feature
            sex_num_ui = sex_to_num(subject_gender)

            # Step1: PD í™•ë¥  cut-off (training_data ê¸°ë°˜)
            pd_cut = 0.5
            if CUTS and isinstance(CUTS, dict) and "step1_cutoff" in CUTS and CUTS["step1_cutoff"] is not None:
                pd_cut = float(CUTS["step1_cutoff"])

            # ê¸°ë³¸ê°’(ì €ì¥ìš©)
            p_pd = 0.0
            p_norm = 1.0

            # ì¡°ìŒì •í™•ë„(p_artic) 78ì  ì´ìƒì´ë©´ Normalë¡œ ê°•ì œí•˜ë˜ ê·œì¹™ì€ ì œê±°í–ˆìŠµë‹ˆë‹¤.
            if False:  # (removed rule)
                pass
                
                
            else:
                input_1 = pd.DataFrame([[
                    st.session_state['f0_mean'], range_adj, final_db, final_sps,
                    sex_num_ui
                ]], columns=FEATS_STEP1)

                proba_1 = model_step1.predict_proba(input_1.to_numpy())[0]
                classes_1 = list(model_step1.classes_)
                if "Parkinson" in classes_1:
                    p_pd = float(proba_1[classes_1.index("Parkinson")])
                if "Normal" in classes_1:
                    p_norm = float(proba_1[classes_1.index("Normal")])
                else:
                    p_norm = 1.0 - p_pd

                prob_normal = p_norm * 100.0

                # cut-off ê¸°ì¤€ìœ¼ë¡œ íŒì •
                if p_pd >= pd_cut:
                    kind, headline, band_code = step1_screening_band(p_pd, pd_cut)
                    if kind == "error":
                        st.error(f"ğŸ”´ **{headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})")
                    elif kind == "warning":
                        st.warning(f"ğŸŸ¡ **{headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})")
                    else:
                        st.success(f"ğŸŸ¢ **{headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})")
                    st.session_state.step1_band_code = band_code
                    if model_step2:
                        # Step2 ì…ë ¥(feature ì¶•ì†Œ ë²„ì „) â€” FEATS_STEP2ì— ë§ì¶° ê°’ë§Œ êµ¬ì„±
                        feat_map2 = {
                            'Intensity': final_db,
                            'SPS': final_sps,
                            'P_Loudness': p_loud,
                            'P_Rate': p_rate,
                            'P_Artic': p_artic,
                        }
                        input_2 = pd.DataFrame([[feat_map2.get(c, None) for c in FEATS_STEP2]], columns=FEATS_STEP2)

                        probs_sub = model_step2.predict_proba(input_2.to_numpy())[0]
                        sub_classes = list(model_step2.classes_)
                        j = int(np.argmax(probs_sub))
                        pred_sub = sub_classes[j]
                        pred_prob = float(probs_sub[j])
                        final_decision = pred_sub  # (ì•ˆì •ì„±) ëª¨ë¸ ì˜ˆì¸¡ ë¼ë²¨ì€ ê¸°ë³¸ì ìœ¼ë¡œ ìœ ì§€

                        # --- í˜¼í•©í˜•(Top1â€“Top2 ì°¨ì´ < MIX_MARGIN_P) í‘œì‹œìš© ìš”ì•½ ---
                        try:
                            _pairs = sorted(zip(sub_classes, probs_sub), key=lambda x: float(x[1]), reverse=True)
                            _top1_lbl, _top1_p = _pairs[0][0], float(_pairs[0][1])
                            _top2_lbl, _top2_p = (_pairs[1][0], float(_pairs[1][1])) if len(_pairs) > 1 else (None, 0.0)
                            _is_mixed = (_top2_lbl is not None) and ((_top1_p - _top2_p) < MIX_MARGIN_P)
                        except Exception:
                            _top1_lbl, _top1_p, _top2_lbl, _top2_p, _is_mixed = pred_sub, float(pred_prob), None, 0.0, False

                        pred_sub_display = pred_sub
                        if _is_mixed:
                            pred_sub_display = f"í˜¼í•©í˜•({_top1_lbl} ìš°ì„¸, {_top2_lbl} ë™ë°˜)"

                        if _is_mixed and (_top2_lbl is not None):
                            # í˜¼í•©í˜•(ì„ìƒìš©) ë¬¸êµ¬: ìš°ì„¸/ë™ë°˜ì„ ëª…ì‹œ
                            if (_top1_lbl == "ê°•ë„ ì§‘ë‹¨") and (_top2_lbl == "ì¡°ìŒ ì§‘ë‹¨"):
                                st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡ : **í˜¼í•©í˜•**ìœ¼ë¡œ ê°•ë„ ì§‘ë‹¨ì— í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ë” ë†’ìœ¼ë©°, ì¡°ìŒ ë¬¸ì œë¥¼ ë™ë°˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ê°•ë„ ì§‘ë‹¨ {_top1_p*100:.1f}%, ì¡°ìŒ ì§‘ë‹¨ {_top2_p*100:.1f}%).")
                            else:
                                st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡ : **í˜¼í•©í˜•**ìœ¼ë¡œ {_top1_lbl}ì— í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ë” ë†’ìœ¼ë©°, {_top2_lbl} ì†Œê²¬ì„ ë™ë°˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤({_top1_lbl} {_top1_p*100:.1f}%, {_top2_lbl} {_top2_p*100:.1f}%).")
                        else:
                            st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡: **{pred_sub_final}** ({pred_prob*100:.1f}%)")

                        # --- Hybrid ì‹ í˜¸(ì„ìƒ ì•ˆì •ì„±): ë¼ë²¨ 'ë³´ì •'ì€ í•˜ì§€ ì•Šê³ , ë™ë°˜ ê°€ëŠ¥ì„±ë§Œ ì•ˆë‚´ ---
                        intensity_prob = float(probs_sub[list(sub_classes).index("ê°•ë„ ì§‘ë‹¨")]) if "ê°•ë„ ì§‘ë‹¨" in sub_classes else None
                        jo_prob = float(probs_sub[list(sub_classes).index("ì¡°ìŒ ì§‘ë‹¨")]) if "ì¡°ìŒ ì§‘ë‹¨" in sub_classes else None
                        rate_prob = float(probs_sub[list(sub_classes).index("ë§ì†ë„ ì§‘ë‹¨")]) if "ë§ì†ë„ ì§‘ë‹¨" in sub_classes else None

                        # ì²­ì§€ê° ì¡°ìŒì •í™•ë„(0-100) ì ìˆ˜: ìŠ¬ë¼ì´ë” ì…ë ¥ê°’(p_artic) ì‚¬ìš©

                        percep_artic_score = float(p_artic) if 'p_artic' in locals() and p_artic is not None else None

                        rule_artic = (percep_artic_score is not None) and (percep_artic_score <= 40) and ((rate_prob is None) or (rate_prob < 0.45))
                        if rule_artic and pred_sub == "ê°•ë„ ì§‘ë‹¨" and jo_prob is not None and jo_prob > 0:
                            st.info("ğŸ§© í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼ ê°•ë„ ì§‘ë‹¨ì— í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ë” ë†’ìœ¼ë©°, ì¡°ìŒ ë™ë°˜ ê°€ëŠ¥ì„±(í˜¼í•©í˜•)ì´ ìˆìŠµë‹ˆë‹¤. (ë¼ë²¨ ë³´ì • ì—†ìŒ)")
                        elif rule_artic:
                            st.info("ğŸ§© í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼ ì¡°ìŒ ì €í•˜ ë™ë°˜ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. (ë¼ë²¨ ë³´ì • ì—†ìŒ)")
                        elif pred_sub == "ê°•ë„ ì§‘ë‹¨" and jo_prob is not None and _top2_lbl == "ì¡°ìŒ ì§‘ë‹¨" and ((_top1_p - _top2_p) < MIX_MARGIN_P):
                            st.info(f"ğŸ§© í˜¼í•© íŒ¨í„´: ê°•ë„({_top1_p*100:.1f}%) ìš°ì„¸ì´ë‚˜ ì¡°ìŒ({_top2_p*100:.1f}%)ë„ ê·¼ì ‘í•©ë‹ˆë‹¤ â†’ **í˜¼í•©í˜•(ê°•ë„ ìš°ì„¸, ì¡°ìŒ ë™ë°˜)** ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”.")
                        else:
                            st.info("â„¹ï¸ ì„ìƒ ì°¸ê³ : PD í•˜ìœ„ì§‘ë‹¨(ê°•ë„/ë§ì†ë„/ì¡°ìŒ)ì€ **PD ë°ì´í„°ë¡œë§Œ í•™ìŠµ**ëœ ì¶”ì • ê²°ê³¼ì…ë‹ˆë‹¤. ì •ìƒ ì¼€ì´ìŠ¤ì—ì„œëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í•´ì„í•˜ì„¸ìš”.")

                        # ---- Spider/Radar chart: PD í•˜ìœ„ì§‘ë‹¨ í™•ë¥  ì‹œê°í™” (ì›ë˜ UI ë³µì›) ----
                        try:
                            labels = sub_classes
                            labels_with_probs = [f"{label}\n({prob*100:.1f}%)" for label, prob in zip(labels, probs_sub)]
                            fig_radar = plt.figure(figsize=(3, 3))
                            ax = fig_radar.add_subplot(111, polar=True)
                            angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
                            angles += angles[:1]
                            stats = probs_sub.tolist() + [probs_sub[0]]
                            ax.plot(angles, stats, linewidth=2, linestyle='solid', color='red')
                            ax.fill(angles, stats, 'red', alpha=0.25)
                            ax.set_xticks(angles[:-1])
                            ax.set_xticklabels(labels_with_probs)

                            c_chart, c_desc = st.columns([1, 2])
                            with c_chart:
                                st.pyplot(fig_radar)

                            with c_desc:
                                if "ê°•ë„" in pred_sub:
                                    st.info("ğŸ’¡ íŠ¹ì§•: ëª©ì†Œë¦¬ í¬ê¸°ê°€ ì‘ê³  ì•½í•©ë‹ˆë‹¤. (Hypophonia)")
                                elif "ë§ì†ë„" in pred_sub:
                                    st.info("ğŸ’¡ íŠ¹ì§•: ë§ì´ ë¹ ë¥´ê±°ë‚˜ ë¦¬ë“¬ì´ ë¶ˆê·œì¹™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (Rate/Rhythm)")
                                else:
                                    st.info("ğŸ’¡ íŠ¹ì§•: ë°œìŒì´ ë­‰ê°œì§€ê³  ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (Articulation)")

                                with st.expander("ğŸ“Š í•˜ìœ„ì§‘ë‹¨ í™•ë¥ (ìƒì„¸)", expanded=False):
                                    dfp = pd.DataFrame({
                                        "ì§‘ë‹¨": labels,
                                        "í™•ë¥ (%)": (np.array(probs_sub) * 100).round(1)
                                    }).sort_values("í™•ë¥ (%)", ascending=False)
                                    
                                    # --- [ì„¤ëª… ë³´ê°•] í•˜ìœ„ì§‘ë‹¨ ë¶„ë¥˜ì— ê¸°ì—¬í•œ ìƒìœ„ ë³€ìˆ˜ TOP-3 ---
                                    try:
                                        x2_row = [final_db, final_sps, p_loud, p_rate, p_artic]
                                        contrib2 = top_contrib_linear_multiclass(model_step2, x2_row, FEATS_STEP2, pred_sub, topk=3)
                                        if contrib2:
                                            st.markdown("**ğŸ” ì´ í•˜ìœ„ì§‘ë‹¨ íŒì •ì— í¬ê²Œ ê¸°ì—¬í•œ ìš”ì†Œ(Top 3)**")
                                            for r in contrib2:
                                                st.write(f"- {r}")
                                    except Exception:
                                        pass

                                    st.dataframe(dfp, hide_index=True, use_container_width=True)
                        except Exception as e:
                            st.warning(f"ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")


                        # Step2 classë³„ cut-off (í•™ìŠµê¸°ë°˜) - ë¯¸ë§Œì´ë©´ ë¶ˆí™•ì‹¤ ê²½ê³ 
                        sub_cut = None
                        if CUTS and isinstance(CUTS, dict):
                            sub_cut = (CUTS.get("step2_cutoff_by_class") or {}).get(pred_sub, None)
                        if sub_cut is not None and pred_prob < float(sub_cut):
                            st.warning(f"âš ï¸ ì˜ˆì¸¡ í™•ë¥ ì´ í•™ìŠµê¸°ë°˜ cut-off({float(sub_cut):.2f}) ë¯¸ë§Œì…ë‹ˆë‹¤. 'ë¶ˆí™•ì‹¤'ë¡œ í•´ì„/ì¬ê²€ ê¶Œê³ ")
                            final_decision = f"{pred_sub} (ë¶ˆí™•ì‹¤)"
                    else:
                        final_decision = "Parkinson"
                else:
                    # í™•ë¥  ê¸°ë°˜ìœ¼ë¡œëŠ” ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆë”ë¼ë„, ì²­ì§€ê°/ìê°€ë³´ê³ /ìŒí–¥ ì¼ë¶€ ì§€í‘œì—ì„œ ëšœë ·í•œ ì´ìƒ ì†Œê²¬ì´ ìˆìœ¼ë©´
                    # ì„œë¹„ìŠ¤ ì•ˆì •ì„±ì„ ìœ„í•´ 'ì •ìƒ(ì£¼ì˜)'ë¡œ í‘œì‹œí•˜ê³  ì¶”ê°€ í‰ê°€/ì¶”ì ê²€ì‚¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
                    red_flags = []
                    try:
                        if p_artic is not None and float(p_artic) <= 40:
                            red_flags.append("ì¡°ìŒì •í™•ë„(ì²­ì§€ê°) â‰¤ 40")
                    except Exception:
                        pass
                    try:
                        if final_db is not None and float(final_db) <= 58:
                            red_flags.append("í‰ê·  ìŒì„± ê°•ë„(dB) ë‚®ìŒ")
                    except Exception:
                        pass
                    try:
                        if final_sps is not None and float(final_sps) >= 4.6:
                            red_flags.append("ë§ì†ë„(SPS) ë¹ ë¦„")
                    except Exception:
                        pass
                    try:
                        if vhi_total is not None and float(vhi_total) >= 10:
                            red_flags.append("VHI-10 ë†’ìŒ(â‰¥10)")
                    except Exception:
                        pass

                    if red_flags:
                        kind, headline, band_code = step1_screening_band(p_pd, pd_cut)
                        # ì •ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆì§€ë§Œ red-flagê°€ ìˆì„ ë•ŒëŠ” ê²½ê³ ë¡œ ê³ ì •
                        st.warning(
                            f"ğŸŸ¡ **ì •ìƒ(ì£¼ì˜): {headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})"
                        )
                        st.write("ê´€ì°°ëœ í•­ëª©: " + ", ".join(red_flags))
                        final_decision = "Normal (ì£¼ì˜)"
                    else:
                        kind, headline, band_code = step1_screening_band(p_pd, pd_cut)
                        # red-flagê°€ ì—†ìœ¼ë©´ êµ¬ê°„ë³„ ë©”ì‹œì§€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        if kind == "warning":
                            st.warning(f"ğŸŸ¡ **{headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})")
                        elif kind == "error":
                            st.error(f"ğŸ”´ **{headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})")
                        else:
                            st.success(f"ğŸŸ¢ **{headline}**  | Normal={prob_normal:.1f}%  PD={p_pd*100:.1f}% (cut-off={pd_cut:.2f})")
                        final_decision = "Normal"
            # --- (ì„ìƒìš©) ì •ìƒ(ì£¼ì˜)ì—ì„œë„ PD í•˜ìœ„ì§‘ë‹¨ ì¶”ì • ê²°ê³¼ í‘œì‹œ(ì°¸ê³ ) ---
            # Step2 ëª¨ë¸ì€ íŒŒí‚¨ìŠ¨ í™˜ì ë°ì´í„°ë¡œ í•™ìŠµë˜ì–´ 'ì •ìƒ'ì—ì„œì˜ í•´ì„ì—ëŠ” ì œí•œì´ ìˆìŠµë‹ˆë‹¤.
            show_step2_reference = False
            try:
                # ì„ìƒìš©: ì •ìƒ/ì •ìƒ(ì£¼ì˜)ì—ì„œë„ í•˜ìœ„ì§‘ë‹¨ ì¶”ì •(ì°¸ê³ ) í‘œì‹œ
                show_step2_reference = str(final_decision).startswith('Normal')
            except Exception:
                show_step2_reference = False

            if show_step2_reference and model_step2:
                st.info("â„¹ï¸ **ì„ìƒ ì°¸ê³ :** PD í•˜ìœ„ì§‘ë‹¨(ê°•ë„/ë§ì†ë„/ì¡°ìŒ) ì¶”ì • ê²°ê³¼ì…ë‹ˆë‹¤. (Step2ëŠ” PD ë°ì´í„°ë¡œ í•™ìŠµë˜ì–´ ì •ìƒ ì¼€ì´ìŠ¤ì—ì„œëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í•´ì„í•˜ì„¸ìš”.)")
                try:
                    feat_map2 = {
                        'Intensity': final_db,
                        'SPS': final_sps,
                        'P_Loudness': p_loud,
                        'P_Rate': p_rate,
                        'P_Artic': p_artic,
                    }
                    input_2_ref = pd.DataFrame([[feat_map2.get(c, None) for c in FEATS_STEP2]], columns=FEATS_STEP2)

                    probs_sub_ref = model_step2.predict_proba(input_2_ref.to_numpy())[0]
                    sub_classes_ref = list(model_step2.classes_)
                    j_ref = int(np.argmax(probs_sub_ref))
                    pred_sub_ref = sub_classes_ref[j_ref]
                    pred_prob_ref = float(probs_sub_ref[j_ref])

                    # Hybrid rule + intensity guard (ì°¸ê³ ìš© ì¶”ì •ì—ë„ ë™ì¼ ì ìš©)
                    pred_sub_ref_final = pred_sub_ref  # ë¼ë²¨ ë³´ì • ì—†ìŒ(ì„ìƒ ì•ˆì •ì„±)

                    # --- í˜¼í•©í˜•(Top1â€“Top2 ì°¨ì´ < MIX_MARGIN_P) í‘œì‹œìš© ìš”ì•½(ì°¸ê³ ) ---
                    try:
                        _pairs_r = sorted(zip(sub_classes_ref, probs_sub_ref), key=lambda x: float(x[1]), reverse=True)
                        _top1_lbl_r, _top1_p_r = _pairs_r[0][0], float(_pairs_r[0][1])
                        _top2_lbl_r, _top2_p_r = (_pairs_r[1][0], float(_pairs_r[1][1])) if len(_pairs_r) > 1 else (None, 0.0)
                        _is_mixed_r = (_top2_lbl_r is not None) and ((_top1_p_r - _top2_p_r) < MIX_MARGIN_P)
                    except Exception:
                        _top1_lbl_r, _top1_p_r, _top2_lbl_r, _top2_p_r, _is_mixed_r = pred_sub_ref, float(pred_prob_ref), None, 0.0, False

                    pred_sub_ref_display = pred_sub_ref
                    if _is_mixed_r:
                        pred_sub_ref_display = f"í˜¼í•©í˜•({_top1_lbl_r} ìš°ì„¸, {_top2_lbl_r} ë™ë°˜)"

                    if _is_mixed_r and (_top2_lbl_r is not None):
                        if (_top1_lbl_r == "ê°•ë„ ì§‘ë‹¨") and (_top2_lbl_r == "ì¡°ìŒ ì§‘ë‹¨"):
                            st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡(ì°¸ê³ ) : **í˜¼í•©í˜•**ìœ¼ë¡œ ê°•ë„ ì§‘ë‹¨ì— í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ë” ë†’ìœ¼ë©°, ì¡°ìŒ ì €í•˜ë¥¼ ë™ë°˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ê°•ë„ ì§‘ë‹¨ {_top1_p_r*100:.1f}%, ì¡°ìŒ ì§‘ë‹¨ {_top2_p_r*100:.1f}%).")
                        else:
                            st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡(ì°¸ê³ ): **í˜¼í•©í˜•({_top1_lbl_r} ìš°ì„¸, {_top2_lbl_r} ë™ë°˜)** (Top1: {_top1_lbl_r} {_top1_p_r*100:.1f}%, Top2: {_top2_lbl_r} {_top2_p_r*100:.1f}%).")
                    else:
                        st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡(ì°¸ê³ ): **{pred_sub_ref_final}** ({pred_prob_ref*100:.1f}%)")

                    # --- Hybrid ì‹ í˜¸(ì°¸ê³ ): ë¼ë²¨ ë³´ì •ì€ í•˜ì§€ ì•Šê³ , ë™ë°˜ ê°€ëŠ¥ì„±ë§Œ ì•ˆë‚´ ---
                    intensity_prob_ref = float(probs_sub_ref[list(sub_classes_ref).index("ê°•ë„ ì§‘ë‹¨")]) if "ê°•ë„ ì§‘ë‹¨" in sub_classes_ref else None
                    jo_prob_ref = float(probs_sub_ref[list(sub_classes_ref).index("ì¡°ìŒ ì§‘ë‹¨")]) if "ì¡°ìŒ ì§‘ë‹¨" in sub_classes_ref else None
                    rate_prob_ref = float(probs_sub_ref[list(sub_classes_ref).index("ë§ì†ë„ ì§‘ë‹¨")]) if "ë§ì†ë„ ì§‘ë‹¨" in sub_classes_ref else None

                    percep_artic_score_ref = float(p_artic) if 'p_artic' in locals() and p_artic is not None else None

                    rule_artic_ref = (percep_artic_score_ref is not None) and (percep_artic_score_ref <= 40) and ((rate_prob_ref is None) or (rate_prob_ref < 0.45))
                    if rule_artic_ref and pred_sub_ref == "ê°•ë„ ì§‘ë‹¨" and jo_prob_ref is not None and jo_prob_ref > 0:
                        st.info("ğŸ§© í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼(ì°¸ê³ ) ê°•ë„ ì§‘ë‹¨ì— í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ë” ë†’ìœ¼ë©°, ì¡°ìŒ ë™ë°˜ ê°€ëŠ¥ì„±(í˜¼í•©í˜•)ì´ ìˆìŠµë‹ˆë‹¤. (ë¼ë²¨ ë³´ì • ì—†ìŒ)")
                    elif rule_artic_ref:
                        st.info("ğŸ§© í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ê²°ê³¼(ì°¸ê³ ) ì¡°ìŒ ì €í•˜ ë™ë°˜ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. (ë¼ë²¨ ë³´ì • ì—†ìŒ)")
                    elif pred_sub_ref == "ê°•ë„ ì§‘ë‹¨" and jo_prob_ref is not None and _top2_lbl_r == "ì¡°ìŒ ì§‘ë‹¨" and ((_top1_p_r - _top2_p_r) < MIX_MARGIN_P):
                        st.info(f"ğŸ§© í˜¼í•© íŒ¨í„´(ì°¸ê³ ): ê°•ë„({_top1_p_r*100:.1f}%) ìš°ì„¸ì´ë‚˜ ì¡°ìŒ({_top2_p_r*100:.1f}%)ë„ ê·¼ì ‘í•©ë‹ˆë‹¤ â†’ **í˜¼í•©í˜•(ê°•ë„ ìš°ì„¸, ì¡°ìŒ ë™ë°˜)** ìœ¼ë¡œ í•´ì„í•˜ì„¸ìš”.")
                    # Radar chart
                    try:
                        labels = sub_classes_ref
                        labels_with_probs = [f"{label}\n({prob*100:.1f}%)" for label, prob in zip(labels, probs_sub_ref)]
                        fig_radar_ref = plt.figure(figsize=(3, 3))
                        ax = fig_radar_ref.add_subplot(111, polar=True)
                        angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
                        angles += angles[:1]
                        stats = probs_sub_ref.tolist() + [probs_sub_ref[0]]
                        ax.plot(angles, stats, linewidth=2, linestyle='solid', color='red')
                        ax.fill(angles, stats, 'red', alpha=0.25)
                        ax.set_thetagrids(np.degrees(angles[:-1]), labels_with_probs, fontsize=10)
                        ax.set_ylim(0, 1)
                        ax.grid(True)
                        st.pyplot(fig_radar_ref, use_container_width=False)
                        plt.close(fig_radar_ref)
                    except Exception:
                        pass
                except Exception:
                    st.info("ì°¸ê³ ìš© í•˜ìœ„ì§‘ë‹¨ ì¶”ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

            # Step1 ë©”íƒ€(ì €ì¥/ë¡œê·¸ìš©)
            st.session_state.step1_meta = {"p_pd": p_pd, "p_normal": p_norm, "cutoff": pd_cut}

            # í•´ì„ í…ìŠ¤íŠ¸
            st.caption('â€» ìê°€ë³´ê³ (VHI)ëŠ” **íŒì • í™•ë¥  ê³„ì‚°ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê³ **, í•´ì„/ê²½ê³ ë¥¼ ìœ„í•œ ì°¸ê³  ì§€í‘œë¡œë§Œ í‘œì‹œë©ë‹ˆë‹¤.')
            positives, negatives = generate_interpretation(prob_normal, final_db, final_sps, range_adj, p_artic, vhi_total, vhi_e)

            # --- [ì„¤ëª… ë³´ê°•] ê·œì¹™ ê¸°ë°˜ ì„¤ëª…ì´ ë¹„ì–´ìˆì„ ë•Œ: ëª¨ë¸ TOP ê¸°ì—¬ ë³€ìˆ˜ë¡œ ìµœì†Œ 3ê°œ ìƒì„± ---
            # --- ìë™ ì„¤ëª…(ëª¨ë¸ ê¸°ì—¬ë„): ì‹¤íŒ¨í•´ë„ ì´ìœ ê°€ ë¹„ì§€ ì•Šë„ë¡ ---
            x1_row = [st.session_state.get('f0_mean'), range_adj, final_db, final_sps, sex_num_ui]
            try:
                pos_auto, neg_auto = top_contrib_linear_binary(model_step1, x1_row, FEATS_STEP1, pos_label="Parkinson", topk=3)
                # ì •ìƒ í™•ë¥  ì„¤ëª…ì´ ë¹„ë©´(ë˜ëŠ” ë„ˆë¬´ ì§§ìœ¼ë©´) ìë™ ì„¤ëª…ì„ ì„ì–´ì¤Œ
                if not positives or len(positives) < 1:
                    positives = (positives or []) + (neg_auto[:3] if neg_auto else [])
                # PD ê°€ëŠ¥ì„± ì´ìœ ê°€ ë¹„ë©´ ìë™ ì„¤ëª…(=PD ìª½ ê¸°ì—¬) ì¶”ê°€
                if not negatives or len(negatives) < 1:
                    negatives = (negatives or []) + (pos_auto[:3] if pos_auto else [])
            except Exception:
                # ìë™ ì„¤ëª…ì´ ì‹¤íŒ¨í•˜ë”ë¼ë„ ì•„ë˜ì˜ ìµœì¢… ì•ˆì „ì¥ì¹˜ì—ì„œ ê³µë€ì„ ë§‰ìŠµë‹ˆë‹¤.
                pass

            # --- ìµœì¢… ì•ˆì „ì¥ì¹˜: ì´ìœ  ë¦¬ìŠ¤íŠ¸ ê³µë€ ë°©ì§€ (try ë°–ì—ì„œ ë¬´ì¡°ê±´ ì‹¤í–‰) ---
            if not positives:
                positives = (neg_auto[:3] if ("neg_auto" in locals() and neg_auto) else ["ì •ìƒ í™•ë¥ ì´ ë” ë†’ì€ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (ê²½ê³„ êµ¬ê°„ì´ë¼ë©´ ì¬ì¸¡ì •/ì¶”ê°€ í‰ê°€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.)"])
            # negatives(=PD ê°€ëŠ¥ì„± ê·¼ê±°)ëŠ” í•™ìŠµë°ì´í„° ê¸°ë°˜/ê·œì¹™ ê¸°ë°˜ ê·¼ê±°ë¥¼ í•©ì¹œ ë’¤ì—ë„ ë¹„ì–´ìˆì„ ìˆ˜ ìˆì–´,
            # ì—¬ê¸°ì„œëŠ” ë¯¸ë¦¬ ì±„ìš°ì§€ ì•Šê³  ì•„ë˜ì—ì„œ 'ê³µë€ ë°©ì§€' ë¡œì§ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³´ê°•í•©ë‹ˆë‹¤.
            # --- Step1 í•´ì„ íƒ€ì´í‹€/ìˆœì„œ(í™•ë¥  êµ¬ê°„ì— ë”°ë¼) + ì„¤ëª… ê³µë€ ë°©ì§€ ---
            band_code = st.session_state.get("step1_band_code", None)

            # í•™ìŠµë°ì´í„° ê¸°ë°˜ 'ê°€ê¹Œì›€' ì„¤ëª…(ì•ˆì „ì¥ì¹˜)
            training_path = get_training_file()
            train_mtime = None
            if False and training_path and os.path.exists(training_path):
                try:
                    train_mtime = os.path.getmtime(training_path)
                except Exception:
                    train_mtime = None

            stats_step1 = get_step1_training_stats(_file_mtime=train_mtime)
            x_dict = {
                "F0": st.session_state.get("f0_mean", np.nan),
                "Range": range_adj,
                "ê°•ë„(dB)": final_db,
                "SPS": final_sps,
            }
            n_like, pd_like_strict, pd_like_closest = explain_step1_by_training(stats_step1, x_dict, topk=3)

            # í•™ìŠµë°ì´í„°(ì¤‘ì•™ê°’) ê¸°ë°˜ ê·¼ê±°ë¥¼ ë³´ê°•
            if n_like:
                positives = list(dict.fromkeys((positives or []) + n_like))

            # PD ê·¼ê±°ëŠ” 'ëª…í™•íˆ PDìª½'ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ê³  cut-off ê·¼ì²˜(ê²½ê³„)ë¼ë©´
            # 'PD ì¤‘ì•™ê°’ê³¼ ìƒëŒ€ì ìœ¼ë¡œ ê°€ê¹Œìš´ í•­ëª©'ì„ ë³´ì—¬ì¤˜ì„œ ê³µë€ì„ ë°©ì§€í•©ë‹ˆë‹¤.
            borderline = abs(p_pd - pd_cut) <= 0.10
            pd_like = pd_like_strict if pd_like_strict else (pd_like_closest if borderline else [])
            if pd_like:
                negatives = list(dict.fromkeys((negatives or []) + pd_like))

            # ì»·ì˜¤í”„ ê·¼ì²˜ì´ë©´ ì²« ì¤„ì„ ê²½ê³„ ì•ˆë‚´ë¡œ ê³ ì •(ê·¸ë¦¬ê³  ì•„ë˜ì— "ì–´ë–¤ ì§€í‘œ"ì¸ì§€ ë°˜ë“œì‹œ ë³´ì—¬ì¤Œ)
            if borderline:
                border_note = f"PD í™•ë¥ ì´ cut-off({pd_cut:.2f}) ê·¼ì²˜ì˜ **ê²½ê³„ êµ¬ê°„**ì…ë‹ˆë‹¤(PD={p_pd*100:.1f}%). ì•„ë˜ ì§€í‘œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ê°€ í‰ê°€/ì¬ì¸¡ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                # ê²½ê³„ì¸ë°ë„ negativesê°€ ë¹„ì–´ìˆìœ¼ë©´(ì…ë ¥ ëˆ„ë½/í†µê³„ ì—†ìŒ) í•œ ì¤„ì€ ë³´ì¥
            if not negatives:
                # ê¸°ì—¬ë„ ê¸°ë°˜ ê·¼ê±°ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ìš°ì„  í‘œì‹œ(êµ¬ì²´ì  ì§€í‘œê°€ í¬í•¨ë¨)
                if ("pos_auto" in locals()) and pos_auto:
                    negatives = pos_auto[:3]
                else:
                    negatives = [f"PD í™•ë¥ ì´ cut-off({pd_cut:.2f}) ê·¼ì²˜ì…ë‹ˆë‹¤(PD={p_pd*100:.1f}%). ì¬ì¸¡ì •/ì¶”ê°€ í‰ê°€ë¡œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."]
            # íƒ€ì´í‹€ í†¤: ë” ë†’ì€ ìª½(ì£¼ê²°ë¡ ) ë¨¼ì € ë³´ì—¬ì£¼ê¸°
            primary_is_pd = bool(p_pd >= pd_cut)

            band_suffix = {
                "normal_very_high": "(ë§¤ìš° ë†’ìŒ)",
                "normal_high": "(ë†’ìŒ)",
                "border_mixed": "(ê²½ê³„)",
                "border_cutoff": "(ì»·ì˜¤í”„ ê·¼ì²˜)",
                "pd_possible": "(ê°€ëŠ¥ì„±)",
                "pd_high": "(ë†’ìŒ)",
                "pd_very_high": "(ë§¤ìš° ë†’ìŒ)",
            }.get(band_code, "")

            if primary_is_pd:
                title_primary = f"##### ğŸ”´ íŒŒí‚¨ìŠ¨ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•˜ëŠ” ê·¼ê±° {band_suffix}".strip()
                title_secondary = "##### âœ… ì •ìƒ ê°€ëŠ¥ì„±ì„ ì§€ì§€í•˜ëŠ” ê·¼ê±°"
                list_primary, list_secondary = negatives, positives
            else:
                title_primary = f"##### âœ… ì •ìƒ ê°€ëŠ¥ì„±ì„ ì§€ì§€í•˜ëŠ” ê·¼ê±° {band_suffix}".strip()
                title_secondary = "##### âš ï¸ íŒŒí‚¨ìŠ¨ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•˜ëŠ” ê·¼ê±°"
                list_primary, list_secondary = positives, negatives

            st.markdown(title_primary)
            for t in (list_primary or []):
                st.write(f"- {t}")

            st.markdown(title_secondary)
            for t in (list_secondary or []):
                st.write(f"- {t}")

            # ì €ì¥/ì „ì†¡ìš© ë°ì´í„° íŒ¨í‚¤ì§•
            st.session_state.save_ready_data = {
                'wav_path': st.session_state.current_wav_path,
                'patient': {'name': subject_name, 'age': subject_age, 'gender': subject_gender},
                'analysis': {
                    'f0': st.session_state['f0_mean'], 'range': range_adj, 'db': final_db, 'sps': final_sps,
                    'vhi_total': vhi_total, 'vhi_p': vhi_p, 'vhi_f': vhi_f, 'vhi_e': vhi_e,
                    'p_artic': p_artic, 'p_pitch': p_pitch, 'p_loud': p_loud, 'p_rate': p_rate, 'p_prange': p_prange
                },
                'diagnosis': {'final': final_decision, 'normal_prob': prob_normal},
                'step1_meta': st.session_state.get('step1_meta', {"p_pd": p_pd, "p_normal": p_norm, "cutoff": pd_cut})
            }
            st.session_state.is_saved = False

        else:
            st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {MODEL_LOAD_ERROR or 'training_data íŒŒì¼/ì»¬ëŸ¼/ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.'}")

# ì „ì†¡ ë²„íŠ¼
st.markdown("---")
if st.button("â˜ï¸ ë°ì´í„° ì „ì†¡ (ë©”ì¼+ì‹œíŠ¸)", type="primary"):
    if 'save_ready_data' not in st.session_state:
        st.error("ğŸš¨ ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ğŸš€ ì§„ë‹¨ ê²°ê³¼ í™•ì¸]ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!")
    elif st.session_state.get('is_saved'):
        st.warning("ì´ë¯¸ ì „ì†¡ëœ ë°ì´í„°ì…ë‹ˆë‹¤.")
    else:
        with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ ê¸°ë¡ ë° ì´ë©”ì¼ ì „ì†¡ ì¤‘..."):
            success, msg = send_email_and_log_sheet(
                st.session_state.save_ready_data['wav_path'], 
                st.session_state.save_ready_data['patient'], 
                st.session_state.save_ready_data['analysis'], 
                st.session_state.save_ready_data['diagnosis']
            )
        if success:
            st.session_state.is_saved = True
            st.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! {msg}")
        else:
            st.error(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {msg}")
