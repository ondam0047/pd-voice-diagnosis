import streamlit as st
import parselmouth
from parselmouth.praat import call
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import platform
import datetime
import io

# --- êµ¬ê¸€ ì‹œíŠ¸ & ì´ë©”ì¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
from google.oauth2 import service_account
import gspread
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email.mime.text import MIMEText
from email import encoders

from sklearn.metrics import confusion_matrix, roc_curve

import sqlite3
import hashlib
import json
from pathlib import Path

from scipy.signal import find_peaks

from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.model_selection import LeaveOneOut
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline


# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="íŒŒí‚¨ìŠ¨ë³‘ í™˜ì í•˜ìœ„ìœ í˜• ë¶„ë¥˜ í”„ë¡œê·¸ë¨", layout="wide")

# ==========================================
# [ì„¤ì •] êµ¬ê¸€ ì‹œíŠ¸ ì •ë³´ (Secrets)
# ==========================================
HAS_GCP_SECRETS = True
try:
    SHEET_NAME = st.secrets["gcp_info"]["sheet_name"]
except:
    st.warning("âš ï¸ Secrets ì„¤ì •ì´ ì—†ì–´ êµ¬ê¸€ì‹œíŠ¸/ì´ë©”ì¼ ì „ì†¡ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. (SQLite ì €ì¥ì€ ì‚¬ìš© ê°€ëŠ¥)")
    SHEET_NAME = None
    HAS_GCP_SECRETS = False

# ==========================================
# [ì „ì—­ ì„¤ì •] í°íŠ¸ ë° ë³€ìˆ˜
# ==========================================
FEATS_STEP1 = ['F0', 'Range', 'Intensity', 'SPS', 'VHI_Total', 'VHI_P', 'VHI_F', 'VHI_E', 'Sex']
FEATS_STEP2 = FEATS_STEP1 + ['P_Pitch', 'P_Range', 'P_Loudness', 'P_Rate', 'P_Artic']

def sex_to_num(x):
    """ì„±ë³„ì„ ìˆ«ì featureë¡œ ë³€í™˜: ë‚¨/M=1.0, ì—¬/F=0.0, ê·¸ ì™¸/ê²°ì¸¡=0.5"""
    if x is None:
        return 0.5
    s = str(x).strip().lower()
    if s in ["ë‚¨", "ë‚¨ì„±", "ë‚¨ì", "m", "male", "man", "1"]:
        return 1.0
    if s in ["ì—¬", "ì—¬ì„±", "ì—¬ì", "f", "female", "woman", "0", "2"]:
        return 0.0
    return 0.5


@st.cache_resource

def _youden_cutoff(y_true, scores):
    """Youden's J(ë¯¼ê°ë„+íŠ¹ì´ë„-1)ë¥¼ ìµœëŒ€í™”í•˜ëŠ” threshold ë°˜í™˜"""
    fpr, tpr, thr = roc_curve(y_true, scores)
    j = tpr - fpr
    bi = int(np.argmax(j))
    # sklearn roc_curveì˜ thrì—ëŠ” infê°€ ë“¤ì–´ê°ˆ ìˆ˜ ìˆì–´ ë°©ì–´
    cut = float(thr[bi]) if np.isfinite(thr[bi]) else 0.5
    sens = float(tpr[bi])
    spec = float(1.0 - fpr[bi])
    return cut, sens, spec


@st.cache_data
def compute_cutoffs_from_training(_file_mtime=None):
    """
    training_data.csv/xlsxë¡œë¶€í„° Step1/Step2 í™•ë¥  cut-offë¥¼ ìë™ ì‚°ì¶œ
    - ëˆ„ìˆ˜ ë°©ì§€: Leave-One-Out(LOO) OOF í™•ë¥ ë¡œ cut-off ì‚°ì •
    - Step1: ì´í•­ ë¡œì§€ìŠ¤í‹±(PD í™•ë¥ ) + Youden cut-off
    - Step2: (PD ë‚´ë¶€) ì •ê·œí™” QDA(reg_param) í™•ë¥  + í´ë˜ìŠ¤ë³„(OVR) Youden cut-off
    """
    DATA_FILE = "training_data.csv"
    target_file = "training_data.xlsx" if os.path.exists("training_data.xlsx") else DATA_FILE
    if not os.path.exists(target_file):
        return None

    loaders = [
        (lambda f: pd.read_excel(f), "excel"),
        (lambda f: pd.read_csv(f, encoding='utf-8'), "utf-8"),
        (lambda f: pd.read_csv(f, encoding='cp949'), "cp949"),
        (lambda f: pd.read_csv(f, encoding='euc-kr'), "euc-kr")
    ]
    df_raw = None
    for loader, _ in loaders:
        try:
            df_raw = loader(target_file)
            if df_raw is not None and not df_raw.empty:
                break
        except Exception:
            continue
    if df_raw is None or df_raw.empty:
        return None

    # --- ë¡œìš° íŒŒì‹± ---
    data_list = []
    for _, row in df_raw.iterrows():
        label = str(row.get('ì§„ë‹¨ê²°ê³¼ (Label)', 'Normal')).strip()
        l = label.lower()
        if 'normal' in l:
            diagnosis, subgroup = "Normal", "Normal"
        elif 'pd_intensity' in l:
            diagnosis, subgroup = "Parkinson", "ê°•ë„ ì§‘ë‹¨"
        elif 'pd_rate' in l:
            diagnosis, subgroup = "Parkinson", "ë§ì†ë„ ì§‘ë‹¨"
        elif 'pd_articulation' in l:
            diagnosis, subgroup = "Parkinson", "ì¡°ìŒ ì§‘ë‹¨"
        else:
            continue

        raw_total = pd.to_numeric(row.get('VHIì´ì ', 0), errors="coerce")
        raw_p = pd.to_numeric(row.get('VHI_ì‹ ì²´', 0), errors="coerce")
        raw_f = pd.to_numeric(row.get('VHI_ê¸°ëŠ¥', 0), errors="coerce")
        raw_e = pd.to_numeric(row.get('VHI_ì •ì„œ', 0), errors="coerce")
        raw_total = float(0 if pd.isna(raw_total) else raw_total)
        raw_p = float(0 if pd.isna(raw_p) else raw_p)
        raw_f = float(0 if pd.isna(raw_f) else raw_f)
        raw_e = float(0 if pd.isna(raw_e) else raw_e)

        # VHIëŠ” UIì—ì„œ VHI-10(0~40) ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ë˜ë¯€ë¡œ,
        # training_dataì˜ VHI-30(ì´ì  0~120, í•˜ìœ„ì²™ë„ 0~40)ì„ VHI-10 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # UIì—ì„œ ê³„ì‚°í•˜ëŠ” ë¶„í•´(ê¸°ëŠ¥ 0~20 / ì‹ ì²´ 0~12 / ì •ì„œ 0~8)ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¥ë‹ˆë‹¤.
        if raw_total <= 40 and raw_f <= 20 and raw_p <= 12 and raw_e <= 8:
            vhi_total, vhi_p, vhi_f, vhi_e = raw_total, raw_p, raw_f, raw_e
        else:
            vhi_f = (raw_f / 40.0) * 20.0
            vhi_p = (raw_p / 40.0) * 12.0
            vhi_e = (raw_e / 40.0) * 8.0
            vhi_total = vhi_f + vhi_p + vhi_e

        sex_num = sex_to_num(row.get('ì„±ë³„', None))

        data_list.append([
            row.get('F0', 0), row.get('Range', 0), row.get('ê°•ë„(dB)', 0), row.get('SPS', 0),
            vhi_total, vhi_p, vhi_f, vhi_e, sex_num,
            row.get('ìŒë„(ì²­ì§€ê°)', 0), row.get('ìŒë„ë²”ìœ„(ì²­ì§€ê°)', 0), row.get('ê°•ë„(ì²­ì§€ê°)', 0),
            row.get('ë§ì†ë„(ì²­ì§€ê°)', 0), row.get('ì¡°ìŒì •í™•ë„(ì²­ì§€ê°)', 0),
            diagnosis, subgroup
        ])

    df = pd.DataFrame(data_list, columns=FEATS_STEP2 + ['Diagnosis', 'Subgroup'])

    # ìˆ«ì ë³€í™˜/ê²°ì¸¡ ì²˜ë¦¬
    for col in FEATS_STEP2:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    # ìŒí–¥/ì²­ì§€ê°ì€ í‰ê· ìœ¼ë¡œ, VHIëŠ” 0ìœ¼ë¡œ(ì…ë ¥ ëˆ„ë½ ëŒ€ë¹„)
    for col in ['F0', 'Range', 'Intensity', 'SPS',
                'P_Pitch', 'P_Range', 'P_Loudness', 'P_Rate', 'P_Artic', 'Sex']:
        if col in df.columns:
            df[col] = df[col].fillna(df[col].mean())
    for col in ['VHI_Total', 'VHI_P', 'VHI_F', 'VHI_E']:
        if col in df.columns:
            df[col] = df[col].fillna(0.0)

    # ---------- Step1: Normal vs PD cut-off (LOO OOF) ----------
    X1 = df[FEATS_STEP1].copy()
    y1 = df["Diagnosis"].astype(str).values

    loo = LeaveOneOut()
    oof_pd = np.zeros(len(df), dtype=float)

    pipe1 = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(
            solver="lbfgs",
            max_iter=5000,
            class_weight="balanced",
            random_state=42
        ))
    ])

    for tr, te in loo.split(X1, y1):
        pipe1.fit(X1.iloc[tr], df['Diagnosis'].iloc[tr].astype(str).values)
        proba = pipe1.predict_proba(X1.iloc[te])[0]
        cls = pipe1.named_steps['clf'].classes_
        pd_idx = int(np.where(cls == 'Parkinson')[0][0]) if 'Parkinson' in cls else -1
        oof_pd[te[0]] = float(proba[pd_idx]) if pd_idx >= 0 else float(proba[-1])

    step1_cutoff, step1_sens, step1_spec = _youden_cutoff(y1, oof_pd)

    # ---------- Step2: PD ë‚´ë¶€ 3ì§‘ë‹¨ cut-off (í´ë˜ìŠ¤ë³„ OVR, LOO OOF) ----------
    df_pd = df[df["Diagnosis"] == "Parkinson"].copy()
    cutoff_by_class = {}
    step2_report = None

    if len(df_pd) >= 3:
        X2 = df_pd[FEATS_STEP2].copy()
        y2 = df_pd["Subgroup"].astype(str).values
        classes = np.unique(y2)
        class_to_idx = {c: i for i, c in enumerate(classes)}

        oof2 = np.zeros((len(df_pd), len(classes)), dtype=float)

        pipe2 = Pipeline([
            ("scaler", StandardScaler()),
            ("clf", QuadraticDiscriminantAnalysis(reg_param=0.1))
        ])

        for tr, te in loo.split(X2, y2):
            # í˜¹ì‹œë¼ë„ íŠ¹ì • foldì—ì„œ í•œ í´ë˜ìŠ¤ê°€ ì‚¬ë¼ì§ˆ ê²½ìš°ë¥¼ ëŒ€ë¹„(í˜„ ë°ì´í„°ì—ì„œëŠ” ê±°ì˜ ì—†ìŒ)
            y_tr = y2[tr]
            if len(np.unique(y_tr)) < 2:
                continue
            pipe2.fit(X2.iloc[tr], y_tr)
            proba = pipe2.predict_proba(X2.iloc[te])[0]
            fold_classes = pipe2.named_steps["clf"].classes_
            for j, c in enumerate(fold_classes):
                oof2[te[0], class_to_idx[c]] = float(proba[j])

        # í´ë˜ìŠ¤ë³„ OVR Youden cut-off
        for c in classes:
            y_bin = (y2 == c).astype(int)
            p = oof2[:, class_to_idx[c]]
            if np.all(y_bin == 0) or np.all(y_bin == 1):
                cutoff_by_class[c] = 0.5
                continue
            cut, _, _ = _youden_cutoff(y_bin, p)
            cutoff_by_class[c] = float(cut)

        # ì°¸ê³ ìš©: LOO ê¸°ì¤€ í˜¼ë™í–‰ë ¬(ë‹¨ìˆœ argmax)
        y_pred = [classes[int(np.argmax(oof2[i]))] for i in range(len(df_pd))]
        step2_cm = confusion_matrix(y2, y_pred, labels=list(classes))
        step2_report = {"classes": list(classes), "confusion_matrix": step2_cm.tolist()}

    # Step1 í˜¼ë™í–‰ë ¬(í™•ë¥  cut-off ì ìš©)
    y_pred1 = (oof_pd >= step1_cutoff).astype(int)
    step1_cm = confusion_matrix(y1, y_pred1, labels=[0, 1])  # 0=Normal,1=PD

    return {
        "step1_cutoff": float(step1_cutoff),
        "step1_sensitivity": float(step1_sens),
        "step1_specificity": float(step1_spec),
        "step1_confusion_matrix": step1_cm.tolist(),
        "step2_cutoff_by_class": cutoff_by_class,
        "step2_report": step2_report
    }


# ==========================================
# [SQLite ì €ì¥] Secretsê°€ ì—†ì–´ë„ ì €ì¥ ê°€ëŠ¥í•œ ë¡œì»¬ DB
# ==========================================
DB_PATH = os.environ.get("PD_TOOL_DB_PATH", "pd_tool.db")

@st.cache_resource
def _db_conn():
    conn = sqlite3.connect(Path(DB_PATH).as_posix(), check_same_thread=False, timeout=30)
    try:
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.execute("PRAGMA synchronous=NORMAL;")
    except Exception:
        pass
    conn.execute("""
        CREATE TABLE IF NOT EXISTS analyses (
            analysis_id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TEXT NOT NULL,
            subject_name TEXT,
            subject_age INTEGER,
            subject_gender TEXT,
            wav_filename TEXT,
            wav_sha256 TEXT,
            f0 REAL, pitch_range REAL, intensity_db REAL, sps REAL,
            vhi_total REAL, vhi_p REAL, vhi_f REAL, vhi_e REAL,
            p_pitch REAL, p_prange REAL, p_loud REAL, p_rate REAL, p_artic REAL,
            step1_p_pd REAL, step1_p_normal REAL, step1_cutoff REAL,
            final_decision TEXT, normal_prob REAL
        );
    """)
    conn.commit()
    return conn

def _sha256_file(path: str) -> str:
    try:
        h = hashlib.sha256()
        with open(path, "rb") as f:
            for chunk in iter(lambda: f.read(1024 * 1024), b""):
                h.update(chunk)
        return h.hexdigest()
    except Exception:
        return ""

def save_to_sqlite(wav_path: str, patient_info: dict, analysis: dict, diagnosis: dict, step1_meta: dict):
    conn = _db_conn()
    now = datetime.datetime.now().isoformat(timespec="seconds")
    wav_filename = os.path.basename(wav_path) if wav_path else None
    wav_sha = _sha256_file(wav_path) if wav_path else ""
    conn.execute(
        """INSERT INTO analyses(
            created_at, subject_name, subject_age, subject_gender,
            wav_filename, wav_sha256,
            f0, pitch_range, intensity_db, sps,
            vhi_total, vhi_p, vhi_f, vhi_e,
            p_pitch, p_prange, p_loud, p_rate, p_artic,
            step1_p_pd, step1_p_normal, step1_cutoff,
            final_decision, normal_prob
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?);""",
        (
            now,
            str(patient_info.get("name","")).strip() or None,
            int(patient_info.get("age")) if str(patient_info.get("age","")).strip() != "" else None,
            str(patient_info.get("gender","")).strip() or None,
            wav_filename, wav_sha,
            float(analysis.get("f0",0.0)), float(analysis.get("range",0.0)), float(analysis.get("db",0.0)), float(analysis.get("sps",0.0)),
            float(analysis.get("vhi_total",0.0)), float(analysis.get("vhi_p",0.0)), float(analysis.get("vhi_f",0.0)), float(analysis.get("vhi_e",0.0)),
            float(analysis.get("p_pitch",0.0)), float(analysis.get("p_prange",0.0)), float(analysis.get("p_loud",0.0)), float(analysis.get("p_rate",0.0)), float(analysis.get("p_artic",0.0)),
            float(step1_meta.get("p_pd",0.0)), float(step1_meta.get("p_normal",0.0)), float(step1_meta.get("cutoff",0.5)),
            str(diagnosis.get("final","")), float(diagnosis.get("normal_prob",0.0))
        )
    )
    conn.commit()

def setup_korean_font():
    system_name = platform.system()
    if system_name == 'Windows':
        try:
            plt.rc('font', family='Malgun Gothic')
        except: pass
    elif system_name == 'Darwin': 
        plt.rc('font', family='AppleGothic')
    else: 
        plt.rc('font', family='NanumGothic')
    plt.rcParams['axes.unicode_minus'] = False

setup_korean_font()

# ==========================================
# 0. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
# ==========================================

@st.cache_resource
def train_models():
    """
    training_data.csv/xlsxë¡œë¶€í„° ëª¨ë¸ í•™ìŠµ
    - Step1: ì´í•­ ë¡œì§€ìŠ¤í‹±(ì •ìƒ vs PD)
    - Step2: ì •ê·œí™” QDA(PD í•˜ìœ„ì§‘ë‹¨ 3ë¶„ë¥˜)
    """
    DATA_FILE = "training_data.csv"
    target_file = "training_data.xlsx" if os.path.exists("training_data.xlsx") else DATA_FILE
    if not os.path.exists(target_file):
        return None, None

    loaders = [
        (lambda f: pd.read_excel(f), "excel"),
        (lambda f: pd.read_csv(f, encoding='utf-8'), "utf-8"),
        (lambda f: pd.read_csv(f, encoding='cp949'), "cp949"),
        (lambda f: pd.read_csv(f, encoding='euc-kr'), "euc-kr")
    ]
    df_raw = None
    for loader, _ in loaders:
        try:
            df_raw = loader(target_file)
            if df_raw is not None and not df_raw.empty:
                break
        except Exception:
            continue
    if df_raw is None or df_raw.empty:
        return None, None

    data_list = []
    for _, row in df_raw.iterrows():
        label = str(row.get('ì§„ë‹¨ê²°ê³¼ (Label)', 'Normal')).strip()
        l = label.lower()
        if 'normal' in l:
            diagnosis, subgroup = "Normal", "Normal"
        elif 'pd_intensity' in l:
            diagnosis, subgroup = "Parkinson", "ê°•ë„ ì§‘ë‹¨"
        elif 'pd_rate' in l:
            diagnosis, subgroup = "Parkinson", "ë§ì†ë„ ì§‘ë‹¨"
        elif 'pd_articulation' in l:
            diagnosis, subgroup = "Parkinson", "ì¡°ìŒ ì§‘ë‹¨"
        else:
            continue

        raw_total = pd.to_numeric(row.get('VHIì´ì ', 0), errors="coerce")
        raw_p = pd.to_numeric(row.get('VHI_ì‹ ì²´', 0), errors="coerce")
        raw_f = pd.to_numeric(row.get('VHI_ê¸°ëŠ¥', 0), errors="coerce")
        raw_e = pd.to_numeric(row.get('VHI_ì •ì„œ', 0), errors="coerce")
        raw_total = float(0 if pd.isna(raw_total) else raw_total)
        raw_p = float(0 if pd.isna(raw_p) else raw_p)
        raw_f = float(0 if pd.isna(raw_f) else raw_f)
        raw_e = float(0 if pd.isna(raw_e) else raw_e)

        # VHIëŠ” UIì—ì„œ VHI-10(0~40) ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ë˜ë¯€ë¡œ,
        # training_dataì˜ VHI-30(ì´ì  0~120, í•˜ìœ„ì²™ë„ 0~40)ì„ VHI-10 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # UIì—ì„œ ê³„ì‚°í•˜ëŠ” ë¶„í•´(ê¸°ëŠ¥ 0~20 / ì‹ ì²´ 0~12 / ì •ì„œ 0~8)ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¥ë‹ˆë‹¤.
        if raw_total <= 40 and raw_f <= 20 and raw_p <= 12 and raw_e <= 8:
            vhi_total, vhi_p, vhi_f, vhi_e = raw_total, raw_p, raw_f, raw_e
        else:
            vhi_f = (raw_f / 40.0) * 20.0
            vhi_p = (raw_p / 40.0) * 12.0
            vhi_e = (raw_e / 40.0) * 8.0
            vhi_total = vhi_f + vhi_p + vhi_e

        sex_num = sex_to_num(row.get('ì„±ë³„', None))

        data_list.append([
            row.get('F0', 0), row.get('Range', 0), row.get('ê°•ë„(dB)', 0), row.get('SPS', 0),
            vhi_total, vhi_p, vhi_f, vhi_e, sex_num,
            row.get('ìŒë„(ì²­ì§€ê°)', 0), row.get('ìŒë„ë²”ìœ„(ì²­ì§€ê°)', 0), row.get('ê°•ë„(ì²­ì§€ê°)', 0),
            row.get('ë§ì†ë„(ì²­ì§€ê°)', 0), row.get('ì¡°ìŒì •í™•ë„(ì²­ì§€ê°)', 0),
            diagnosis, subgroup
        ])

    df = pd.DataFrame(data_list, columns=FEATS_STEP2 + ['Diagnosis', 'Subgroup'])
    for col in FEATS_STEP2:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # ê²°ì¸¡ ì²˜ë¦¬
    for col in ['F0', 'Range', 'Intensity', 'SPS',
                'P_Pitch', 'P_Range', 'P_Loudness', 'P_Rate', 'P_Artic', 'Sex']:
        if col in df.columns:
            df[col] = df[col].fillna(df[col].mean())
    for col in ['VHI_Total', 'VHI_P', 'VHI_F', 'VHI_E']:
        if col in df.columns:
            df[col] = df[col].fillna(0.0)

    # Step1
    X1 = df[FEATS_STEP1].copy()
    y1 = df["Diagnosis"].astype(str).values
    model_step1 = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(
            solver="lbfgs",
            max_iter=5000,
            class_weight="balanced",
            random_state=42
        ))
    ])
    model_step1.fit(X1, y1)

    # Step2 (PD ë‚´ë¶€)
    df_pd = df[df["Diagnosis"] == "Parkinson"].copy()
    if df_pd.empty:
        return model_step1, None

    X2 = df_pd[FEATS_STEP2].copy()
    y2 = df_pd["Subgroup"].astype(str).values
    model_step2 = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", QuadraticDiscriminantAnalysis(reg_param=0.1))
    ])
    model_step2.fit(X2, y2)

    return model_step1, model_step2


try: model_step1, model_step2 = train_models()
except: model_step1, model_step2 = None, None

# training_data ê¸°ë°˜ cut-off(í™•ë¥  ì„ê³„ê°’) ìë™ ì‚°ì¶œ
try:
    _tf = "training_data.xlsx" if os.path.exists("training_data.xlsx") else "training_data.csv"
    _mt = os.path.getmtime(_tf) if os.path.exists(_tf) else None
    CUTS = compute_cutoffs_from_training(_mt)
except Exception:
    CUTS = None

# ==========================================
# [ì´ë©”ì¼ ì „ì†¡ í•¨ìˆ˜] íŒŒì¼ëª…: ì´ë¦„.wav
# ==========================================
def send_email_and_log_sheet(wav_path, patient_info, analysis, diagnosis):
    # Secretsê°€ ì—†ìœ¼ë©´(ë˜ëŠ” ì‹œíŠ¸ëª…ì´ ì—†ìœ¼ë©´) í´ë¼ìš°ë“œ ì „ì†¡ ëŒ€ì‹  SQLiteì— ì €ì¥
    if not globals().get("HAS_GCP_SECRETS", True) or (SHEET_NAME is None):
        try:
            step1_meta = st.session_state.get("save_ready_data", {}).get("step1_meta", st.session_state.get("step1_meta", {}))
        except Exception:
            step1_meta = {}
        try:
            save_to_sqlite(wav_path, patient_info, analysis, diagnosis, step1_meta)
            return True, "Secrets ë¯¸ì„¤ì •: êµ¬ê¸€ì‹œíŠ¸/ì´ë©”ì¼ ëŒ€ì‹  SQLiteì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            return False, f"Secrets ë¯¸ì„¤ì • + SQLite ì €ì¥ ì‹¤íŒ¨: {e}"

    try:
        creds = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        )
        gc = gspread.authorize(creds)
        sh = gc.open(SHEET_NAME)
        worksheet = sh.sheet1
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = patient_info['name'].replace(" ", "")
        
        # êµ¬ê¸€ ì‹œíŠ¸ìš© íŒŒì¼ëª… (ìƒì„¸ ì •ë³´ í¬í•¨)
        log_filename = f"{safe_name}_{patient_info['age']}_{patient_info['gender']}_{timestamp}.wav"

        if not worksheet.row_values(1):
            worksheet.append_row([
                "Timestamp", "Filename", "Name", "Age", "Gender",
                "F0", "Range", "Intensity_dB", "SPS", 
                "VHI_Total", "VHI_P", "VHI_F", "VHI_E",
                "P_Artic", "P_Pitch", "P_Loud", "P_Rate", "P_PRange",
                "Final_Diagnosis", "Normal_Prob"
            ])
            
        row_data = [
            timestamp, log_filename,
            patient_info['name'], patient_info['age'], patient_info['gender'],
            analysis['f0'], analysis['range'], analysis['db'], analysis['sps'],
            analysis['vhi_total'], analysis['vhi_p'], analysis['vhi_f'], analysis['vhi_e'],
            analysis['p_artic'], analysis['p_pitch'], analysis['p_loud'], analysis['p_rate'], analysis['p_prange'],
            diagnosis['final'], diagnosis['normal_prob']
        ]
        worksheet.append_row(row_data)

        sender = st.secrets["email"]["sender"]
        password = st.secrets["email"]["password"]
        receiver = st.secrets["email"]["receiver"]

        msg = MIMEMultipart()
        msg['From'] = sender
        msg['To'] = receiver
        
        # [ìˆ˜ì •] ì´ë©”ì¼ ì²¨ë¶€ íŒŒì¼ëª…: ì´ë¦„.wav
        email_attach_name = f"{safe_name}.wav"
        msg['Subject'] = f"[PD Data] {email_attach_name}"

        body = f"""
        í™˜ì: {patient_info['name']} ({patient_info['age']}/{patient_info['gender']})
        ì§„ë‹¨: {diagnosis['final']} ({diagnosis['normal_prob']:.1f}%)
        
        * ìŒì„± íŒŒì¼ì´ ì²¨ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ({email_attach_name})
        * ìƒì„¸ ìˆ˜ì¹˜ëŠ” êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
        """
        msg.attach(MIMEText(body, 'plain'))

        with open(wav_path, "rb") as f:
            part = MIMEBase("audio", "wav")
            part.set_payload(f.read())
        
        encoders.encode_base64(part)
        # ì²¨ë¶€ íŒŒì¼ëª… ì„¤ì •
        part.add_header("Content-Disposition", f"attachment; filename={email_attach_name}")
        msg.attach(part)

        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender, password)
        server.sendmail(sender, receiver, msg.as_string())
        server.quit()

        # (ì„ íƒ) í´ë¼ìš°ë“œ ì „ì†¡ ì„±ê³µ ì‹œì—ë„ SQLiteì— ë¡œê·¸ ì €ì¥
        try:
            step1_meta = st.session_state.get("save_ready_data", {}).get("step1_meta", st.session_state.get("step1_meta", {}))
            save_to_sqlite(wav_path, patient_info, analysis, diagnosis, step1_meta)
            return True, "ë©”ì¼/ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ + SQLite ë¡œê·¸ ì €ì¥ ì™„ë£Œ"
        except Exception:
            return True, "ë©”ì¼ ì „ì†¡ ë° ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ"

    except Exception as e:
        return False, str(e)

# ==========================================
# [SMR ì¸¡ì • í•¨ìˆ˜]
# ==========================================
def auto_detect_smr_events(sound_path, top_n=20):
    try:
        sound = parselmouth.Sound(sound_path)
        intensity = sound.to_intensity(time_step=0.005)
        times = intensity.xs()
        values = intensity.values[0, :]
        inv_vals = -values
        peaks, properties = find_peaks(inv_vals, prominence=5, distance=40)
        candidates = []
        for p_idx in peaks:
            time_point = times[p_idx]
            v_int = values[p_idx]
            start_search = max(0, p_idx - 20)
            end_search = min(len(values), p_idx + 20)
            local_max = np.max(values[start_search:end_search])
            depth = local_max - v_int
            candidates.append({"time": time_point, "depth": depth})
        candidates.sort(key=lambda x: x['time'])
        return candidates, len(candidates)
    except:
        return [], 0

# ==========================================
# [ë¶„ì„ ë¡œì§] Median Ratio í•„í„°ë¡œ í™•ì‹¤í•œ ì˜¥íƒ€ë¸Œ ì œê±°
# ==========================================
def plot_pitch_contour_plotly(sound_path, f0_min, f0_max):
    try:
        sound = parselmouth.Sound(sound_path)
        pitch = call(sound, "To Pitch", 0.0, f0_min, f0_max)
        pitch_array = pitch.selected_array['frequency']
        pitch_values = np.array(pitch_array, dtype=np.float64)
        duration = sound.get_total_duration()
        n_points = len(pitch_values)
        time_array = np.linspace(0, duration, n_points)
        
        valid_indices = pitch_values != 0
        valid_times = time_array[valid_indices]
        valid_pitch = pitch_values[valid_indices]

        if len(valid_pitch) > 0:
            median_f0 = np.median(valid_pitch)
            lower_bound = median_f0 * 0.6
            upper_bound = median_f0 * 1.6
            
            clean_mask = (valid_pitch >= lower_bound) & (valid_pitch <= upper_bound)
            clean_p = valid_pitch[clean_mask]
            clean_t = valid_times[clean_mask]
            
            if len(clean_p) > 0:
                mean_f0 = np.mean(clean_p)
                rng = np.max(clean_p) - np.min(clean_p)
            else:
                mean_f0, rng = 0, 0
                clean_p, clean_t = [], []
        else:
            clean_p, clean_t = [], []
            mean_f0, rng = 0, 0

        fig = go.Figure()
        if len(clean_p) > 0:
            fig.add_trace(go.Scatter(x=clean_t, y=clean_p, mode='markers', marker=dict(size=4, color='red'), name='Pitch'))
            y_min = max(0, np.min(clean_p) - 20)
            y_max = np.max(clean_p) + 20
            fig.update_layout(title="ìŒë„ ì»¨íˆ¬ì–´ (ì´ìƒì¹˜ ì œê±°ë¨)", xaxis_title="Time(s)", yaxis_title="Hz", height=300, yaxis=dict(range=[y_min, y_max]))
        else:
            fig.update_layout(title="ìŒë„ ì»¨íˆ¬ì–´ (ê°ì§€ëœ ìŒì„± ì—†ìŒ)", height=300)

        return fig, mean_f0, rng, duration
    except: return None, 0, 0, 0

def run_analysis_logic(file_path):
    try:
        fig, f0, rng, dur = plot_pitch_contour_plotly(file_path, 70, 500)
        sound = parselmouth.Sound(file_path)
        intensity = sound.to_intensity()
        mean_db = call(intensity, "Get mean", 0, 0, "energy")
        sps = st.session_state.user_syllables / dur if dur > 0 else 0
        smr_events, smr_count = auto_detect_smr_events(file_path)
        
        st.session_state.update({
            'f0_mean': f0, 'pitch_range': rng, 'mean_db': mean_db, 
            'sps': sps, 'duration': dur, 'fig_plotly': fig, 
            'smr_events': smr_events, 'smr_count': smr_count,
            'is_analyzed': True, 'is_saved': False
        })
        return True
    except Exception as e:
        st.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}"); return False

def generate_interpretation(prob_normal, db, sps, range_val, artic, vhi, vhi_e):
    positives, negatives = [], []
    if vhi < 15: positives.append(f"í™˜ì ë³¸ì¸ì˜ ì£¼ê´€ì  ë¶ˆí¸í•¨(VHI {vhi}ì )ì´ ë‚®ì•„, ì¼ìƒ ëŒ€í™”ì— ì‹¬ë¦¬ì /ê¸°ëŠ¥ì  ë¶€ë‹´ì´ ì ì€ ìƒíƒœì…ë‹ˆë‹¤.")
    if range_val >= 100: positives.append(f"ìŒë„ ë²”ìœ„ê°€ {range_val:.1f}Hzë¡œ ë„“ê²Œ ë‚˜íƒ€ë‚˜, ëª©ì†Œë¦¬ì— ìƒë™ê°ì´ ìˆê³  ì–µì–‘ì˜ ë³€í™”ê°€ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.")
    if artic >= 75: positives.append(f"ì²­ì§€ê°ì  ì¡°ìŒ ì •í™•ë„ê°€ {artic}ì ìœ¼ë¡œ ì–‘í˜¸í•˜ì—¬, ìƒëŒ€ë°©ì´ ë§ì„ ì•Œì•„ë“£ê¸°ì— ëª…ë£Œí•œ ìƒíƒœì…ë‹ˆë‹¤.")
    if sps < 4.5: positives.append(f"ë§ì†ë„ê°€ {sps:.2f} SPSë¡œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤. íŒŒí‚¨ìŠ¨ë³‘ì—ì„œ í”íˆ ë‚˜íƒ€ë‚˜ëŠ” ê¸‰ê²©í•œ ê°€ì† í˜„ìƒ(Festination) ì—†ì´ ì•ˆì •ì ì¸ ì†ë„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    if db >= 60: positives.append(f"í‰ê·  ìŒì„± ê°•ë„ê°€ {db:.1f} dBë¡œ, ì¼ë°˜ì ì¸ ëŒ€í™” ìˆ˜ì¤€(60dB ì´ìƒ)ì˜ ì„±ëŸ‰ì„ íŠ¼íŠ¼í•˜ê²Œ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

    if db < 60: negatives.append(f"í‰ê·  ìŒì„± ê°•ë„ê°€ {db:.1f} dBë¡œ ë‹¤ì†Œ ì‘ìŠµë‹ˆë‹¤. ì´ëŠ” íŒŒí‚¨ìŠ¨ë³‘ì˜ ëŒ€í‘œì  ì¦ìƒì¸ 'ê°•ë„ ê°ì†Œ(Hypophonia)'ì™€ ìœ ì‚¬í•˜ì—¬ ë°œì„± í›ˆë ¨ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    if sps >= 4.5: negatives.append(f"ë§ì†ë„ê°€ {sps:.2f} SPSë¡œ ì§€ë‚˜ì¹˜ê²Œ ë¹ ë¦…ë‹ˆë‹¤. ì´ëŠ” ë°œí™” ì œì–´ê°€ ì–´ë ¤ì›Œ ë§ì´ ë¹ ë¥´ì§€ëŠ” ê°€ì† ì§•í›„(Short rushes of speech)ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
    if artic < 70: negatives.append(f"ì²­ì§€ê°ì  ì¡°ìŒ ì •í™•ë„ê°€ {artic}ì ìœ¼ë¡œ ë‹¤ì†Œ ë‚®ìŠµë‹ˆë‹¤. ë°œìŒì´ ë¶ˆë¶„ëª…í•´ì§€ëŠ” ì¡°ìŒ ì¥ì• (Dysarthria) ì§•í›„ê°€ ê´€ì°°ë©ë‹ˆë‹¤.")
    if vhi >= 20: negatives.append(f"VHI ì´ì ì´ {vhi}ì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤. í™˜ì ìŠ¤ìŠ¤ë¡œ ìŒì„± ë¬¸ì œë¡œ ì¸í•œ ìƒí™œì˜ ë¶ˆí¸í•¨ê³¼ ì‹¬ë¦¬ì  ìœ„ì¶•ì„ í¬ê²Œ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.")
    if vhi_e >= 5: negatives.append("íŠ¹íˆ VHI ì •ì„œ(E) ì ìˆ˜ê°€ ë†’ì•„, ë§í•˜ê¸°ì— ëŒ€í•œ ë¶ˆì•ˆê°ì´ë‚˜ ìì‹ ê° ì €í•˜ê°€ ê°ì§€ë©ë‹ˆë‹¤.")
    return positives, negatives

# --- UI Title ---
st.title("íŒŒí‚¨ìŠ¨ë³‘ í™˜ì í•˜ìœ„ìœ í˜• ë¶„ë¥˜ í”„ë¡œê·¸ë¨")
st.markdown("ì´ í”„ë¡œê·¸ë¨ì€ ì²­ì§€ê°ì  í‰ê°€, ìŒí–¥í•™ì  ë¶„ì„, ìê°€ë³´ê³ (VHI-10) ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ íŒŒí‚¨ìŠ¨ë³‘ í™˜ìì˜ ìŒì„± íŠ¹ì„±ì„ 3ê°€ì§€ í•˜ìœ„ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

# 1. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ‘¤ ëŒ€ìƒì ì •ë³´ (í•„ìˆ˜)")
    subject_name = st.text_input("ì´ë¦„ (ì‹¤ëª…/ID)", "ì°¸ì—¬ì")
    subject_age = st.number_input("ë‚˜ì´", 1, 120, 60)
    subject_gender = st.selectbox("ì„±ë³„", ["M", "F"])

# 2. ë°ì´í„° ìˆ˜ì§‘
st.header("1. ìŒì„± ë°ì´í„° ìˆ˜ì§‘")
if 'user_syllables' not in st.session_state: st.session_state.user_syllables = 80
if 'source_type' not in st.session_state: st.session_state.source_type = None

col_rec, col_up = st.columns(2)
TEMP_FILENAME = "temp_for_analysis.wav"

with col_rec:
    st.markdown("#### ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ")
    font_size = st.slider("ğŸ” ê¸€ì í¬ê¸°", 15, 50, 28, key="fs_read")
    
    # ë¬¸ë‹¨ ì„ íƒ
    read_opt = st.radio("ğŸ“– ë‚­ë… ë¬¸ë‹¨ ì„ íƒ", ["1. ì‚°ì±… (ì¼ë°˜ìš© - 69ìŒì ˆ)", "2. ë°”ë‹·ê°€ì˜ ì¶”ì–µ (SMR/ì •ë°€ìš© - 80ìŒì ˆ)"])
    
    def styled_text(text, size): 
        return f"""<div style="font-size: {size}px; line-height: 1.8; border: 1px solid #ddd; padding: 15px; background-color: #f9f9f9; color: #333;">{text}</div>"""

    if "ë°”ë‹·ê°€" in read_opt:
        read_text = "ë°”ë‹·ê°€ì— íŒŒë„ê°€ ì¹©ë‹ˆë‹¤. ë¬´ì§€ê°œ ì•„ë˜ ë°”ë‘‘ì´ê°€ ëœë‹ˆë‹¤. ë³´íŠ¸ê°€ ì§€ë‚˜ê°€ê³  ë²„í„°êµ¬ì´ë¥¼ ë¨¹ìŠµë‹ˆë‹¤. í¬í† ì¹´ë“œë¥¼ ë¶€íƒí•´ì„œ ë‹ë³´ê¸°ë¡œ ë´…ë‹ˆë‹¤. ì‹œì¥ì—ì„œ ë¹ˆëŒ€ë–¡ì„ ì‚¬ ë¨¹ì—ˆìŠµë‹ˆë‹¤."
        default_syl = 80
    else:
        read_text = "ë†’ì€ ì‚°ì— ì˜¬ë¼ê°€ ë§‘ì€ ê³µê¸°ë¥¼ ë§ˆì‹œë©° ì†Œë¦¬ë¥¼ ì§€ë¥´ë©´ ê°€ìŠ´ì´ í™œì§ ì—´ë¦¬ëŠ” ë“¯í•˜ë‹¤. ë°”ë‹·ê°€ì— ë‚˜ê°€ ì¡°ê°œë¥¼ ì£¼ìœ¼ë©° ë„“ê²Œ í¼ì³ìˆëŠ” ë°”ë‹¤ë¥¼ ë°”ë¼ë³´ë©´ ë‚´ ë§ˆìŒ ì—­ì‹œ ë„“ì–´ì§€ëŠ” ê²ƒ ê°™ë‹¤."
        default_syl = 69
        
    st.markdown(styled_text(read_text, font_size), unsafe_allow_html=True)
    
    # ìŒì ˆ ìˆ˜ ìë™ ë³€ê²½
    syllables_rec = st.number_input("ì „ì²´ ìŒì ˆ ìˆ˜", 1, 500, default_syl, key=f"syl_rec_{read_opt}")
    st.session_state.user_syllables = syllables_rec
    
    audio_buf = st.audio_input("ë‚­ë… ë…¹ìŒ")
    if st.button("ğŸ™ï¸ ë…¹ìŒëœ ìŒì„± ë¶„ì„"):
        if audio_buf:
            with open(TEMP_FILENAME, "wb") as f: f.write(audio_buf.read())
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            run_analysis_logic(st.session_state.current_wav_path)
        else: st.warning("ë…¹ìŒë¶€í„° í•´ì£¼ì„¸ìš”.")

with col_up:
    st.markdown("#### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    up_file = st.file_uploader("WAV íŒŒì¼ ì„ íƒ", type=["wav"])
    if up_file: st.audio(up_file, format='audio/wav')
    if st.button("ğŸ“‚ ì—…ë¡œë“œ íŒŒì¼ ë¶„ì„"):
        if up_file:
            with open(TEMP_FILENAME, "wb") as f: f.write(up_file.read())
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            run_analysis_logic(st.session_state.current_wav_path)
        else: st.warning("íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")

# 3. ê²°ê³¼ ë° ì €ì¥
if st.session_state.get('is_analyzed'):
    st.markdown("---")
    st.subheader("2. ë¶„ì„ ê²°ê³¼ ë° ë³´ì •")
    
    c1, c2 = st.columns([2, 1])
    
    with c1: 
        st.plotly_chart(st.session_state['fig_plotly'], use_container_width=True)
    
    with c2:
        db_adj = st.slider("ê°•ë„(dB) ë³´ì •", -50.0, 50.0, -10.0)
        final_db = st.session_state['mean_db'] + db_adj
        
        range_adj = st.slider("ìŒë„ë²”ìœ„(Hz) ë³´ì •", 0.0, 300.0, float(st.session_state['pitch_range']))
        s_time, e_time = st.slider("ë§ì†ë„ êµ¬ê°„(ì´ˆ)", 0.0, st.session_state['duration'], (0.0, st.session_state['duration']), 0.01)
        sel_dur = max(0.1, e_time - s_time)
        final_sps = st.session_state.user_syllables / sel_dur
        
        st.write("#### ğŸ“Š ìŒí–¥í•™ì  ë¶„ì„ ê²°ê³¼")
        result_df = pd.DataFrame({
            "í•­ëª©": ["í‰ê·  ê°•ë„(dB)", "í‰ê·  ìŒë„(Hz)", "ìŒë„ ë²”ìœ„(Hz)", "ë§ì†ë„(SPS)"],
            "ìˆ˜ì¹˜": [f"{final_db:.2f}", f"{st.session_state['f0_mean']:.2f}", f"{range_adj:.2f}", f"{final_sps:.2f}"]
        })
        st.dataframe(result_df, hide_index=True)

    st.markdown("---")
    if st.session_state.get('smr_events'):
        st.markdown("##### ğŸ” SMR ìë™ ë¶„ì„ (ë‹¨ì–´ ë§¤ì¹­)")
        events = st.session_state['smr_events']
        smr_df_data = {}
        words = ["ë°”ë‹·ê°€", "íŒŒë„ê°€", "ë¬´ì§€ê°œ", "ë°”ë‘‘ì´", "ë³´íŠ¸ê°€", "ë²„í„°êµ¬ì´", "í¬í† ì¹´ë“œ", "ë¶€íƒí•´", "ë‹ë³´ê¸°", "ë¹ˆëŒ€ë–¡"]
        
        for i, word in enumerate(words):
            if i < len(events):
                ev = events[i]
                status = "ğŸŸ¢ ì–‘í˜¸" if ev['depth'] >= 20 else ("ğŸŸ¡ ì£¼ì˜" if ev['depth'] >= 15 else "ğŸ”´ ë¶ˆëŸ‰")
                val = f"{ev['depth']:.1f}dB\n{status}"
            else:
                val = "ë¯¸ê°ì§€"
            smr_df_data[word] = [val]
        
        st.dataframe(pd.DataFrame(smr_df_data), use_container_width=True)

    st.markdown("---")
    st.subheader("3. ì²­ì§€ê° ë° VHI-10 ì…ë ¥")
    cc1, cc2 = st.columns([1, 1.2])
    with cc1:
        st.markdown("#### ğŸ”Š ì²­ì§€ê° í‰ê°€")
        p_artic = st.slider("ì¡°ìŒ ì •í™•ë„", 0, 100, 50)
        p_pitch = st.slider("ìŒë„", 0, 100, 50)
        p_prange = st.slider("ìŒë„ ë²”ìœ„", 0, 100, 50)
        p_loud = st.slider("ê°•ë„", 0, 100, 50)
        p_rate = st.slider("ë§ì†ë„", 0, 100, 50)
    with cc2:
        st.markdown("#### ğŸ“ VHI-10")
        vhi_opts = [0, 1, 2, 3, 4]
        
        with st.expander("VHI-10 ë¬¸í•­ ì…ë ¥ (í´ë¦­í•´ì„œ í¼ì¹˜ê¸°)", expanded=True):
            q1 = st.select_slider("1. ì‚¬ëŒë“¤ì´ ë‚´ ëª©ì†Œë¦¬ë¥¼ ë“£ëŠ”ë° ì–´ë ¤ì›€ì„ ëŠë‚€ë‹¤.", options=vhi_opts)
            q2 = st.select_slider("2. ì‚¬ëŒë“¤ì´ ë‚´ ë§ì„ ì˜ ëª» ì•Œì•„ë“¤ì–´ ë°˜ë³µí•´ì•¼ í•œë‹¤.", options=vhi_opts)
            q3 = st.select_slider("3. ë‚¯ì„  ì‚¬ëŒë“¤ê³¼ ì „í™”ë¡œ ëŒ€í™”í•˜ëŠ” ê²ƒì´ ì–´ë µë‹¤.", options=vhi_opts)
            q4 = st.select_slider("4. ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ì¸í•´ ê¸´ì¥ëœë‹¤.", options=vhi_opts)
            q5 = st.select_slider("5. ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ì¸í•´ ì‚¬ëŒë“¤ì„ í”¼í•˜ê²Œ ëœë‹¤.", options=vhi_opts)
            q6 = st.select_slider("6. ë‚´ ëª©ì†Œë¦¬ ë•Œë¬¸ì— ì§œì¦ì´ ë‚œë‹¤.", options=vhi_opts)
            q7 = st.select_slider("7. ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ìˆ˜ì…ì— ì§€ì¥ì´ ìˆë‹¤.", options=vhi_opts)
            q8 = st.select_slider("8. ë‚´ ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ëŒ€í™”ê°€ ì œí•œëœë‹¤.", options=vhi_opts)
            q9 = st.select_slider("9. ë‚´ ëª©ì†Œë¦¬ ë•Œë¬¸ì— ì†Œì™¸ê°ì„ ëŠë‚€ë‹¤.", options=vhi_opts)
            q10 = st.select_slider("10. ëª©ì†Œë¦¬ë¥¼ ë‚´ëŠ” ê²ƒì´ í˜ë“¤ë‹¤.", options=vhi_opts)

        vhi_f = q1 + q2 + q5 + q7 + q8
        vhi_p = q3 + q4 + q6
        vhi_e = q9 + q10
        vhi_total = vhi_f + vhi_p + vhi_e
        
        st.markdown("##### ğŸ“Š ì˜ì—­ë³„ ì ìˆ˜")
        col_v1, col_v2, col_v3, col_v4 = st.columns(4)
        col_v1.metric("ì´ì ", f"{vhi_total}ì ")
        col_v2.metric("ê¸°ëŠ¥(F)", f"{vhi_f}ì ")
        col_v3.metric("ì‹ ì²´(P)", f"{vhi_p}ì ")
        col_v4.metric("ì •ì„œ(E)", f"{vhi_e}ì ")

    st.markdown("---")
    st.subheader("4. ìµœì¢… ì§„ë‹¨ ë° í´ë¼ìš°ë“œ ì „ì†¡")
    
    if st.button("ğŸš€ ì§„ë‹¨ ê²°ê³¼ í™•ì¸", key="btn_diag"):
        if model_step1:
            # ì„±ë³„ feature
            sex_num_ui = sex_to_num(subject_gender)

            # Step1: PD í™•ë¥  cut-off (training_data ê¸°ë°˜)
            pd_cut = 0.5
            if CUTS and isinstance(CUTS, dict) and "step1_cutoff" in CUTS and CUTS["step1_cutoff"] is not None:
                pd_cut = float(CUTS["step1_cutoff"])

            # ê¸°ë³¸ê°’(ì €ì¥ìš©)
            p_pd = 0.0
            p_norm = 1.0

            # ì¡°ìŒì •í™•ë„(p_artic) 78ì  ì´ìƒì´ë©´ Normalë¡œ ê°•ì œí•˜ë˜ ê·œì¹™ì€ ì œê±°í–ˆìŠµë‹ˆë‹¤.
            if False:  # (removed rule)
                pass
                
                
            else:
                input_1 = pd.DataFrame([[
                    st.session_state['f0_mean'], range_adj, final_db, final_sps,
                    vhi_total, vhi_p, vhi_f, vhi_e,
                    sex_num_ui
                ]], columns=FEATS_STEP1)

                proba_1 = model_step1.predict_proba(input_1)[0]
                classes_1 = list(model_step1.classes_)
                if "Parkinson" in classes_1:
                    p_pd = float(proba_1[classes_1.index("Parkinson")])
                if "Normal" in classes_1:
                    p_norm = float(proba_1[classes_1.index("Normal")])
                else:
                    p_norm = 1.0 - p_pd

                prob_normal = p_norm * 100.0

                # cut-off ê¸°ì¤€ìœ¼ë¡œ íŒì •
                if p_pd >= pd_cut:
                    st.error(f"ğŸ”´ **íŒŒí‚¨ìŠ¨ ê°€ëŠ¥ì„± (PD) ({p_pd*100:.1f}%)**  | cut-off={pd_cut:.2f}")
                    if model_step2:
                        input_2 = pd.DataFrame([[
                            st.session_state['f0_mean'], range_adj, final_db, final_sps,
                            vhi_total, vhi_p, vhi_f, vhi_e,
                            sex_num_ui,
                            p_pitch, p_prange, p_loud, p_rate, p_artic
                        ]], columns=FEATS_STEP2)

                        probs_sub = model_step2.predict_proba(input_2)[0]
                        sub_classes = list(model_step2.classes_)
                        j = int(np.argmax(probs_sub))
                        pred_sub = sub_classes[j]
                        pred_prob = float(probs_sub[j])
                        final_decision = pred_sub

                        st.info(f"â¡ï¸ PD í•˜ìœ„ ì§‘ë‹¨ ì˜ˆì¸¡: **{pred_sub}** ({pred_prob*100:.1f}%)")

                        # Step2 classë³„ cut-off (í•™ìŠµê¸°ë°˜) - ë¯¸ë§Œì´ë©´ ë¶ˆí™•ì‹¤ ê²½ê³ 
                        sub_cut = None
                        if CUTS and isinstance(CUTS, dict):
                            sub_cut = (CUTS.get("step2_cutoff_by_class") or {}).get(pred_sub, None)
                        if sub_cut is not None and pred_prob < float(sub_cut):
                            st.warning(f"âš ï¸ ì˜ˆì¸¡ í™•ë¥ ì´ í•™ìŠµê¸°ë°˜ cut-off({float(sub_cut):.2f}) ë¯¸ë§Œì…ë‹ˆë‹¤. 'ë¶ˆí™•ì‹¤'ë¡œ í•´ì„/ì¬ê²€ ê¶Œê³ ")
                            final_decision = f"{pred_sub} (ë¶ˆí™•ì‹¤)"
                    else:
                        final_decision = "Parkinson"
                else:
                    st.success(f"ğŸŸ¢ **ì •ìƒ ìŒì„± (Normal) ({prob_normal:.1f}%)**  | PD={p_pd*100:.1f}% , cut-off={pd_cut:.2f}")
                    final_decision = "Normal"

            # Step1 ë©”íƒ€(ì €ì¥/ë¡œê·¸ìš©)
            st.session_state.step1_meta = {"p_pd": p_pd, "p_normal": p_norm, "cutoff": pd_cut}

            # í•´ì„ í…ìŠ¤íŠ¸
            positives, negatives = generate_interpretation(prob_normal, final_db, final_sps, range_adj, p_artic, vhi_total, vhi_e)
            st.markdown("##### âœ… ì •ìƒì¼ í™•ë¥ ì´ ë†’ê²Œ ë‚˜ì˜¨ ì´ìœ ")
            for p in positives: st.write(f"- {p}")
            st.markdown("##### âš ï¸ íŒŒí‚¨ìŠ¨ ê°€ëŠ¥ì„±ì´ ì¡´ì¬í•˜ëŠ” ì´ìœ ")
            for n in negatives: st.write(f"- {n}")


            # ì €ì¥/ì „ì†¡ìš© ë°ì´í„° íŒ¨í‚¤ì§•
            st.session_state.save_ready_data = {
                'wav_path': st.session_state.current_wav_path,
                'patient': {'name': subject_name, 'age': subject_age, 'gender': subject_gender},
                'analysis': {
                    'f0': st.session_state['f0_mean'], 'range': range_adj, 'db': final_db, 'sps': final_sps,
                    'vhi_total': vhi_total, 'vhi_p': vhi_p, 'vhi_f': vhi_f, 'vhi_e': vhi_e,
                    'p_artic': p_artic, 'p_pitch': p_pitch, 'p_loud': p_loud, 'p_rate': p_rate, 'p_prange': p_prange
                },
                'diagnosis': {'final': final_decision, 'normal_prob': prob_normal},
                'step1_meta': st.session_state.get('step1_meta', {"p_pd": p_pd, "p_normal": p_norm, "cutoff": pd_cut})
            }
            st.session_state.is_saved = False

        else:
            st.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

# ì „ì†¡ ë²„íŠ¼
st.markdown("---")
if st.button("â˜ï¸ ë°ì´í„° ì „ì†¡ (ë©”ì¼+ì‹œíŠ¸)", type="primary"):
    if 'save_ready_data' not in st.session_state:
        st.error("ğŸš¨ ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ğŸš€ ì§„ë‹¨ ê²°ê³¼ í™•ì¸]ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!")
    elif st.session_state.get('is_saved'):
        st.warning("ì´ë¯¸ ì „ì†¡ëœ ë°ì´í„°ì…ë‹ˆë‹¤.")
    else:
        with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ ê¸°ë¡ ë° ì´ë©”ì¼ ì „ì†¡ ì¤‘..."):
            success, msg = send_email_and_log_sheet(
                st.session_state.save_ready_data['wav_path'], 
                st.session_state.save_ready_data['patient'], 
                st.session_state.save_ready_data['analysis'], 
                st.session_state.save_ready_data['diagnosis']
            )
        if success:
            st.session_state.is_saved = True
            st.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! {msg}")
        else:
            st.error(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {msg}")
