import streamlit as st
import parselmouth
from parselmouth.praat import call
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import platform
from sklearn.ensemble import RandomForestClassifier
from scipy.signal import find_peaks

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="PD ìŒì„± ë³€ë³„ ì§„ë‹¨ ì‹œìŠ¤í…œ", layout="wide")

# ==========================================
# [ì¤‘ìš”] ë³€ìˆ˜ ì „ì—­ ì„¤ì •
# ==========================================
FEATS_STEP1 = ['F0', 'Range', 'Intensity', 'SPS', 'VHI_Total', 'VHI_P', 'VHI_F', 'VHI_E']
FEATS_STEP2 = FEATS_STEP1 + ['P_Pitch', 'P_Range', 'P_Loudness', 'P_Rate', 'P_Artic']

# ==========================================
# [í•œê¸€ í°íŠ¸ ì„¤ì •]
# ==========================================
def setup_korean_font():
    system_name = platform.system()
    if system_name == 'Windows':
        try:
            font_path = "C:/Windows/Fonts/malgun.ttf"
            font_name = fm.FontProperties(fname=font_path).get_name()
            plt.rc('font', family=font_name)
        except:
            plt.rc('font', family='Malgun Gothic')
    elif system_name == 'Darwin': 
        plt.rc('font', family='AppleGothic')
    else: 
        plt.rc('font', family='NanumGothic')
    plt.rcParams['axes.unicode_minus'] = False

setup_korean_font()

# ==========================================
# 0. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
# ==========================================
@st.cache_resource
def train_models():
    DATA_FILE = "training_data.csv"
    df = None
    
    if os.path.exists(DATA_FILE) or os.path.exists("training_data.xlsx"):
        loaders = [
            (lambda f: pd.read_excel(f.replace(".csv", ".xlsx")), "excel"),
            (lambda f: pd.read_csv(f, encoding='utf-8'), "utf-8"),
            (lambda f: pd.read_csv(f, encoding='cp949'), "cp949"),
            (lambda f: pd.read_csv(f, encoding='euc-kr'), "euc-kr")
        ]
        
        target_file = "training_data.xlsx" if os.path.exists("training_data.xlsx") else DATA_FILE
        
        df_raw = None
        for loader, enc_name in loaders:
            try:
                df_raw = loader(target_file)
                if df_raw is not None and not df_raw.empty: break
            except: continue
                
        if df_raw is not None:
            try:
                data_list = []
                for _, row in df_raw.iterrows():
                    label = str(row.get('ì§„ë‹¨ê²°ê³¼ (Label)', 'Normal')).strip()
                    
                    if 'normal' in label.lower():
                        diagnosis = "Normal"
                        subgroup = "Normal"
                    elif 'pd_intensity' in label.lower():
                        diagnosis = "Parkinson"
                        subgroup = "ê°•ë„ ì§‘ë‹¨"
                    elif 'pd_rate' in label.lower():
                        diagnosis = "Parkinson"
                        subgroup = "ë§ì†ë„ ì§‘ë‹¨"
                    elif 'pd_articulation' in label.lower():
                        diagnosis = "Parkinson"
                        subgroup = "ì¡°ìŒ ì§‘ë‹¨"
                    else:
                        continue

                    # VHI ì ìˆ˜ ì²´ê³„ ë³´ì •
                    raw_total = row.get('VHIì´ì ', 0)
                    raw_p = row.get('VHI_ì‹ ì²´', 0)
                    raw_f = row.get('VHI_ê¸°ëŠ¥', 0)
                    raw_e = row.get('VHI_ì •ì„œ', 0)
                    
                    if raw_total > 40: 
                        vhi_f = (raw_f / 40.0) * 20.0
                        vhi_p = (raw_p / 40.0) * 12.0
                        vhi_e = (raw_e / 40.0) * 8.0
                        vhi_total = vhi_f + vhi_p + vhi_e
                    else:
                        vhi_total = raw_total
                        vhi_f = raw_f
                        vhi_p = raw_p
                        vhi_e = raw_e
                    
                    p_pitch = row.get('ìŒë„(ì²­ì§€ê°)', 0)
                    p_prange = row.get('ìŒë„ë²”ìœ„(ì²­ì§€ê°)', 0)
                    p_loud = row.get('ê°•ë„(ì²­ì§€ê°)', 0)
                    p_rate = row.get('ë§ì†ë„(ì²­ì§€ê°)', 0)
                    p_artic = row.get('ì¡°ìŒì •í™•ë„(ì²­ì§€ê°)', 0)
                    
                    data_list.append([
                        row.get('F0', 0), row.get('Range', 0), row.get('ê°•ë„(dB)', 0), row.get('SPS', 0),
                        vhi_total, vhi_p, vhi_f, vhi_e,
                        p_pitch, p_prange, p_loud, p_rate, p_artic,
                        diagnosis, subgroup
                    ])
                
                df = pd.DataFrame(data_list, columns=FEATS_STEP2 + ['Diagnosis', 'Subgroup'])
                
                for col in FEATS_STEP2[:4]: # Acoustic vars
                    df[col] = df[col].fillna(df[col].mean())
                
                df[FEATS_STEP1[4:]] = df[FEATS_STEP1[4:]].fillna(0) # VHI vars

            except Exception as e:
                st.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                df = None

    if df is None:
        st.warning("âš ï¸ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    model_step1 = RandomForestClassifier(n_estimators=200, random_state=42)
    model_step1.fit(df[FEATS_STEP1], df['Diagnosis'])

    df_pd = df[df['Diagnosis'] == 'Parkinson'].copy()
    if not df_pd.empty:
        for col in FEATS_STEP2[8:]:
             df_pd[col] = df_pd[col].fillna(df_pd[col].mean())
             
        model_step2 = RandomForestClassifier(n_estimators=200, random_state=42)
        model_step2.fit(df_pd[FEATS_STEP2], df_pd['Subgroup'])
    else:
        model_step2 = None

    return model_step1, model_step2

try:
    model_step1, model_step2 = train_models()
except:
    model_step1, model_step2 = None, None

# --- Sidebar ---
with st.sidebar:
    st.title("ğŸ‘¤ ëŒ€ìƒì ì •ë³´")
    subject_name = st.text_input("ì´ë¦„", "ëŒ€ìƒì")
    subject_age = st.number_input("ë‚˜ì´", 1, 120, 60)
    subject_gender = st.selectbox("ì„±ë³„", ["ë‚¨", "ì—¬", "ê¸°íƒ€"])

TEMP_FILENAME = "temp_for_analysis.wav"

# ==========================================
# [í•¨ìˆ˜] ê³µí†µ ë¶„ì„ ë¡œì§
# ==========================================
def auto_detect_smr_events(sound_path, top_n=10):
    try:
        sound = parselmouth.Sound(sound_path)
        intensity = sound.to_intensity(time_step=0.005)
        times = intensity.xs()
        values = intensity.values[0, :]
        inv_vals = -values
        peaks, properties = find_peaks(inv_vals, prominence=5, distance=40)
        candidates = []
        for p_idx in peaks:
            time_point = times[p_idx]
            v_int = values[p_idx]
            start_search = max(0, p_idx - 20)
            end_search = min(len(values), p_idx + 20)
            local_max = np.max(values[start_search:end_search])
            depth = local_max - v_int
            candidates.append({"time": time_point, "depth": depth})
        candidates.sort(key=lambda x: x['time'])
        return candidates[:top_n], len(candidates)
    except:
        return [], 0

def plot_pitch_contour_plotly(sound_path, f0_min, f0_max):
    try:
        sound = parselmouth.Sound(sound_path)
        pitch = call(sound, "To Pitch", 0.0, f0_min, f0_max)
        pitch_vals = np.array(pitch.selected_array['frequency'], dtype=np.float64)
        duration = sound.get_total_duration()
        times = np.linspace(0, duration, len(pitch_vals))
        
        valid_idx = pitch_vals != 0
        valid_t = times[valid_idx]
        valid_p = pitch_vals[valid_idx]

        if len(valid_p) > 0:
            mean_f0 = np.mean(valid_p)
            rng = np.max(valid_p) - np.min(valid_p)
        else:
            mean_f0, rng = 0, 0

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=valid_t, y=valid_p, mode='markers', marker=dict(size=4, color='red'), name='Pitch'))
        fig.update_layout(title="ìŒë„ ì»¨íˆ¬ì–´", xaxis_title="Time(s)", yaxis_title="Hz", height=300, yaxis=dict(range=[0, 350]))
        return fig, mean_f0, rng, duration
    except:
        return None, 0, 0, 0

def run_analysis_logic(file_path):
    try:
        fig, f0, rng, dur = plot_pitch_contour_plotly(file_path, 75, 300)
        sound = parselmouth.Sound(file_path)
        intensity = sound.to_intensity()
        mean_db = call(intensity, "Get mean", 0, 0, "energy")
        sps = st.session_state.user_syllables / dur if dur > 0 else 0
        
        smr_events, _ = auto_detect_smr_events(file_path)
        
        st.session_state.update({
            'f0_mean': f0, 'pitch_range': rng, 'mean_db': mean_db, 
            'sps': sps, 'duration': dur, 'fig_plotly': fig, 
            'is_analyzed': True, 'smr_events': smr_events
        })
        return True
    except Exception as e:
        st.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
        return False

# ==========================================
# [ìˆ˜ì •ëœ í•¨ìˆ˜] ì¢…í•© í•´ì„ ìƒì„±ê¸°
# ==========================================
def generate_interpretation(prob_normal, db, sps, range_val, artic, vhi, vhi_e):
    positives = []
    negatives = []

    # 1. ê¸ì •ì  ìš”ì¸ (Normal í™•ë¥ ì„ ë†’ì´ëŠ” ìš”ì†Œ)
    if vhi < 15:
        positives.append(f"í™˜ì ë³¸ì¸ì˜ ì£¼ê´€ì  ë¶ˆí¸í•¨(VHI {vhi}ì )ì´ ë‚®ì•„ ì¼ìƒ ëŒ€í™”ì— ì‹¬ë¦¬ì  ë¶€ë‹´ì´ ì ìŠµë‹ˆë‹¤.")
    if range_val >= 100:
        positives.append(f"ìŒë„ ë²”ìœ„({range_val:.1f}Hz)ê°€ ë„“ì–´ ëª©ì†Œë¦¬ì— ìƒë™ê°ì´ ìˆê³  ì–µì–‘ì´ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.")
    if artic >= 75:
        positives.append(f"ì²­ì§€ê°ì  ì¡°ìŒ ì •í™•ë„({artic}ì )ê°€ ì–‘í˜¸í•˜ì—¬ ì˜ì‚¬ì†Œí†µ ëª…ë£Œë„ê°€ ë†’ìŠµë‹ˆë‹¤.")
    
    # [ìˆ˜ì •] ë§ì†ë„ê°€ 4.5 ë¯¸ë§Œì´ë©´(ëŠë¦¬ë”ë¼ë„) 'ê¸ì •ì /ì•ˆì •ì 'ìœ¼ë¡œ í‰ê°€
    if sps < 4.5:
        positives.append(f"ë§ì†ë„({sps:.2f} SPS)ê°€ ê¸‰ê²©íˆ ë¹¨ë¼ì§€ëŠ” ê°€ì† í˜„ìƒ ì—†ì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
    if db >= 60:
        positives.append(f"ì„±ëŸ‰({db:.1f} dB)ì´ íŠ¼íŠ¼í•˜ì—¬ ì •ìƒì ì¸ ë°œì„±ì´ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤.")

    # 2. ë¶€ì •ì /ìœ„í—˜ ìš”ì¸ (PD í™•ë¥ ì„ ë‚¨ê¸°ëŠ” ìš”ì†Œ)
    if db < 60:
        negatives.append(f"ì„±ëŸ‰({db:.1f} dB)ì´ ì¼ë°˜ ëŒ€í™” ìˆ˜ì¤€(60dB)ë³´ë‹¤ ì‘ì•„ íŒŒí‚¨ìŠ¨ë³‘ì˜ 'ê°•ë„ ê°ì†Œ(Hypophonia)' íŠ¹ì„±ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.")
    
    # [ìˆ˜ì •] ë§ì†ë„ê°€ 3.0 ë¯¸ë§Œì´ì–´ë„ ë¬¸ì œ ì‚¼ì§€ ì•ŠìŒ (ì‚­ì œë¨). 4.5 ì´ìƒì¼ ë•Œë§Œ ê²½ê³ .
    if sps >= 4.5:
        negatives.append(f"ë§ì†ë„({sps:.2f} SPS)ê°€ ì§€ë‚˜ì¹˜ê²Œ ë¹¨ë¼ ê°€ì†ë³´í–‰(Festination)ê³¼ ìœ ì‚¬í•œ ë§ì†ë„ ê°€ì† ì§•í›„ê°€ ì˜ì‹¬ë©ë‹ˆë‹¤.")
        
    if artic < 70:
        negatives.append(f"ë°œìŒì˜ ì •í™•ë„({artic}ì )ê°€ ë‹¤ì†Œ ë‚®ì•„ íŒŒí‚¨ìŠ¨ë³‘ì˜ ì¡°ìŒ ë¬¸ì œ(Dysarthria) ì§•í›„ë¡œ í•´ì„ë  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.")
    if vhi >= 20:
        negatives.append(f"VHI ì ìˆ˜({vhi}ì )ê°€ ë†’ì•„ í™˜ì ìŠ¤ìŠ¤ë¡œ ìŒì„± ë¬¸ì œë¥¼ í¬ê²Œ ìê°í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    if vhi_e >= 5:
        negatives.append("ì •ì„œì  ìŠ¤íŠ¸ë ˆìŠ¤(VHI-E)ê°€ ë†’ì•„ ë§í•˜ê¸°ì— ëŒ€í•œ ë¶ˆì•ˆê°ì´ ê°ì§€ë©ë‹ˆë‹¤.")

    return positives, negatives

# --- UI Title ---
st.title("ğŸ§  íŒŒí‚¨ìŠ¨ë³‘(PD) ìŒì„± í•˜ìœ„ìœ í˜• ë³€ë³„ ì§„ë‹¨ ì‹œìŠ¤í…œ")
st.markdown("ì²­ì§€ê°(Perceptual) + ìŒí–¥(Acoustic) + ìê°€ë³´ê³ (VHI-10) í†µí•© í•˜ì´ë¸Œë¦¬ë“œ ì§„ë‹¨ ëª¨ë¸")

# ==========================================
# 1. ë¬¸ë‹¨ ë‚­ë… ë° ìŒì„± ë¶„ì„
# ==========================================
st.header("1. ë¬¸ë‹¨ ë‚­ë… ë° ìŒì„± ë¶„ì„")

if 'user_syllables' not in st.session_state: st.session_state.user_syllables = 80
if 'source_type' not in st.session_state: st.session_state.source_type = None

col_rec, col_up = st.columns(2)

# [ì¢Œì¸¡: ë§ˆì´í¬ ë…¹ìŒ]
with col_rec:
    st.markdown("#### ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ & ë¬¸ë‹¨")
    font_size = st.slider("ğŸ” ê¸€ì í¬ê¸°", 15, 50, 28, key="fs_read")
    
    def styled_text(text, size):
        return f"""<div style="font-size: {size}px; line-height: 1.8; border: 1px solid #ddd; padding: 15px; background-color: #f9f9f9; color: #333;">{text}</div>"""

    with st.expander("ğŸ“– [1] ì‚°ì±… ë¬¸ë‹¨ (ì¼ë°˜ìš©)"):
        full_text = "ë†’ì€ ì‚°ì— ì˜¬ë¼ê°€ ë§‘ì€ ê³µê¸°ë¥¼ ë§ˆì‹œë©° ì†Œë¦¬ë¥¼ ì§€ë¥´ë©´ ê°€ìŠ´ì´ í™œì§ ì—´ë¦¬ëŠ” ë“¯í•˜ë‹¤. ë°”ë‹·ê°€ì— ë‚˜ê°€ ì¡°ê°œë¥¼ ì£¼ìœ¼ë©° ë„“ê²Œ í¼ì³ìˆëŠ” ë°”ë‹¤ë¥¼ ë°”ë¼ë³´ë©´ ë‚´ ë§ˆìŒ ì—­ì‹œ ë„“ì–´ì§€ëŠ” ê²ƒ ê°™ë‹¤."
        st.markdown(styled_text(full_text, font_size), unsafe_allow_html=True)
        
    with st.expander("ğŸ” [2] ë°”ë‹·ê°€ì˜ ì¶”ì–µ (SMR/ì¡°ìŒ ì •ë°€ ì§„ë‹¨ìš©)", expanded=True):
        seaside_text = """
        <strong>ë°”ë‹·ê°€</strong>ì— <strong>íŒŒë„ê°€</strong> ì¹©ë‹ˆë‹¤.<br>
        <strong>ë¬´ì§€ê°œ</strong> ì•„ë˜ <strong>ë°”ë‘‘ì´</strong>ê°€ ëœë‹ˆë‹¤.<br>
        <strong>ë³´íŠ¸ê°€</strong> ì§€ë‚˜ê°€ê³  <strong>ë²„í„°êµ¬ì´</strong>ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.<br>
        <strong>í¬í† ì¹´ë“œ</strong>ë¥¼ <strong>ë¶€íƒí•´</strong>ì„œ <strong>ë‹ë³´ê¸°</strong>ë¡œ ë´…ë‹ˆë‹¤.<br>
        ì‹œì¥ì—ì„œ <strong>ë¹ˆëŒ€ë–¡</strong>ì„ ì‚¬ ë¨¹ì—ˆìŠµë‹ˆë‹¤.
        """
        st.markdown(styled_text(seaside_text, font_size), unsafe_allow_html=True)

    syllables_rec = st.number_input("ì „ì²´ ìŒì ˆ ìˆ˜ (ê¸°ë³¸ê°’: 80)", 1, 500, 80, key="syl_rec")
    st.session_state.user_syllables = syllables_rec
    
    audio_buf = st.audio_input("ë‚­ë… ë…¹ìŒ")
    
    if st.button("ğŸ™ï¸ ë…¹ìŒëœ ìŒì„± ë¶„ì„", key="btn_anal_mic"):
        if audio_buf:
            with open(TEMP_FILENAME, "wb") as f: f.write(audio_buf.read())
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            st.session_state.source_type = "mic"
            run_analysis_logic(st.session_state.current_wav_path)
        else:
            st.warning("ë¨¼ì € ë…¹ìŒì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")

# [ìš°ì¸¡: íŒŒì¼ ì—…ë¡œë“œ]
with col_up:
    st.markdown("#### ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
    up_file = st.file_uploader("WAV íŒŒì¼ ì„ íƒ", type=["wav"], key="up_read")
    
    if up_file:
        st.audio(up_file, format='audio/wav')
    
    if st.button("ğŸ“‚ ì—…ë¡œë“œ íŒŒì¼ ë¶„ì„", key="btn_anal_file"):
        if up_file:
            with open(TEMP_FILENAME, "wb") as f: f.write(up_file.read())
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            st.session_state.source_type = "upload"
            run_analysis_logic(st.session_state.current_wav_path)
        else:
            st.warning("ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ==========================================
# 2. ê²°ê³¼ ë° ë³´ì •
# ==========================================
if st.session_state.get('is_analyzed'):
    st.markdown("---")
    st.subheader("2. ë¶„ì„ ê²°ê³¼ ë° ë³´ì •")
    
    c1, c2 = st.columns([2, 1])
    with c1: st.plotly_chart(st.session_state['fig_plotly'], use_container_width=True)
    with c2:
        db_adj = st.slider("ê°•ë„(dB) ë³´ì •", -50.0, 50.0, -10.0)
        final_db = st.session_state['mean_db'] + db_adj
        range_adj = st.slider("ìŒë„ë²”ìœ„(Hz) ë³´ì •", 0.0, 300.0, float(st.session_state['pitch_range']))
        s_time, e_time = st.slider("ë§ì†ë„ ì¸¡ì • êµ¬ê°„(ì´ˆ)", 0.0, st.session_state['duration'], (0.0, st.session_state['duration']), 0.01)
        sel_dur = max(0.1, e_time - s_time)
        final_sps = st.session_state.user_syllables / sel_dur
        
        st.dataframe(pd.DataFrame({
            "í•­ëª©": ["ê°•ë„(dB)", "ìŒë„(Hz)", "ìŒë„ë²”ìœ„(Hz)", "ë§ì†ë„(SPS)"],
            "ê°’": [f"{final_db:.2f}", f"{st.session_state['f0_mean']:.2f}", f"{range_adj:.2f}", f"{final_sps:.2f}"]
        }), hide_index=True)

    if st.session_state.get('smr_events'):
        st.markdown("##### ğŸ” SMR ìë™ ë¶„ì„")
        events = st.session_state['smr_events']
        smr_df_data = []
        words = ["ë°”ë‹·ê°€", "íŒŒë„ê°€", "ë¬´ì§€ê°œ", "ë°”ë‘‘ì´", "ë³´íŠ¸ê°€", "ë²„í„°êµ¬ì´", "í¬í† ì¹´ë“œ", "ë¶€íƒí•´", "ë‹ë³´ê¸°", "ë¹ˆëŒ€ë–¡"]
        for i, ev in enumerate(events):
            label = words[i] if i < len(words) else f"êµ¬ê°„ {i+1}"
            status = "ğŸŸ¢ ì–‘í˜¸" if ev['depth'] >= 20 else ("ğŸŸ¡ ì£¼ì˜" if ev['depth'] >= 15 else "ğŸ”´ ë¶ˆëŸ‰")
            smr_df_data.append({"ë‹¨ì–´": label, "íì‡„ ê¹Šì´(dB)": f"{ev['depth']:.1f}", "ìƒíƒœ": status})
        st.dataframe(pd.DataFrame(smr_df_data).T)

    # ==========================================
    # 3. ì²­ì§€ê°/ìê°€ë³´ê³  (VHI-10)
    # ==========================================
    st.markdown("---")
    st.subheader("3. ì²­ì§€ê° í‰ê°€ ë° ìê°€ë³´ê³  (VHI-10)")
    
    cc1, cc2 = st.columns([1, 1.2])
    
    with cc1:
        st.markdown("#### ğŸ”Š ì²­ì§€ê° í‰ê°€")
        p_artic = st.slider("ì¡°ìŒ ì •í™•ë„ (Articulation)", 0, 100, 50, help="78ì  ì´ìƒì´ë©´ ì •ìƒìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.")
        p_pitch = st.slider("ìŒë„ (Pitch)", 0, 100, 50)
        p_prange = st.slider("ìŒë„ ë²”ìœ„ (Pitch Range)", 0, 100, 50)
        p_loud = st.slider("ê°•ë„ (Loudness)", 0, 100, 50)
        p_rate = st.slider("ë§ì†ë„ (Rate)", 0, 100, 50)
        
    with cc2:
        st.markdown("#### ğŸ“ VHI-10 (ìê°€ë³´ê³ )")
        st.caption("0: ì „í˜€, 1: ê±°ì˜X, 2: ê°€ë”, 3: ìì£¼, 4: í•­ìƒ")
        
        vhi_opts = [0, 1, 2, 3, 4]
        
        with st.expander("VHI-10 ë¬¸í•­ ì…ë ¥ (í´ë¦­)", expanded=True):
            # ê¸°ëŠ¥(F)
            q1 = st.select_slider("1. ìƒëŒ€ë°©ì´ ë‚´ ë§ì„ ì•Œì•„ë“£ê¸° í˜ë“¤ì–´í•œë‹¤", options=vhi_opts)
            q2 = st.select_slider("2. ì‹œë„ëŸ¬ìš´ ê³³ì—ì„œ ì´í•´í•˜ê¸° ì–´ë ¤ì›Œí•œë‹¤", options=vhi_opts)
            q5 = st.select_slider("5. ìŒì„±ë¬¸ì œë¡œ ìƒí™œì— ì œí•œì„ ë°›ëŠ”ë‹¤", options=vhi_opts)
            q7 = st.select_slider("7. ëŒ€í™”ì— ë¼ì§€ ëª»í•´ ì†Œì™¸ê°ì„ ëŠë‚€ë‹¤", options=vhi_opts)
            q8 = st.select_slider("8. ìŒì„± ë¬¸ì œë¡œ ìˆ˜ì… ê°ì†Œê°€ ìƒê¸´ë‹¤", options=vhi_opts)
            
            # ì‹ ì²´(P)
            q3 = st.select_slider("3. ì‚¬ëŒë“¤ì´ ëª©ì†Œë¦¬ê°€ ì™œ ê·¸ëŸ¬ëƒê³  ë¬»ëŠ”ë‹¤", options=vhi_opts)
            q4 = st.select_slider("4. ëª©ì†Œë¦¬ë¥¼ ë‚´ë ¤ë©´ í˜ì„ ì£¼ì–´ì•¼ í•œë‹¤", options=vhi_opts)
            q6 = st.select_slider("6. ëª©ì†Œë¦¬ê°€ ì–¸ì œ ë§‘ê²Œ ë‚˜ì˜¬ì§€ ì•Œ ìˆ˜ ì—†ë‹¤", options=vhi_opts)

            # ì •ì„œ(E)
            q9 = st.select_slider("9. ë‚´ ëª©ì†Œë¦¬ ë¬¸ì œë¡œ ì†ì´ ìƒí•œë‹¤", options=vhi_opts)
            q10 = st.select_slider("10. ìŒì„± ë¬¸ì œê°€ ì¥ì• ë¡œ ì—¬ê²¨ì§„ë‹¤", options=vhi_opts)

        # ì˜ì—­ë³„ ê³„ì‚°
        vhi_f = q1 + q2 + q5 + q7 + q8
        vhi_p = q3 + q4 + q6
        vhi_e = q9 + q10
        vhi_total = vhi_f + vhi_p + vhi_e
        
        st.divider()
        c_v1, c_v2, c_v3, c_v4 = st.columns(4)
        c_v1.metric("VHI ì´ì ", f"{vhi_total}ì ", "/ 40")
        c_v2.metric("ê¸°ëŠ¥(F)", f"{vhi_f}ì ", "/ 20")
        c_v3.metric("ì‹ ì²´(P)", f"{vhi_p}ì ", "/ 12")
        c_v4.metric("ì •ì„œ(E)", f"{vhi_e}ì ", "/ 8")

    # ==========================================
    # 4. ìµœì¢… ì§„ë‹¨ (Hybrid Logic)
    # ==========================================
    st.markdown("---")
    st.subheader("4. ìµœì¢… ì¢…í•© ì§„ë‹¨")
    
    if st.button("ğŸš€ ì§„ë‹¨ ê²°ê³¼ í™•ì¸", key="btn_diag"):
        if model_step1 is None:
            st.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            # Step 0: Rule-based (ê·œì¹™ ê¸°ë°˜)
            if p_artic >= 78 and vhi_total < 12:
                st.success(f"ğŸŸ¢ **ì •ìƒ ìŒì„± (Normal) (100.0%)**")
                prob_normal = 100.0
                
                final_decision = "Normal"
                final_db = st.session_state['mean_db'] + db_adj
                final_sps = st.session_state.user_syllables / sel_dur
            
            else:
                # Step 1: 1ì°¨ AI ì§„ë‹¨
                input_step1 = pd.DataFrame([[
                    st.session_state['f0_mean'], range_adj, final_db, final_sps,
                    vhi_total, vhi_p, vhi_f, vhi_e
                ]], columns=FEATS_STEP1)
                
                pred_1 = model_step1.predict(input_step1)[0]
                prob_1 = model_step1.predict_proba(input_step1)[0]
                
                classes_1 = list(model_step1.classes_)
                normal_idx = classes_1.index('Normal') if 'Normal' in classes_1 else 0
                prob_normal = prob_1[normal_idx] * 100

                if pred_1 == 'Normal':
                    st.success(f"ğŸŸ¢ **ì •ìƒ ìŒì„± (Normal) ({prob_normal:.1f}%)**")
                    final_decision = "Normal"
                
                else:
                    # Step 2: 2ì°¨ AI ì§„ë‹¨
                    st.error(f"ğŸ”´ **íŒŒí‚¨ìŠ¨ë³‘(PD) ìŒì„± íŠ¹ì„±**ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.write("1ì°¨ AI ì§„ë‹¨ ê²°ê³¼ íŒŒí‚¨ìŠ¨ íŒ¨í„´ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ì„¸ë¶€ ìœ í˜•ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
                    
                    if model_step2:
                        input_step2 = pd.DataFrame([[
                            st.session_state['f0_mean'], range_adj, final_db, final_sps,
                            vhi_total, vhi_p, vhi_f, vhi_e,
                            p_pitch, p_prange, p_loud, p_rate, p_artic
                        ]], columns=FEATS_STEP2)
                        
                        pred_subtype = model_step2.predict(input_step2)[0]
                        probs_sub = model_step2.predict_proba(input_step2)[0]
                        
                        # --- [Hybrid Logic] ì„ê³„ê°’ ë° ê°€ì¤‘ì¹˜ ì ìš© ---
                        final_decision = pred_subtype
                        warn_msg = []
                        
                        is_rate_feature = False
                        
                        emotional_ratio = vhi_e / 8.0 
                        if emotional_ratio >= 0.55: 
                            is_rate_feature = True
                            warn_msg.append("âš ï¸ **[ì¤‘ìš”]** ë†’ì€ ì •ì„œì  ìŠ¤íŠ¸ë ˆìŠ¤(VHI-ì •ì„œ)ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” **'ë§ì†ë„ ì§‘ë‹¨'**ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤.")
                        
                        # [ìˆ˜ì •] ê°ê´€ì  ë§ì†ë„ê°€ ë¹ ë¥¼ ë•Œë§Œ ê²½ê³ 
                        if final_sps >= 4.5:
                             is_rate_feature = True
                             warn_msg.append("âš ï¸ ê°ê´€ì  ë§ì†ë„(SPS)ê°€ ë¹ ë¦…ë‹ˆë‹¤.")
                        
                        if is_rate_feature and "ë§ì†ë„" not in final_decision:
                            final_decision = "ë§ì†ë„ ì§‘ë‹¨ (ì¬ì¡°ì •ë¨)"
                            warn_msg.append("ğŸ’¡ ê°ê´€ì  ì§€í‘œì— ë”°ë¼ ì§„ë‹¨ ê²°ê³¼ê°€ **'ë§ì†ë„ ì§‘ë‹¨'**ìœ¼ë¡œ ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

                        # ê°•ë„ ì§‘ë‹¨ íŒë³„
                        MIC_INTENSITY_CUTOFF = 60.0
                        if final_db < MIC_INTENSITY_CUTOFF:
                            if "ê°•ë„" not in final_decision:
                                warn_msg.append(f"âš ï¸ **[ì¤‘ìš”]** ìŒì„± ê°•ë„ê°€ {final_db:.1f}dBë¡œ ê¸°ì¤€ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. **'ê°•ë„ ì§‘ë‹¨'** íŠ¹ì„±ì´ ê°•í•©ë‹ˆë‹¤.")
                                final_decision = "ê°•ë„ ì§‘ë‹¨ (ì¬ì¡°ì •ë¨)"

                        # ì¡°ìŒ ì§‘ë‹¨ íŒë³„
                        if vhi_total < 15 and p_artic < 60:
                            if "ì¡°ìŒ" not in final_decision:
                                warn_msg.append("âš ï¸ ì£¼ê´€ì  ë¶ˆí¸í•¨(VHI)ì€ ì ìœ¼ë‚˜ ì²­ì§€ê°ì  ì¡°ìŒ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. **'ì¡°ìŒ ì§‘ë‹¨'** ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
                                final_decision = "ì¡°ìŒ ì§‘ë‹¨ (ì¬ì¡°ì •ë¨)"

                        st.markdown(f"### ğŸ” ìµœì¢… ì˜ˆì¸¡ í•˜ìœ„ ìœ í˜•: **[{final_decision}]**")
                        for msg in warn_msg: st.warning(msg)
                        
                        labels = list(model_step2.classes_)
                        labels_with_probs = [f"{label}\n({prob*100:.1f}%)" for label, prob in zip(labels, probs_sub)]
                        
                        fig_radar = plt.figure(figsize=(4, 4))
                        ax = fig_radar.add_subplot(111, polar=True)
                        angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
                        angles += angles[:1]
                        stats = probs_sub.tolist() + [probs_sub[0]]

                        ax.plot(angles, stats, linewidth=2, linestyle='solid', color='red')
                        ax.fill(angles, stats, 'red', alpha=0.25)
                        ax.set_xticks(angles[:-1])
                        ax.set_xticklabels(labels_with_probs)
                        
                        c_chart, c_desc = st.columns([1, 2])
                        with c_chart: st.pyplot(fig_radar)
                        with c_desc:
                            if "ê°•ë„" in final_decision:
                                st.info("ğŸ’¡ **íŠ¹ì§•:** ëª©ì†Œë¦¬ í¬ê¸°ê°€ ì‘ê³  ì•½í•©ë‹ˆë‹¤. (Hypophonia)")
                            elif "ë§ì†ë„" in final_decision:
                                st.info("ğŸ’¡ **íŠ¹ì§•:** ë§ì´ ë¹ ë¥´ê±°ë‚˜ ë¦¬ë“¬ì´ ë¶ˆê·œì¹™í•˜ë©°, ì •ì„œì  ë¶ˆì•ˆê°ì´ ë™ë°˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            else:
                                st.info("ğŸ’¡ **íŠ¹ì§•:** ë°œìŒì´ ë­‰ê°œì§€ê³  ì •í™•ë„ê°€ ë–¨ì–´ì§‘ë‹ˆë‹¤.")

            # ğŸ’¡ ìƒì„¸ ì¢…í•© í•´ì„
            st.divider()
            with st.expander("ğŸ’¡ ìƒì„¸ ì¢…í•© í•´ì„ (AI Interpretation) ë³´ê¸°", expanded=True):
                positives, negatives = generate_interpretation(prob_normal, final_db, final_sps, range_adj, p_artic, vhi_total, vhi_e)
                
                st.markdown(f"**1. ì •ìƒ(Normal) í™•ë¥ ì´ {prob_normal:.1f}%ë¡œ ë‚˜íƒ€ë‚œ ì´ìœ  (ê¸ì •ì  ìš”ì¸):**")
                if positives:
                    for p in positives:
                        st.markdown(f"- âœ… {p}")
                else:
                    st.markdown("- íŠ¹ë³„í•œ ê¸ì •ì  ìš”ì¸ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                st.markdown(f"**2. íŒŒí‚¨ìŠ¨(PD) ê°€ëŠ¥ì„±ì´ {100-prob_normal:.1f}% ì¡´ì¬í•˜ëŠ” ì´ìœ  (ìœ„í—˜ ìš”ì¸):**")
                if negatives:
                    for n in negatives:
                        st.markdown(f"- âš ï¸ {n}")
                else:
                    st.markdown("- íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì¸ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                # ì¢…í•© ê²°ë¡ 
                if prob_normal >= 70:
                    st.info("ğŸ“‹ **ê²°ë¡ :** ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ìƒíƒœì´ë‚˜, ìœ„ì—ì„œ ì–¸ê¸‰ëœ ì¼ë¶€ 'ìœ„í—˜ ìš”ì¸'(íŠ¹íˆ ê°•ë„ë‚˜ ì¡°ìŒ)ì— ëŒ€í•´ì„œëŠ” ì§€ì†ì ì¸ ê´€ì°°ì´ë‚˜ ê°€ë²¼ìš´ í›ˆë ¨ì´ ê¶Œì¥ë©ë‹ˆë‹¤.")
                elif prob_normal >= 40:
                    st.warning("ğŸ“‹ **ê²°ë¡ :** ì •ìƒê³¼ íŒŒí‚¨ìŠ¨ íŠ¹ì„±ì´ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ê²½ê³ ê°€ ëœ¬ í•­ëª©(ê°•ë„, ì†ë„ ë“±)ì— ëŒ€í•´ ì •ë°€ ê²€ì‚¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    st.error("ğŸ“‹ **ê²°ë¡ :** íŒŒí‚¨ìŠ¨ë³‘ì˜ ìŒì„±í•™ì  íŠ¹ì§•ì´ ëšœë ·í•˜ê²Œ ê´€ì°°ë©ë‹ˆë‹¤. ì „ë¬¸ì˜ì™€ì˜ ìƒë‹´ ë° ìŒì„± ì¹˜ë£Œê°€ ì ê·¹ ê¶Œì¥ë©ë‹ˆë‹¤.")
