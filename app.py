import streamlit as st
import parselmouth
from parselmouth.praat import call
import numpy as np
import pandas as pd
import plotly.graph_objects as go  # Interactive plotting
import matplotlib.pyplot as plt    
import matplotlib.font_manager as fm 
import os
import platform
from sklearn.ensemble import RandomForestClassifier
from datetime import datetime

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="PD ìŒì„± ë³€ë³„ ì§„ë‹¨ ì‹œìŠ¤í…œ", layout="wide")

# ==========================================
# [í•œê¸€ í°íŠ¸ ì„¤ì •]
# ==========================================
def setup_korean_font():
    system_name = platform.system()
    if system_name == 'Windows':
        try:
            font_path = "C:/Windows/Fonts/malgun.ttf"
            font_name = fm.FontProperties(fname=font_path).get_name()
            plt.rc('font', family=font_name)
        except:
            plt.rc('font', family='Malgun Gothic')
    elif system_name == 'Darwin': 
        plt.rc('font', family='AppleGothic')
    else: 
        plt.rc('font', family='NanumGothic')
    plt.rcParams['axes.unicode_minus'] = False

setup_korean_font()

# ==========================================
# 0. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ (ì²­ì§€ê°ì  VAS í†µê³„ ì™„ë²½ ë°˜ì˜)
# ==========================================
@st.cache_resource
def train_models():
    SCALE_FACTOR = 3.0 
    
    # Feature ìˆœì„œ: [F0, Range, Intensity, SPS, VHI_P, VHI_F, VHI_E, P_Loudness, P_Rate, P_Artic]
    
    # ëª¨ë¸ì˜ ì•ˆì •ì ì¸ í•™ìŠµì„ ìœ„í•´ ê° ì§‘ë‹¨ë³„ë¡œ ì¶©ë¶„í•œ ìˆ˜ì˜ ê°€ìƒ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ê° 50ê°œ)
    # í†µê³„ì¹˜ëŠ” ì œê³µí•´ì£¼ì‹  ì‹¤ì œ ì—°êµ¬ ë°ì´í„°ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
    
    # A. ì •ìƒ ê·¸ë£¹
    normal_data = []
    for _ in range(50):
        normal_data.append([
            np.random.normal(151.32, 20.0), # F0
            np.random.normal(91.68, 20.0),  # Range
            np.random.normal(70.0, 4.0),    # Intensity
            np.random.normal(4.25, 0.8),    # SPS
            0, 0, 0,                        # VHI
            np.random.normal(80.0, 10.0),   # P_Loudness (ì •ìƒ ë²”ìœ„)
            np.random.normal(50.0, 10.0),   # P_Rate (ë³´í†µ)
            np.random.normal(95.0, 5.0),    # P_Artic (ëª…ë£Œí•¨)
            "Normal", "None"
        ])
        
    # B. íŒŒí‚¨ìŠ¨ ê·¸ë£¹ (ì œê³µëœ í†µê³„ì¹˜ ì ìš©)
    pd_data = []
    
    # 1) ê°•ë„ ì§‘ë‹¨ (Red)
    # íŠ¹ì§•: P_Loudness(ê°•ë„)ê°€ 29.47ë¡œ ë§¤ìš° ë‚®ìŒ
    for _ in range(50):
        pd_data.append([
            np.random.normal(153.21, 25.0), 
            np.random.normal(101.21, 25.0), 
            np.random.normal(52.0, 5.0),     # ìŒí–¥ ê°•ë„ë„ ë‚®ê²Œ ì„¤ì •
            np.random.normal(4.05, 0.8),     
            np.random.normal(20.18 / SCALE_FACTOR, 2.0), 
            np.random.normal(19.36 / SCALE_FACTOR, 2.0), 
            np.random.normal(18.91 / SCALE_FACTOR, 2.0),
            np.random.normal(29.47, 10.0),   # [í•µì‹¬] P_Loudness: ë§¤ìš° ë‚®ìŒ (29.47)
            np.random.normal(49.73, 8.89),   # P_Rate: ë³´í†µ
            np.random.normal(49.53, 15.0),   # P_Artic: ë³´í†µ ë‚®ìŒ
            "Parkinson", "ê°•ë„ ì§‘ë‹¨"
        ])
        
    # 2) ë§ì†ë„ ì§‘ë‹¨ (Yellow)
    # íŠ¹ì§•: P_Rate(ë§ì†ë„)ê°€ 75.63ìœ¼ë¡œ ë§¤ìš° ë†’ìŒ(ë¹ ë¦„)
    for _ in range(50):
        pd_data.append([
            np.random.normal(162.90, 25.0), 
            np.random.normal(84.84, 15.0), 
            np.random.normal(60.0, 4.0),     
            np.random.normal(6.0, 0.5),      # ìŒí–¥ SPSë„ ë¹ ë¥´ê²Œ
            np.random.normal(24.67 / SCALE_FACTOR, 2.0), 
            np.random.normal(29.00 / SCALE_FACTOR, 2.0), 
            np.random.normal(32.00 / SCALE_FACTOR, 2.0), 
            np.random.normal(51.56, 13.23),  # P_Loudness: ë³´í†µ
            np.random.normal(75.63, 10.0),   # [í•µì‹¬] P_Rate: ë§¤ìš° ë¹ ë¦„ (75.63)
            np.random.normal(56.22, 17.64),  # P_Artic: ë³´í†µ
            "Parkinson", "ë§ì†ë„ ì§‘ë‹¨"
        ])
        
    # 3) ì¡°ìŒ ì§‘ë‹¨ (Blue)
    # íŠ¹ì§•: P_Artic(ì¡°ìŒ)ì´ 40.97ë¡œ ê°€ì¥ ë‚®ìŒ. P_LoudnessëŠ” 65.61ë¡œ ì–‘í˜¸.
    for _ in range(50):
        pd_data.append([
            np.random.normal(151.32, 20.0),  
            np.random.normal(91.68, 20.0),   
            np.random.normal(65.0, 4.0),     
            np.random.normal(4.18, 0.6),     
            np.random.normal(17.75 / SCALE_FACTOR, 2.0), 
            np.random.normal(13.75 / SCALE_FACTOR, 2.0), 
            np.random.normal(11.25 / SCALE_FACTOR, 2.0), 
            np.random.normal(65.61, 5.0),    # P_Loudness: ë†’ìŒ (65.61) - ê°•ë„ ì§‘ë‹¨ê³¼ í™•ì‹¤íˆ êµ¬ë³„ë¨
            np.random.normal(50.61, 9.78),   # P_Rate: ë³´í†µ
            np.random.normal(40.97, 8.0),    # [í•µì‹¬] P_Artic: ê°€ì¥ ë‚®ìŒ (40.97)
            "Parkinson", "ì¡°ìŒ ì§‘ë‹¨"
        ])

    df = pd.DataFrame(normal_data + pd_data, columns=[
        'F0', 'Range', 'Intensity', 'SPS', 'VHI_P', 'VHI_F', 'VHI_E', 
        'P_Loudness', 'P_Rate', 'P_Artic', 'Diagnosis', 'Subgroup'
    ])

    features = ['F0', 'Range', 'Intensity', 'SPS', 'VHI_P', 'VHI_F', 'VHI_E', 'P_Loudness', 'P_Rate', 'P_Artic']

    model_diagnosis = RandomForestClassifier(n_estimators=100, random_state=42)
    model_diagnosis.fit(df[features], df['Diagnosis'])

    df_pd = df[df['Diagnosis'] == 'Parkinson']
    model_subgroup = RandomForestClassifier(n_estimators=100, random_state=42)
    model_subgroup.fit(df_pd[features], df_pd['Subgroup'])

    return model_diagnosis, model_subgroup

diagnosis_model, subgroup_model = train_models()

# --- Sidebar ---
with st.sidebar:
    st.title("ğŸ‘¤ ëŒ€ìƒì ì •ë³´")
    subject_name = st.text_input("ì´ë¦„", "ëŒ€ìƒì")
    subject_age = st.number_input("ë‚˜ì´", 1, 120, 60)
    subject_gender = st.selectbox("ì„±ë³„", ["ë‚¨", "ì—¬", "ê¸°íƒ€"])

    def generate_filename(name, age, gender, is_uploaded=False):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        type_str = "ì—…ë¡œë“œ" if is_uploaded else "ë…¹ìŒ"
        gender_short = gender[0] if gender else "X"
        return f"{timestamp}_{name}_{age}ì„¸_{gender_short}_{type_str}.wav"

TEMP_FILENAME = "temp_for_analysis.wav"

# ==========================================
# í”¼ì¹˜ ì»¨íˆ¬ì–´ ì‹œê°í™” í•¨ìˆ˜ (Plotly)
# ==========================================
def plot_pitch_contour_plotly(sound_path, f0_min, f0_max):
    try:
        sound = parselmouth.Sound(sound_path)
        pitch = call(sound, "To Pitch", 0.0, f0_min, f0_max)
        pitch_array = np.array(pitch.selected_array)
        pitch_values = np.array(pitch_array['frequency'], dtype=np.float64)
        duration = sound.get_total_duration()
        n_points = len(pitch_values)
        time_array = np.linspace(0, duration, n_points)
        
        valid_indices = pitch_values != 0
        valid_times = time_array[valid_indices]
        valid_pitch = pitch_values[valid_indices]

        if len(valid_pitch) > 0:
            median_f0 = np.median(valid_pitch)
            std_f0 = np.std(valid_pitch)
            upper = median_f0 + 3 * std_f0
            lower = median_f0 - 3 * std_f0
            clean_mask = (valid_pitch <= upper) & (valid_pitch >= lower)
            final_times = valid_times[clean_mask]
            final_pitch = valid_pitch[clean_mask]
            cleaned_mean_f0 = np.mean(final_pitch)
        else:
            final_times = valid_times
            final_pitch = valid_pitch
            cleaned_mean_f0 = 0

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=final_times, y=final_pitch,
            mode='markers', name='Pitch (Hz)',
            marker=dict(size=4, color='red'),
            hovertemplate='ì‹œê°„: %{x:.2f}ì´ˆ<br>ìŒë„: %{y:.1f}Hz'
        ))
        fig.add_trace(go.Scatter(
            x=[0, duration], y=[cleaned_mean_f0, cleaned_mean_f0],
            mode='lines', name=f'í‰ê·  F0 ({cleaned_mean_f0:.1f}Hz)',
            line=dict(color='gray', dash='dash'), hoverinfo='skip'
        ))
        fig.update_layout(
            title=f"ìŒë„ ì»¨íˆ¬ì–´ (Pitch Contour)",
            xaxis_title="ì‹œê°„ (ì´ˆ)", yaxis_title="ìŒë„ (Hz)",
            yaxis=dict(range=[0, 300]),
            height=300, margin=dict(l=20, r=20, t=40, b=20),
            showlegend=True
        )
        return fig, cleaned_mean_f0
    except Exception as e:
        st.error(f"í”¼ì¹˜ ì»¨íˆ¬ì–´ ì˜¤ë¥˜: {e}")
        return None, 0

# --- ì œëª© ---
st.title("ğŸ§  íŒŒí‚¨ìŠ¨ë³‘(PD) ìŒì„± í•˜ìœ„ìœ í˜• ë³€ë³„ ì§„ë‹¨ ì‹œìŠ¤í…œ")
st.markdown("""
ì´ í”„ë¡œê·¸ë¨ì€ **ì²­ì§€ê°ì  í‰ê°€**, **ìŒí–¥í•™ì  ë¶„ì„**, **ìê°€ë³´ê³ (VHI-10)** ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ 
íŒŒí‚¨ìŠ¨ë³‘ í™˜ìì˜ ìŒì„± íŠ¹ì„±ì„ 4ê°€ì§€ í•˜ìœ„ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
""")

# ==========================================
# 1. ìŒì„± ë…¹ìŒ ë° ì—…ë¡œë“œ
# ==========================================
st.header("1. ìŒì„± ë…¹ìŒ ë° íŒŒì¼ ì—…ë¡œë“œ")

tab1, tab2 = st.tabs(["ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ (ì‹œì‘/ì¤‘ì§€)", "ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ"])

if 'current_wav_path' in st.session_state:
    current_wav_path = st.session_state.current_wav_path

if 'user_syllables' not in st.session_state:
    st.session_state.user_syllables = 69 

# [Tab 1] ë§ˆì´í¬ ë…¹ìŒ
with tab1:
    st.markdown("##### ë§ˆì´í¬ ë…¹ìŒ (ì‹œì‘/ì¤‘ì§€)")
    st.caption("ì•„ë˜ ë§ˆì´í¬ ì•„ì´ì½˜ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ê³ , ì™„ë£Œë˜ë©´ ì •ì§€ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
    
    syllables_rec = st.number_input("ë‚­ë… ë¬¸ë‹¨ì˜ ì´ ìŒì ˆ ìˆ˜", min_value=1, value=69, key="syllables_rec")
    st.session_state.user_syllables = syllables_rec

    audio_buffer = st.audio_input("ë…¹ìŒí•˜ê¸°", label_visibility="collapsed")
    
    if audio_buffer:
        audio_bytes = audio_buffer.read()
        with open(TEMP_FILENAME, "wb") as f:
            f.write(audio_bytes)
        
        st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
        final_filename = generate_filename(subject_name, subject_age, subject_gender, is_uploaded=False)
        
        st.success("ë…¹ìŒ ì™„ë£Œ! ë¶„ì„ ì¤€ë¹„ë¨.")
        st.download_button(
            label="ğŸ’¾ ë…¹ìŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=audio_bytes,
            file_name=final_filename,
            mime="audio/wav"
        )

# [Tab 2] íŒŒì¼ ì—…ë¡œë“œ
with tab2:
    st.markdown("##### ê¸°ì¡´ WAV íŒŒì¼ ì—…ë¡œë“œ")
    
    syllables_up = st.number_input("ë‚­ë… ë¬¸ë‹¨ì˜ ì´ ìŒì ˆ ìˆ˜ (ì—…ë¡œë“œ íŒŒì¼ìš©)", min_value=1, value=69, key="syllables_up")
    uploaded_file = st.file_uploader("WAV íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["wav"], key="file_uploader")
    
    if uploaded_file is not None:
        try:
            file_bytes = uploaded_file.read()
            with open(TEMP_FILENAME, 'wb') as f:
                f.write(file_bytes)
            
            st.session_state.current_wav_path = os.path.join(os.getcwd(), TEMP_FILENAME)
            st.session_state.user_syllables = syllables_up
            
            final_filename = generate_filename(subject_name, subject_age, subject_gender, is_uploaded=True)
            
            st.success("ì—…ë¡œë“œ ì™„ë£Œ! ë¶„ì„ ì¤€ë¹„ë¨.")
            st.download_button(
                label="ğŸ’¾ ì—…ë¡œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì €ì¥)",
                data=file_bytes,
                file_name=final_filename,
                mime="audio/wav"
            )
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

# ==========================================
# 2. ê°ê´€ì /ê¸°ê¸°ì  í‰ê°€
# ==========================================
st.header("2. ìŒí–¥í•™ì  ë¶„ì„ ë° ìˆ˜ë™ ë³´ì •")

is_analyzed = False

if 'current_wav_path' in st.session_state and st.session_state.current_wav_path and os.path.exists(st.session_state.current_wav_path):
    current_wav_path = st.session_state.current_wav_path
    
    if st.button("ğŸ› ï¸ ìŒì„± ë¶„ì„ ì‹¤í–‰/ê°±ì‹ ", key="analyze_button"):
        try:
            sound = parselmouth.Sound(current_wav_path)
            
            # 1. Pitch Plotly (F0 Mean í¬í•¨)
            fig_plotly, f0_mean_calc = plot_pitch_contour_plotly(current_wav_path, 75, 300)
            
            # 2. Pitch Range (Cleaned)
            pitch = call(sound, "To Pitch", 0.0, 75, 300)
            pitch_vals = pitch.selected_array['frequency']
            valid_p = pitch_vals[pitch_vals != 0]
            if len(valid_p) > 0:
                pitch_range_init = np.max(valid_p) - np.min(valid_p)
            else:
                pitch_range_init = 0

            # 3. Intensity, SPS
            intensity = sound.to_intensity()
            mean_db_spl = call(intensity, "Get mean", 0, 0, "energy")
            sps = st.session_state.user_syllables / sound.duration
            
            # 4. Jitter/Shimmer ì œê±°ë¨
            
            st.session_state['pitch_range_init'] = pitch_range_init
            st.session_state['f0_mean_init'] = f0_mean_calc
            st.session_state['mean_db_spl_init'] = mean_db_spl
            st.session_state['sps_init'] = sps
            st.session_state['fig_plotly'] = fig_plotly
            st.session_state['is_analyzed'] = True
            
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ (ì ìš©ëœ ìŒì ˆ ìˆ˜: {st.session_state.user_syllables})")
        except Exception as e:
            st.error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")

if 'is_analyzed' in st.session_state and st.session_state['is_analyzed']:
    st.markdown("#### ğŸ§ ìŒë„ ë²”ìœ„ (Pitch Range) ìˆ˜ë™ ë³´ì •")
    
    if 'fig_plotly' in st.session_state:
        st.plotly_chart(st.session_state['fig_plotly'])
    
    col_adj1, col_adj2 = st.columns([2, 1])
    with col_adj1:
        final_pitch_range = st.slider("ìµœì¢… ìŒë„ ë²”ìœ„ (Hz) ë³´ì •", 0.0, 150.0, st.session_state['pitch_range_init'], 0.1)
    
    st.markdown("#### ğŸ“Š ìµœì¢… ìŒí–¥ ë¶„ì„ ì§€í‘œ")
    
    acoustic_data = {
        "ì§€í‘œëª…": ["ê°•ë„ (dB)", "ìŒë„ (F0)", "ìŒë„ ë²”ìœ„", "ë§ì†ë„ (SPS)"],
        "ê°’": [
            f"{st.session_state['mean_db_spl_init']:.2f} dB",
            f"{st.session_state['f0_mean_init']:.2f} Hz",
            f"{final_pitch_range:.2f} Hz",
            f"{st.session_state['sps_init']:.2f}"
        ]
    }
    df_acoustic = pd.DataFrame(acoustic_data)
    c_table, c_dummy = st.columns([1, 2])
    with c_table:
        st.dataframe(df_acoustic, hide_index=True)

# ==========================================
# 3. ì²­ì§€ê°ì  ë° ìê°€ë³´ê³  í‰ê°€
# ==========================================
st.markdown("---")
st.header("3. ì²­ì§€ê°ì  ë° ìê°€ë³´ê³  í‰ê°€")

c1, c2 = st.columns(2)

with c1:
    st.subheader("ğŸ”Š ì²­ì§€ê°ì  í‰ê°€")
    st.caption("ëŒ€ìƒìì˜ ìŒì„± íŠ¹ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš” (0 ~ 100)")
    p_pitch = st.slider("ìŒë„", 0, 100, 50, help="0(ë‚®ë‹¤) ~ 100(ë†’ë‹¤)")
    p_pitch_range = st.slider("ìŒë„ ë²”ìœ„", 0, 100, 50, help="0(ì¢ë‹¤/ë‹¨ì¡°ë¡­ë‹¤) ~ 100(ë„“ë‹¤/ë³€í™”í¬ë‹¤)")
    p_loudness = st.slider("ê°•ë„", 0, 100, 50, help="0(ì‘ë‹¤) ~ 100(í¬ë‹¤)")
    p_rate = st.slider("ë§ì†ë„", 0, 100, 50, help="0(ëŠë¦¬ë‹¤) ~ 100(ë¹ ë¥´ë‹¤)")
    p_articulation = st.slider("ì¡°ìŒ ì •í™•ë„", 0, 100, 50, help="0(ë‚˜ì˜ë‹¤) ~ 100(ì¢‹ë‹¤)")

with c2:
    st.subheader("ğŸ“ í™˜ì ìê°€ë³´ê³  (VHI-10)")
    vhi_scale = [0, 1, 2, 3, 4]
    vhi_labels = {0: "0: ì „í˜€", 1: "1: ê±°ì˜X", 2: "2: ê°€ë”", 3: "3: ìì£¼", 4: "4: í•­ìƒ"}
    def vhi_slider(label, k):
        return st.select_slider(label, options=vhi_scale, value=0, key=k, format_func=lambda x: vhi_labels[x])

    q1 = vhi_slider("1. ì „í™” í†µí™”ê°€ í˜ë“¤ë‹¤", 'q1')
    q2 = vhi_slider("2. ëŒ€í™”ê°€ ë¶ˆí¸í•˜ë‹¤", 'q2')
    q3 = vhi_slider("3. ëª©ì†Œë¦¬ê°€ ë¶ˆì•ˆì •í•˜ë‹¤", 'q3')
    q4 = vhi_slider("4. ì—…ë¬´ ìˆ˜í–‰ ì–´ë ¤ì›€", 'q4')
    q5 = vhi_slider("5. ëª©ì†Œë¦¬ê°€ ê±°ì¹ ë‹¤", 'q5')
    q6 = vhi_slider("6. ëª©ì´ ì‰½ê²Œ í”¼ê³¤í•˜ë‹¤", 'q6')
    q7 = vhi_slider("7. ëª©ì— í˜ì´ ë“¤ì–´ê°„ë‹¤", 'q7')
    q8 = vhi_slider("8. ìì‹ ê°ì´ ë–¨ì–´ì§„ë‹¤", 'q8')
    q9 = vhi_slider("9. ë¶ˆì•ˆí•˜ê±°ë‚˜ ìš°ìš¸í•˜ë‹¤", 'q9')
    q10 = vhi_slider("10. íƒ€ì¸ì˜ ì§€ì ì„ ë°›ëŠ”ë‹¤", 'q10')

    vhi_functional = q1 + q2 + q4
    vhi_physical = q3 + q5 + q6 + q7
    vhi_emotional = q8 + q9 + q10
    vhi_total = vhi_functional + vhi_physical + vhi_emotional
    st.markdown(f"**VHI ì´ì : {vhi_total}/40** (ì‹ ì²´ {vhi_physical}, ê¸°ëŠ¥ {vhi_functional}, ì •ì„œ {vhi_emotional})")

# ==========================================
# 4. ì¢…í•© ì§„ë‹¨ ë° ë¶„ë¥˜ ê²°ê³¼
# ==========================================
st.markdown("---")
st.header("4. ì¢…í•© ì§„ë‹¨ ë° ë¶„ë¥˜ ê²°ê³¼")

if st.button("ğŸš€ ìµœì¢… ë³€ë³„ ì§„ë‹¨ ì‹¤í–‰", key="final_classify_button"):
    if 'is_analyzed' not in st.session_state or not st.session_state['is_analyzed']:
        st.error("âš ï¸ ìŒì„± ë¶„ì„ (2ë‹¨ê³„)ì„ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
    else:
        # [ìˆ˜ì •] 3ê°€ì§€ ì²­ì§€ê° ë³€ìˆ˜(ê°•ë„, ë§ì†ë„, ì¡°ìŒ) ëª¨ë‘ í¬í•¨
        feature_names = ['F0', 'Range', 'Intensity', 'SPS', 'VHI_P', 'VHI_F', 'VHI_E', 'P_Loudness', 'P_Rate', 'P_Artic']
        
        input_values = [[
            st.session_state['f0_mean_init'],
            final_pitch_range,
            st.session_state['mean_db_spl_init'],
            st.session_state['sps_init'],
            vhi_physical,
            vhi_functional,
            vhi_emotional,
            p_loudness,     # ì²­ì§€ê°-ê°•ë„
            p_rate,         # ì²­ì§€ê°-ë§ì†ë„
            p_articulation  # ì²­ì§€ê°-ì¡°ìŒ
        ]]
        
        input_features = pd.DataFrame(input_values, columns=feature_names)
        
        diag_pred = diagnosis_model.predict(input_features)[0]
        diag_prob = diagnosis_model.predict_proba(input_features)[0] 
        
        st.subheader("ğŸ“Š 1ë‹¨ê³„: ë³€ë³„ ì§„ë‹¨ ê²°ê³¼")
        
        if diag_pred == "Normal":
            st.success(f"ğŸŸ¢ **ì •ìƒ ìŒì„± (Normal)** ë²”ìœ„ì— ì†í•©ë‹ˆë‹¤.")
            st.metric("ì •ìƒ í™•ë¥ ", f"{diag_prob[0]*100:.1f}%")
            st.info("íŒŒí‚¨ìŠ¨ë³‘ íŠ¹ì´ì  ìŒì„± ì§•í›„ê°€ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        else:
            st.error(f"ğŸ”´ **íŒŒí‚¨ìŠ¨ë³‘(PD) ìŒì„± ì¥ì• ** íŠ¹ì„±ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.metric("PD ì˜ì‹¬ í™•ë¥ ", f"{diag_prob[1]*100:.1f}%")
            
            sub_pred = subgroup_model.predict(input_features)[0]
            sub_probs = subgroup_model.predict_proba(input_features)[0]
            classes = subgroup_model.classes_
            
            st.markdown("---")
            st.subheader("ğŸ” 2ë‹¨ê³„: í•˜ìœ„ ìœ í˜• ë¶„ë¥˜")
            st.write(f"ê°€ì¥ ìœ ë ¥í•œ ìœ í˜•ì€ **[{sub_pred}]** ì…ë‹ˆë‹¤.")
            
            fig = plt.figure(figsize=(4, 4)) 
            ax = fig.add_subplot(111, polar=True)
            
            values = sub_probs.tolist()
            values += values[:1] 
            angles = np.linspace(0, 2 * np.pi, len(classes), endpoint=False).tolist()
            angles += angles[:1]
            
            ax.fill(angles, values, color='red', alpha=0.25)
            ax.plot(angles, values, color='red', linewidth=2)
            
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(classes, size=10) 
            ax.set_title("íŒŒí‚¨ìŠ¨ ìŒì„± í•˜ìœ„ ìœ í˜• í™•ë¥ ", size=12, pad=15)
            
            c_chart, c_empty = st.columns([1, 1]) 
            with c_chart:
                st.pyplot(fig)
            
            if sub_pred == "ê°•ë„ ì§‘ë‹¨":
                desc = "ì²­ì§€ê°ì  ê°•ë„ê°€ í˜„ì €íˆ ë‚®ê³ (ì•½í•œ ëª©ì†Œë¦¬), ì‹ ì²´ì  ë¶ˆí¸í•¨ì´ ì£¼ìš” íŠ¹ì§•ì…ë‹ˆë‹¤."
            elif sub_pred == "ë§ì†ë„ ì§‘ë‹¨":
                desc = "ë§ì†ë„ê°€ ë§¤ìš° ë¹ ë¥´ë©°(ê°€ì†ë³´í–‰ í˜„ìƒ), ì •ì„œì  ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
            else: # ì¡°ìŒ ì§‘ë‹¨
                desc = "ì²­ì§€ê°ì  ì¡°ìŒ ì •í™•ë„ê°€ í˜„ì €íˆ ë‚®ê³  ë°œìŒì´ ë¶ˆëª…ë£Œí•œ ê²ƒì´ ì£¼ëœ íŠ¹ì§•ì…ë‹ˆë‹¤."
                
            st.info(f"ğŸ’¡ **ì„ìƒì  ì œì–¸:** {desc}")
